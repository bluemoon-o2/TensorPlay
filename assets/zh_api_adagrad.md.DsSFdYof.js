import{_ as a,c as o,o as t,a4 as s}from"./chunks/framework.t-GQSDtj.js";const u=JSON.parse('{"title":"tensorplay.optim.adagrad","description":"","frontmatter":{},"headers":[],"relativePath":"zh/api/adagrad.md","filePath":"zh/api/adagrad.md"}'),r={name:"zh/api/adagrad.md"};function i(l,e,n,p,d,h){return t(),o("div",null,[...e[0]||(e[0]=[s('<div class="warning custom-block"><p class="custom-block-title">WARNING</p><p>该页面尚未翻译。 以下内容为英文原版。</p></div><h1 id="tensorplay-optim-adagrad" tabindex="-1">tensorplay.optim.adagrad <a class="header-anchor" href="#tensorplay-optim-adagrad" aria-label="Permalink to &quot;tensorplay.optim.adagrad&quot;">​</a></h1><h2 id="classes" tabindex="-1">Classes <a class="header-anchor" href="#classes" aria-label="Permalink to &quot;Classes&quot;">​</a></h2><h3 id="class-adagrad-source" tabindex="-1"><code>class Adagrad</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/adagrad.py#L4" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-adagrad-source" aria-label="Permalink to &quot;`class Adagrad` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/adagrad.py#L4)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Adagrad(params, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr_decay</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weight_decay</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">initial_accumulator_value</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>Optimizer</code></p><details><summary>Methods</summary><h4 id="init-self-params-lr-0-01-lr-decay-0-weight-decay-0-initial-accumulator-value-0-eps-1e-10-source" tabindex="-1"><code>__init__(self, params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/adagrad.py#L5" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-params-lr-0-01-lr-decay-0-weight-decay-0-initial-accumulator-value-0-eps-1e-10-source" aria-label="Permalink to &quot;`__init__(self, params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/adagrad.py#L5)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="add-param-group-self-param-group-source" tabindex="-1"><code>add_param_group(self, param_group)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L29" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#add-param-group-self-param-group-source" aria-label="Permalink to &quot;`add_param_group(self, param_group)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L29)&quot;">​</a></h4><hr><h4 id="load-state-dict-self-state-dict-source" tabindex="-1"><code>load_state_dict(self, state_dict)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L110" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-source" aria-label="Permalink to &quot;`load_state_dict(self, state_dict)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L110)&quot;">​</a></h4><hr><h4 id="state-dict-self-source" tabindex="-1"><code>state_dict(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L80" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-source" aria-label="Permalink to &quot;`state_dict(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L80)&quot;">​</a></h4><hr><h4 id="step-self-closure-none-source" tabindex="-1"><code>step(self, closure=None)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/adagrad.py#L27" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-closure-none-source" aria-label="Permalink to &quot;`step(self, closure=None)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/adagrad.py#L27)&quot;">​</a></h4><hr><h4 id="zero-grad-self-set-to-none-false-source" tabindex="-1"><code>zero_grad(self, set_to_none=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#zero-grad-self-set-to-none-false-source" aria-label="Permalink to &quot;`zero_grad(self, set_to_none=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L64)&quot;">​</a></h4><hr></details><h3 id="class-optimizer-source" tabindex="-1"><code>class Optimizer</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L5" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-optimizer-source" aria-label="Permalink to &quot;`class Optimizer` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L5)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Optimizer(params, defaults)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Base class for optimizers.</p><h4 id="args" tabindex="-1">Args <a class="header-anchor" href="#args" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>params</strong> (<code>iterable</code>): an iterable of <code>Tensor</code> s or <code>dict</code> s. Specifies what Tensors should be optimized.</li><li><strong>defaults</strong>: (dict): a dict containing default values of optimization options (used when a parameter group doesn&#39;t specify them).</li></ul><details><summary>Methods</summary><h4 id="init-self-params-defaults-source" tabindex="-1"><code>__init__(self, params, defaults)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L16" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-params-defaults-source" aria-label="Permalink to &quot;`__init__(self, params, defaults)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L16)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="add-param-group-self-param-group-source-1" tabindex="-1"><code>add_param_group(self, param_group)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L29" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#add-param-group-self-param-group-source-1" aria-label="Permalink to &quot;`add_param_group(self, param_group)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L29)&quot;">​</a></h4><hr><h4 id="load-state-dict-self-state-dict-source-1" tabindex="-1"><code>load_state_dict(self, state_dict)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L110" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-source-1" aria-label="Permalink to &quot;`load_state_dict(self, state_dict)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L110)&quot;">​</a></h4><hr><h4 id="state-dict-self-source-1" tabindex="-1"><code>state_dict(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L80" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-source-1" aria-label="Permalink to &quot;`state_dict(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L80)&quot;">​</a></h4><hr><h4 id="step-self-closure-none-source-1" tabindex="-1"><code>step(self, closure=None)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L77" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-closure-none-source-1" aria-label="Permalink to &quot;`step(self, closure=None)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L77)&quot;">​</a></h4><hr><h4 id="zero-grad-self-set-to-none-false-source-1" tabindex="-1"><code>zero_grad(self, set_to_none=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#zero-grad-self-set-to-none-false-source-1" aria-label="Permalink to &quot;`zero_grad(self, set_to_none=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L64)&quot;">​</a></h4><hr></details>',13)])])}const m=a(r,[["render",i]]);export{u as __pageData,m as default};

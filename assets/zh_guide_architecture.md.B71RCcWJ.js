import{_ as a,c as n,o as i,a4 as l}from"./chunks/framework.t-GQSDtj.js";const g=JSON.parse('{"title":"架构概览","description":"","frontmatter":{},"headers":[],"relativePath":"zh/guide/architecture.md","filePath":"zh/guide/architecture.md"}'),t={name:"zh/guide/architecture.md"};function e(r,s,o,p,h,d){return i(),n("div",null,[...s[0]||(s[0]=[l(`<h1 id="架构概览" tabindex="-1">架构概览 <a class="header-anchor" href="#架构概览" aria-label="Permalink to &quot;架构概览&quot;">​</a></h1><p>TensorPlay 采用严格解耦的分层架构设计。它由四个核心库组成，具有清晰的边界和单向依赖关系。</p><h2 id="_4-个核心库" tabindex="-1">4 个核心库 <a class="header-anchor" href="#_4-个核心库" aria-label="Permalink to &quot;4 个核心库&quot;">​</a></h2><h3 id="_1-p10-张量计算引擎" tabindex="-1">1. P10（张量计算引擎） <a class="header-anchor" href="#_1-p10-张量计算引擎" aria-label="Permalink to &quot;1. P10（张量计算引擎）&quot;">​</a></h3><ul><li><strong>角色</strong>：基础的“计算引擎”。</li><li><strong>设计理念</strong>： <ul><li><strong>硬件抽象</strong>：使用 <code>Tensor</code> 接口和 <code>TensorImpl</code> 多态性来支持多种硬件后端（CPU、CUDA、自定义边缘芯片），而无需更改前端 API。</li><li><strong>零微分逻辑</strong>：专注于高效的张量内核和内存管理，作为所有其他层的稳定基石。</li><li><strong>调度器模式</strong>：将算子定义与特定于设备的实现解耦，允许轻松集成 MKL 或 cuDNN 等库。</li></ul></li></ul><h3 id="_2-tpx-自动微分引擎" tabindex="-1">2. TPX（自动微分引擎） <a class="header-anchor" href="#_2-tpx-自动微分引擎" aria-label="Permalink to &quot;2. TPX（自动微分引擎）&quot;">​</a></h3><ul><li><strong>角色</strong>：“微分层”。</li><li><strong>设计理念</strong>： <ul><li><strong>解耦的自动微分</strong>：作为轻量级扩展层实现，而不是烘焙到张量核心中。它仅在 <code>requires_grad=True</code> 时跟踪操作。</li><li><strong>显式图构建</strong>：专为教育清晰度而设计，允许用户检查计算图是如何构建的以及在反向传播期间是如何遍历的。</li><li><strong>可插拔引擎</strong>：可以替换或扩展不同的微分模式（例如高阶导数），而不影响底层的 P10 引擎。</li></ul></li></ul><h3 id="_3-stax-静态图加速器" tabindex="-1">3. Stax（静态图加速器） <a class="header-anchor" href="#_3-stax-静态图加速器" aria-label="Permalink to &quot;3. Stax（静态图加速器）&quot;">​</a></h3><ul><li><strong>角色</strong>：“优化层”。</li><li><strong>设计理念</strong>： <ul><li><strong>优化优先</strong>：专注于静态图捕获、算子融合和即时 (JIT) 编译，以最大限度地减少 Python 开销。</li><li><strong>独立路径</strong>：在与 TPX/NN 分离的依赖链上运行，使其成为可以根据性能需求添加或删除的模块化组件。</li><li><strong>编译器集成</strong>：设计用于在未来对接 MLIR 或 TVM 等高级编译器后端。</li></ul></li></ul><h3 id="_4-nn-神经网络库" tabindex="-1">4. NN（神经网络库） <a class="header-anchor" href="#_4-nn-神经网络库" aria-label="Permalink to &quot;4. NN（神经网络库）&quot;">​</a></h3><ul><li><strong>角色</strong>：“业务层”。</li><li><strong>设计理念</strong>： <ul><li><strong>用户友好的抽象</strong>：为 <code>Linear</code>、<code>Conv2d</code> 和 <code>Optimizers</code> 等高级组件提供熟悉的、兼容 PyTorch 的接口。</li><li><strong>蓝图方法</strong>：每一层都被设计成清晰、可读的蓝图，演示复杂的神经网络组件是如何从基本的张量操作构建的。</li><li><strong>纯依赖</strong>：严格依赖 P10 和 TPX 的公共 API，确保它保持为高级建模的可选、非侵入式层。</li></ul></li></ul><hr><h2 id="依赖图" tabindex="-1">依赖图 <a class="header-anchor" href="#依赖图" aria-label="Permalink to &quot;依赖图&quot;">​</a></h2><div class="language-mermaid vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">mermaid</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">graph TD</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    NN[NN: Neural Networks] --&gt; TPX[TPX: Autograd]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    NN --&gt; P10[P10: Computation]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    TPX --&gt; P10</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Stax[Stax: Static Graph] --&gt; P10</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    style P10 fill:#f9f,stroke:#333,stroke-width:2px</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    style TPX fill:#bbf,stroke:#333,stroke-width:1px</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    style Stax fill:#bfb,stroke:#333,stroke-width:1px</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    style NN fill:#fbb,stroke:#333,stroke-width:1px</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h2 id="为什么采用这种架构" tabindex="-1">为什么采用这种架构？ <a class="header-anchor" href="#为什么采用这种架构" aria-label="Permalink to &quot;为什么采用这种架构？&quot;">​</a></h2><ol><li><strong>解耦</strong>：每个库都可以独立开发、测试和优化。</li><li><strong>可扩展性</strong>：添加新的硬件后端仅需更改 P10。添加新的微分模式仅影响 TPX。</li><li><strong>性能</strong>：用户只需为他们使用的功能付费。纯计算任务不会加载自动微分引擎或静态图编译器。</li><li><strong>教育价值</strong>：通过分离这些关注点，TensorPlay 使开发人员能够轻松理解现代深度学习框架的内部结构。</li></ol>`,16)])])}const u=a(t,[["render",e]]);export{g as __pageData,u as default};

import{_ as o,c as t,o as r,a4 as e}from"./chunks/framework.t-GQSDtj.js";const h=JSON.parse('{"title":"tensorplay.autograd.function","description":"","frontmatter":{},"headers":[],"relativePath":"zh/api/function.md","filePath":"zh/api/function.md"}'),s={name:"zh/api/function.md"};function n(i,a,l,c,u,p){return r(),t("div",null,[...a[0]||(a[0]=[e('<div class="warning custom-block"><p class="custom-block-title">WARNING</p><p>该页面尚未翻译。 以下内容为英文原版。</p></div><h1 id="tensorplay-autograd-function" tabindex="-1">tensorplay.autograd.function <a class="header-anchor" href="#tensorplay-autograd-function" aria-label="Permalink to &quot;tensorplay.autograd.function&quot;">​</a></h1><h2 id="classes" tabindex="-1">Classes <a class="header-anchor" href="#classes" aria-label="Permalink to &quot;Classes&quot;">​</a></h2><h3 id="class-function-source" tabindex="-1"><code>class Function</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L18" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-function-source" aria-label="Permalink to &quot;`class Function` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L18)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Function()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Records operation history and defines formulas for differentiating ops.</p><details><summary>Methods</summary><h4 id="apply-args-kwargs-source" tabindex="-1"><code>apply(*args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L37" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#apply-args-kwargs-source" aria-label="Permalink to &quot;`apply(*args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L37)&quot;">​</a></h4><hr><h4 id="backward-ctx-grad-outputs-source" tabindex="-1"><code>backward(ctx, *grad_outputs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L30" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#backward-ctx-grad-outputs-source" aria-label="Permalink to &quot;`backward(ctx, *grad_outputs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L30)&quot;">​</a></h4><p>Defines a formula for differentiating the operation.</p><hr><h4 id="forward-ctx-args-kwargs-source" tabindex="-1"><code>forward(ctx, *args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L23" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#forward-ctx-args-kwargs-source" aria-label="Permalink to &quot;`forward(ctx, *args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L23)&quot;">​</a></h4><p>Performs the operation.</p><hr></details>',7)])])}const b=o(s,[["render",n]]);export{h as __pageData,b as default};

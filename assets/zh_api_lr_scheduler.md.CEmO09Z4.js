import{_ as l,c as s,o,a4 as a,j as e,a as r}from"./chunks/framework.DWXU4yX9.js";const k=JSON.parse('{"title":"tensorplay.optim.lr_scheduler","description":"","frontmatter":{},"headers":[],"relativePath":"zh/api/lr_scheduler.md","filePath":"zh/api/lr_scheduler.md"}'),i={name:"zh/api/lr_scheduler.md"},n={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},h={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.489ex"},xmlns:"http://www.w3.org/2000/svg",width:"4.478ex",height:"1.489ex",role:"img",focusable:"false",viewBox:"0 -442 1979.4 658","aria-hidden":"true"},p={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"4.675ex",height:"1.889ex",role:"img",focusable:"false",viewBox:"0 -677 2066.4 834.8","aria-hidden":"true"};function d(u,t,m,b,g,y){return o(),s("div",null,[t[7]||(t[7]=a('<div class="warning custom-block"><p class="custom-block-title">WARNING</p><p>该页面尚未翻译。 以下内容为英文原版。</p></div><h1 id="tensorplay-optim-lr-scheduler" tabindex="-1">tensorplay.optim.lr_scheduler <a class="header-anchor" href="#tensorplay-optim-lr-scheduler" aria-label="Permalink to &quot;tensorplay.optim.lr_scheduler&quot;">​</a></h1><h2 id="classes" tabindex="-1">Classes <a class="header-anchor" href="#classes" aria-label="Permalink to &quot;Classes&quot;">​</a></h2><h3 id="class-cosineannealinglr-source" tabindex="-1"><code>class CosineAnnealingLR</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L218" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-cosineannealinglr-source" aria-label="Permalink to &quot;`class CosineAnnealingLR` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L218)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">CosineAnnealingLR(optimizer, t_max, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eta_min</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">last_epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_LRScheduler</code></p>',6)),e("p",null,[t[4]||(t[4]=r("Set the learning rate of each parameter group using a cosine annealing schedule, where ",-1)),e("mjx-container",n,[(o(),s("svg",h,[...t[0]||(t[0]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(530,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1407,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g></g></g></g></g>',1)])])),t[1]||(t[1]=e("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("msub",null,[e("mi",null,"η"),e("mrow",{"data-mjx-texclass":"ORD"},[e("mi",null,"m"),e("mi",null,"a"),e("mi",null,"x")])])])],-1))]),t[5]||(t[5]=r(" is set to the initial lr and ",-1)),e("mjx-container",p,[(o(),s("svg",c,[...t[2]||(t[2]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(617,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1407,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g></g></g></g></g>',1)])])),t[3]||(t[3]=e("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("msub",null,[e("mi",null,"T"),e("mrow",{"data-mjx-texclass":"ORD"},[e("mi",null,"m"),e("mi",null,"a"),e("mi",null,"x")])])])],-1))]),t[6]||(t[6]=r(" is the number of epochs to decay. When last_epoch=-1, sets initial lr as lr.",-1))]),t[8]||(t[8]=a('<h4 id="args" tabindex="-1">Args <a class="header-anchor" href="#args" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>optimizer</strong> (<code>Optimizer</code>): Wrapped optimizer.</li><li><strong>t_max</strong> (<code>int</code>): Maximum number of epochs.</li><li><strong>eta_min</strong> (<code>float</code>): Minimum learning rate. Default: 0.</li><li><strong>last_epoch</strong> (<code>int</code>): The index of last epoch. Default: -1.</li><li><strong>verbose</strong> (<code>bool</code>): If <code>True</code>, prints a message to stdout for each update. Default: <code>False</code>.</li></ul><details><summary>Methods</summary><h4 id="init-self-optimizer-t-max-eta-min-0-last-epoch-1-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, t_max, eta_min=0, last_epoch=-1, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L233" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-t-max-eta-min-0-last-epoch-1-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, t_max, eta_min=0, last_epoch=-1, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L233)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="get-last-lr-self-list-float-source" tabindex="-1"><code>get_last_lr(self) -&gt; List[float]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-last-lr-self-list-float-source" aria-label="Permalink to &quot;`get_last_lr(self) -&gt; List[float]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93)&quot;">​</a></h4><p>Return last computed learning rates by the scheduler.</p><h4 id="raises" tabindex="-1">Raises <a class="header-anchor" href="#raises" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>RuntimeError</strong>: If the scheduler has not stepped yet.</li></ul><hr><h4 id="get-lr-self-source" tabindex="-1"><code>get_lr(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L238" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-lr-self-source" aria-label="Permalink to &quot;`get_lr(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L238)&quot;">​</a></h4><p>Compute the learning rate for the current epoch.</p><h4 id="returns" tabindex="-1">Returns <a class="header-anchor" href="#returns" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>List[float]: Learning rates for each parameter group. Must have the same length as param_groups.\n</code></pre><hr><h4 id="load-state-dict-self-state-dict-dict-str-typing-any-none-source" tabindex="-1"><code>load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-dict-str-typing-any-none-source" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64)&quot;">​</a></h4><p>Loads the scheduler state.</p><h4 id="args-1" tabindex="-1">Args <a class="header-anchor" href="#args-1" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): Scheduler state. Should be an object returned from a call to <code>state_dict</code>.</li></ul><h4 id="raises-1" tabindex="-1">Raises <a class="header-anchor" href="#raises-1" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the number of base_lrs in state_dict does not match the current optimizer&#39;s param_groups.</li></ul><hr><h4 id="state-dict-self-dict-str-typing-any-source" tabindex="-1"><code>state_dict(self) -&gt; dict[str, typing.Any]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-dict-str-typing-any-source" aria-label="Permalink to &quot;`state_dict(self) -&gt; dict[str, typing.Any]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56)&quot;">​</a></h4><p>Returns the state of the scheduler as a dict.</p><p>Includes all attributes except &#39;optimizer&#39; to avoid circular references.</p><hr><h4 id="step-self-epoch-optional-int-none-none-source" tabindex="-1"><code>step(self, epoch: Optional[int] = None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-epoch-optional-int-none-none-source" aria-label="Permalink to &quot;`step(self, epoch: Optional[int] = None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104)&quot;">​</a></h4><p>Step the scheduler to update learning rates.</p><h4 id="args-2" tabindex="-1">Args <a class="header-anchor" href="#args-2" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>epoch</strong> (<code>Optional[int]</code>): The epoch index to set. If None, increment last_epoch by 1.</li></ul><h4 id="raises-2" tabindex="-1">Raises <a class="header-anchor" href="#raises-2" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If epoch is a non-integer or negative value, or less than current last_epoch.</li></ul><hr></details><h3 id="class-exponentiallr-source" tabindex="-1"><code>class ExponentialLR</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L195" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-exponentiallr-source" aria-label="Permalink to &quot;`class ExponentialLR` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L195)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ExponentialLR(optimizer, gamma, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">last_epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_LRScheduler</code></p><p>Set the learning rate of each parameter group to the initial lr decayed by gamma every epoch. When last_epoch=-1, sets initial lr as lr.</p><h4 id="args-3" tabindex="-1">Args <a class="header-anchor" href="#args-3" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>optimizer</strong> (<code>Optimizer</code>): Wrapped optimizer.</li><li><strong>gamma</strong> (<code>float</code>): Multiplicative factor of learning rate decay.</li><li><strong>Default</strong>: 0.1.</li><li><strong>last_epoch</strong> (<code>int</code>): The index of last epoch. Default: -1.</li><li><strong>verbose</strong> (<code>bool</code>): If <code>True</code>, prints a message to stdout for each update. Default: <code>False</code>.</li></ul><details><summary>Methods</summary><h4 id="init-self-optimizer-gamma-last-epoch-1-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, gamma, last_epoch=-1, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L208" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-gamma-last-epoch-1-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, gamma, last_epoch=-1, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L208)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="get-last-lr-self-list-float-source-1" tabindex="-1"><code>get_last_lr(self) -&gt; List[float]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-last-lr-self-list-float-source-1" aria-label="Permalink to &quot;`get_last_lr(self) -&gt; List[float]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93)&quot;">​</a></h4><p>Return last computed learning rates by the scheduler.</p><h4 id="raises-3" tabindex="-1">Raises <a class="header-anchor" href="#raises-3" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>RuntimeError</strong>: If the scheduler has not stepped yet.</li></ul><hr><h4 id="get-lr-self-source-1" tabindex="-1"><code>get_lr(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L212" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-lr-self-source-1" aria-label="Permalink to &quot;`get_lr(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L212)&quot;">​</a></h4><p>Compute the learning rate for the current epoch.</p><h4 id="returns-1" tabindex="-1">Returns <a class="header-anchor" href="#returns-1" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>List[float]: Learning rates for each parameter group. Must have the same length as param_groups.\n</code></pre><hr><h4 id="load-state-dict-self-state-dict-dict-str-typing-any-none-source-1" tabindex="-1"><code>load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-dict-str-typing-any-none-source-1" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64)&quot;">​</a></h4><p>Loads the scheduler state.</p><h4 id="args-4" tabindex="-1">Args <a class="header-anchor" href="#args-4" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): Scheduler state. Should be an object returned from a call to <code>state_dict</code>.</li></ul><h4 id="raises-4" tabindex="-1">Raises <a class="header-anchor" href="#raises-4" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the number of base_lrs in state_dict does not match the current optimizer&#39;s param_groups.</li></ul><hr><h4 id="state-dict-self-dict-str-typing-any-source-1" tabindex="-1"><code>state_dict(self) -&gt; dict[str, typing.Any]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-dict-str-typing-any-source-1" aria-label="Permalink to &quot;`state_dict(self) -&gt; dict[str, typing.Any]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56)&quot;">​</a></h4><p>Returns the state of the scheduler as a dict.</p><p>Includes all attributes except &#39;optimizer&#39; to avoid circular references.</p><hr><h4 id="step-self-epoch-optional-int-none-none-source-1" tabindex="-1"><code>step(self, epoch: Optional[int] = None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-epoch-optional-int-none-none-source-1" aria-label="Permalink to &quot;`step(self, epoch: Optional[int] = None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104)&quot;">​</a></h4><p>Step the scheduler to update learning rates.</p><h4 id="args-5" tabindex="-1">Args <a class="header-anchor" href="#args-5" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>epoch</strong> (<code>Optional[int]</code>): The epoch index to set. If None, increment last_epoch by 1.</li></ul><h4 id="raises-5" tabindex="-1">Raises <a class="header-anchor" href="#raises-5" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If epoch is a non-integer or negative value, or less than current last_epoch.</li></ul><hr></details><h3 id="class-multisteplr-source" tabindex="-1"><code>class MultiStepLR</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L169" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-multisteplr-source" aria-label="Permalink to &quot;`class MultiStepLR` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L169)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MultiStepLR(optimizer, milestones, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">gamma</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">last_epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_LRScheduler</code></p><p>Set the learning rate of each parameter group to the initial lr decayed by gamma once the number of epoch reaches one of the milestones. When last_epoch=-1, sets initial lr as lr.</p><h4 id="args-6" tabindex="-1">Args <a class="header-anchor" href="#args-6" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>optimizer</strong> (<code>Optimizer</code>): Wrapped optimizer.</li><li><strong>milestones</strong> (<code>set of int</code>): Set of epoch indices. Must be increasing.</li><li><strong>gamma</strong> (<code>float</code>): Multiplicative factor of learning rate decay.</li><li><strong>Default</strong>: 0.1.</li><li><strong>last_epoch</strong> (<code>int</code>): The index of last epoch. Default: -1.</li><li><strong>verbose</strong> (<code>bool</code>): If <code>True</code>, prints a message to stdout for each update. Default: <code>False</code>.</li></ul><details><summary>Methods</summary><h4 id="init-self-optimizer-milestones-gamma-0-1-last-epoch-1-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, milestones, gamma=0.1, last_epoch=-1, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L184" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-milestones-gamma-0-1-last-epoch-1-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, milestones, gamma=0.1, last_epoch=-1, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L184)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="get-last-lr-self-list-float-source-2" tabindex="-1"><code>get_last_lr(self) -&gt; List[float]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-last-lr-self-list-float-source-2" aria-label="Permalink to &quot;`get_last_lr(self) -&gt; List[float]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93)&quot;">​</a></h4><p>Return last computed learning rates by the scheduler.</p><h4 id="raises-6" tabindex="-1">Raises <a class="header-anchor" href="#raises-6" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>RuntimeError</strong>: If the scheduler has not stepped yet.</li></ul><hr><h4 id="get-lr-self-source-2" tabindex="-1"><code>get_lr(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L189" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-lr-self-source-2" aria-label="Permalink to &quot;`get_lr(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L189)&quot;">​</a></h4><p>Compute the learning rate for the current epoch.</p><h4 id="returns-2" tabindex="-1">Returns <a class="header-anchor" href="#returns-2" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>List[float]: Learning rates for each parameter group. Must have the same length as param_groups.\n</code></pre><hr><h4 id="load-state-dict-self-state-dict-dict-str-typing-any-none-source-2" tabindex="-1"><code>load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-dict-str-typing-any-none-source-2" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64)&quot;">​</a></h4><p>Loads the scheduler state.</p><h4 id="args-7" tabindex="-1">Args <a class="header-anchor" href="#args-7" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): Scheduler state. Should be an object returned from a call to <code>state_dict</code>.</li></ul><h4 id="raises-7" tabindex="-1">Raises <a class="header-anchor" href="#raises-7" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the number of base_lrs in state_dict does not match the current optimizer&#39;s param_groups.</li></ul><hr><h4 id="state-dict-self-dict-str-typing-any-source-2" tabindex="-1"><code>state_dict(self) -&gt; dict[str, typing.Any]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-dict-str-typing-any-source-2" aria-label="Permalink to &quot;`state_dict(self) -&gt; dict[str, typing.Any]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56)&quot;">​</a></h4><p>Returns the state of the scheduler as a dict.</p><p>Includes all attributes except &#39;optimizer&#39; to avoid circular references.</p><hr><h4 id="step-self-epoch-optional-int-none-none-source-2" tabindex="-1"><code>step(self, epoch: Optional[int] = None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-epoch-optional-int-none-none-source-2" aria-label="Permalink to &quot;`step(self, epoch: Optional[int] = None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104)&quot;">​</a></h4><p>Step the scheduler to update learning rates.</p><h4 id="args-8" tabindex="-1">Args <a class="header-anchor" href="#args-8" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>epoch</strong> (<code>Optional[int]</code>): The epoch index to set. If None, increment last_epoch by 1.</li></ul><h4 id="raises-8" tabindex="-1">Raises <a class="header-anchor" href="#raises-8" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If epoch is a non-integer or negative value, or less than current last_epoch.</li></ul><hr></details><h3 id="class-optimizer-source" tabindex="-1"><code>class Optimizer</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L5" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-optimizer-source" aria-label="Permalink to &quot;`class Optimizer` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L5)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Optimizer(params, defaults)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Base class for optimizers.</p><h4 id="args-9" tabindex="-1">Args <a class="header-anchor" href="#args-9" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>params</strong> (<code>iterable</code>): an iterable of <code>Tensor</code> s or <code>dict</code> s. Specifies what Tensors should be optimized.</li><li><strong>defaults</strong>: (dict): a dict containing default values of optimization options (used when a parameter group doesn&#39;t specify them).</li></ul><details><summary>Methods</summary><h4 id="init-self-params-defaults-source" tabindex="-1"><code>__init__(self, params, defaults)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L16" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-params-defaults-source" aria-label="Permalink to &quot;`__init__(self, params, defaults)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L16)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="add-param-group-self-param-group-source" tabindex="-1"><code>add_param_group(self, param_group)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L29" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#add-param-group-self-param-group-source" aria-label="Permalink to &quot;`add_param_group(self, param_group)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L29)&quot;">​</a></h4><hr><h4 id="load-state-dict-self-state-dict-source" tabindex="-1"><code>load_state_dict(self, state_dict)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L110" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-source" aria-label="Permalink to &quot;`load_state_dict(self, state_dict)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L110)&quot;">​</a></h4><hr><h4 id="state-dict-self-source" tabindex="-1"><code>state_dict(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L80" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-source" aria-label="Permalink to &quot;`state_dict(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L80)&quot;">​</a></h4><hr><h4 id="step-self-closure-none-source" tabindex="-1"><code>step(self, closure=None)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L77" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-closure-none-source" aria-label="Permalink to &quot;`step(self, closure=None)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L77)&quot;">​</a></h4><hr><h4 id="zero-grad-self-set-to-none-false-source" tabindex="-1"><code>zero_grad(self, set_to_none=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#zero-grad-self-set-to-none-false-source" aria-label="Permalink to &quot;`zero_grad(self, set_to_none=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L64)&quot;">​</a></h4><hr></details><h3 id="class-reducelronplateau-source" tabindex="-1"><code>class ReduceLROnPlateau</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L251" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-reducelronplateau-source" aria-label="Permalink to &quot;`class ReduceLROnPlateau` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L251)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ReduceLROnPlateau(optimizer, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;min&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">factor</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">patience</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0001</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">threshold_mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;rel&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">cooldown</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">min_lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-08</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Base class for reducing learning rate when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This scheduler reads a metrics quantity and if no improvement is seen for a &#39;patience&#39; number of epochs, the learning rate is reduced.</p><details><summary>Methods</summary><h4 id="init-self-optimizer-mode-min-factor-0-1-patience-10-threshold-0-0001-threshold-mode-rel-cooldown-0-min-lr-0-eps-1e-08-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, mode=&#39;min&#39;, factor=0.1, patience=10, threshold=0.0001, threshold_mode=&#39;rel&#39;, cooldown=0, min_lr=0, eps=1e-08, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L260" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-mode-min-factor-0-1-patience-10-threshold-0-0001-threshold-mode-rel-cooldown-0-min-lr-0-eps-1e-08-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, mode=&#39;min&#39;, factor=0.1, patience=10, threshold=0.0001, threshold_mode=&#39;rel&#39;, cooldown=0, min_lr=0, eps=1e-08, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L260)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="is-better-self-a-best-source" tabindex="-1"><code>is_better(self, a, best)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L341" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#is-better-self-a-best-source" aria-label="Permalink to &quot;`is_better(self, a, best)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L341)&quot;">​</a></h4><hr><h4 id="load-state-dict-self-state-dict-source-1" tabindex="-1"><code>load_state_dict(self, state_dict)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L374" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-source-1" aria-label="Permalink to &quot;`load_state_dict(self, state_dict)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L374)&quot;">​</a></h4><hr><h4 id="state-dict-self-source-1" tabindex="-1"><code>state_dict(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L371" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-source-1" aria-label="Permalink to &quot;`state_dict(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L371)&quot;">​</a></h4><hr><h4 id="step-self-metrics-epoch-none-source" tabindex="-1"><code>step(self, metrics, epoch=None)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L304" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-metrics-epoch-none-source" aria-label="Permalink to &quot;`step(self, metrics, epoch=None)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L304)&quot;">​</a></h4><hr></details><h3 id="class-steplr-source" tabindex="-1"><code>class StepLR</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L143" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-steplr-source" aria-label="Permalink to &quot;`class StepLR` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L143)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">StepLR(optimizer, step_size, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">gamma</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">last_epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_LRScheduler</code></p><p>Set the learning rate of each parameter group to the initial lr decayed by gamma every step_size epochs. When last_epoch=-1, sets initial lr as lr.</p><h4 id="args-10" tabindex="-1">Args <a class="header-anchor" href="#args-10" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>optimizer</strong> (<code>Optimizer</code>): Wrapped optimizer.</li><li><strong>step_size</strong> (<code>int</code>): Period of learning rate decay.</li><li><strong>gamma</strong> (<code>float</code>): Multiplicative factor of learning rate decay.</li><li><strong>Default</strong>: 0.1.</li><li><strong>last_epoch</strong> (<code>int</code>): The index of last epoch. Default: -1.</li><li><strong>verbose</strong> (<code>bool</code>): If <code>True</code>, prints a message to stdout for each update. Default: <code>False</code>.</li></ul><details><summary>Methods</summary><h4 id="init-self-optimizer-step-size-gamma-0-1-last-epoch-1-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, step_size, gamma=0.1, last_epoch=-1, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L158" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-step-size-gamma-0-1-last-epoch-1-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, step_size, gamma=0.1, last_epoch=-1, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L158)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="get-last-lr-self-list-float-source-3" tabindex="-1"><code>get_last_lr(self) -&gt; List[float]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-last-lr-self-list-float-source-3" aria-label="Permalink to &quot;`get_last_lr(self) -&gt; List[float]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93)&quot;">​</a></h4><p>Return last computed learning rates by the scheduler.</p><h4 id="raises-9" tabindex="-1">Raises <a class="header-anchor" href="#raises-9" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>RuntimeError</strong>: If the scheduler has not stepped yet.</li></ul><hr><h4 id="get-lr-self-source-3" tabindex="-1"><code>get_lr(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L163" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-lr-self-source-3" aria-label="Permalink to &quot;`get_lr(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L163)&quot;">​</a></h4><p>Compute the learning rate for the current epoch.</p><h4 id="returns-3" tabindex="-1">Returns <a class="header-anchor" href="#returns-3" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>List[float]: Learning rates for each parameter group. Must have the same length as param_groups.\n</code></pre><hr><h4 id="load-state-dict-self-state-dict-dict-str-typing-any-none-source-3" tabindex="-1"><code>load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-dict-str-typing-any-none-source-3" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64)&quot;">​</a></h4><p>Loads the scheduler state.</p><h4 id="args-11" tabindex="-1">Args <a class="header-anchor" href="#args-11" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): Scheduler state. Should be an object returned from a call to <code>state_dict</code>.</li></ul><h4 id="raises-10" tabindex="-1">Raises <a class="header-anchor" href="#raises-10" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the number of base_lrs in state_dict does not match the current optimizer&#39;s param_groups.</li></ul><hr><h4 id="state-dict-self-dict-str-typing-any-source-3" tabindex="-1"><code>state_dict(self) -&gt; dict[str, typing.Any]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-dict-str-typing-any-source-3" aria-label="Permalink to &quot;`state_dict(self) -&gt; dict[str, typing.Any]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56)&quot;">​</a></h4><p>Returns the state of the scheduler as a dict.</p><p>Includes all attributes except &#39;optimizer&#39; to avoid circular references.</p><hr><h4 id="step-self-epoch-optional-int-none-none-source-3" tabindex="-1"><code>step(self, epoch: Optional[int] = None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-epoch-optional-int-none-none-source-3" aria-label="Permalink to &quot;`step(self, epoch: Optional[int] = None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104)&quot;">​</a></h4><p>Step the scheduler to update learning rates.</p><h4 id="args-12" tabindex="-1">Args <a class="header-anchor" href="#args-12" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>epoch</strong> (<code>Optional[int]</code>): The epoch index to set. If None, increment last_epoch by 1.</li></ul><h4 id="raises-11" tabindex="-1">Raises <a class="header-anchor" href="#raises-11" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If epoch is a non-integer or negative value, or less than current last_epoch.</li></ul><hr></details>',34))])}const _=l(i,[["render",d]]);export{k as __pageData,_ as default};

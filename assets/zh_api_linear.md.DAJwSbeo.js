import{_ as e,c as s,o as a,ah as t,j as i,a as n}from"./chunks/framework.DJtYh1Hc.js";const l=JSON.parse('{"title":"tensorplay.nn.modules.linear","description":"","frontmatter":{},"headers":[],"relativePath":"zh/api/linear.md","filePath":"zh/api/linear.md"}'),o={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},r={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.651ex"},xmlns:"http://www.w3.org/2000/svg",width:"14.449ex",height:"2.556ex",role:"img",focusable:"false",viewBox:"0 -841.7 6386.4 1129.6","aria-hidden":"true"},h={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},p={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"8.099ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 3579.9 1000","aria-hidden":"true"},d={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},k={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.339ex"},xmlns:"http://www.w3.org/2000/svg",width:"19.117ex",height:"1.934ex",role:"img",focusable:"false",viewBox:"0 -705 8449.8 855","aria-hidden":"true"},c={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},u={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0.079ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.131ex",height:"0.973ex",role:"img",focusable:"false",viewBox:"0 -465 500 430","aria-hidden":"true"},g={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},m={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"8.099ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 3579.9 1000","aria-hidden":"true"},T={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},b={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.339ex"},xmlns:"http://www.w3.org/2000/svg",width:"19.117ex",height:"1.934ex",role:"img",focusable:"false",viewBox:"0 -705 8449.8 855","aria-hidden":"true"},y={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},Q={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"8.277ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 3658.4 1000","aria-hidden":"true"},f={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},E={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"19.546ex",height:"1.952ex",role:"img",focusable:"false",viewBox:"0 -705 8639.3 862.8","aria-hidden":"true"},F={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},w={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"39.718ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 17555.3 1000","aria-hidden":"true"},_={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},x={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.298ex",height:"2.758ex",role:"img",focusable:"false",viewBox:"0 -969 5435.7 1219","aria-hidden":"true"},H={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},v={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.88ex"},xmlns:"http://www.w3.org/2000/svg",width:"13.605ex",height:"2.837ex",role:"img",focusable:"false",viewBox:"0 -864.9 6013.2 1253.8","aria-hidden":"true"},C={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},V={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"13.91ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 6148 1000","aria-hidden":"true"},A={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},L={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.298ex",height:"2.758ex",role:"img",focusable:"false",viewBox:"0 -969 5435.7 1219","aria-hidden":"true"},B={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},q={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.88ex"},xmlns:"http://www.w3.org/2000/svg",width:"13.605ex",height:"2.837ex",role:"img",focusable:"false",viewBox:"0 -864.9 6013.2 1253.8","aria-hidden":"true"},M={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},D={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.891ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 1278 1000","aria-hidden":"true"},P={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},Z={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0.079ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.131ex",height:"0.973ex",role:"img",focusable:"false",viewBox:"0 -465 500 430","aria-hidden":"true"},R={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},N={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.891ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 1278 1000","aria-hidden":"true"},S={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},I={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.464ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.167ex",height:"2.368ex",role:"img",focusable:"false",viewBox:"0 -841.7 5377.8 1046.7","aria-hidden":"true"},j={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},O={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"7.3ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 3226.4 1000","aria-hidden":"true"},z={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},U={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0.079ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.131ex",height:"0.973ex",role:"img",focusable:"false",viewBox:"0 -465 500 430","aria-hidden":"true"},Y={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},G={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.339ex"},xmlns:"http://www.w3.org/2000/svg",width:"17.186ex",height:"1.934ex",role:"img",focusable:"false",viewBox:"0 -705 7596.3 855","aria-hidden":"true"},J={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},K={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"8.277ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 3658.4 1000","aria-hidden":"true"},W={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},X={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"19.546ex",height:"1.952ex",role:"img",focusable:"false",viewBox:"0 -705 8639.3 862.8","aria-hidden":"true"},$={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},ee={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"25.683ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 11351.7 1000","aria-hidden":"true"},se={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},ae={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.298ex",height:"2.758ex",role:"img",focusable:"false",viewBox:"0 -969 5435.7 1219","aria-hidden":"true"},te={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},ie={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.88ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.805ex",height:"2.837ex",role:"img",focusable:"false",viewBox:"0 -864.9 5659.7 1253.8","aria-hidden":"true"},ne={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},le={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"13.91ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 6148 1000","aria-hidden":"true"},oe={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},re={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.298ex",height:"2.758ex",role:"img",focusable:"false",viewBox:"0 -969 5435.7 1219","aria-hidden":"true"},he={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},pe={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.88ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.805ex",height:"2.837ex",role:"img",focusable:"false",viewBox:"0 -864.9 5659.7 1253.8","aria-hidden":"true"};const de=e({name:"zh/api/linear.md"},[["render",function(e,l,de,ke,ce,ue){return a(),s("div",null,[l[108]||(l[108]=t('<h1 id="tensorplay-nn-modules-linear" tabindex="-1">tensorplay.nn.modules.linear <a class="header-anchor" href="#tensorplay-nn-modules-linear" aria-label="Permalink to &quot;tensorplay.nn.modules.linear&quot;">​</a></h1><h2 id="classes" tabindex="-1">Classes <a class="header-anchor" href="#classes" aria-label="Permalink to &quot;Classes&quot;">​</a></h2><h3 id="class-bilinear-source" tabindex="-1"><code>class Bilinear</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L136" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-bilinear-source" aria-label="Permalink to &quot;`class Bilinear` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L136)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Bilinear(in1_features: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, in2_features: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, out_features: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, bias: </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">device</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>Module</code></p>',5)),i("p",null,[l[2]||(l[2]=n("对传入数据应用双线性变换：",-1)),i("mjx-container",o,[(a(),s("svg",r,[...l[0]||(l[0]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="msubsup" transform="translate(1823.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(605,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(605,-287.9) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(2976.4,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(3726.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(4957.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(5957.4,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[1]||(l[1]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mi",null,"y"),i("mo",null,"="),i("msubsup",null,[i("mi",null,"x"),i("mn",null,"1"),i("mi",null,"T")]),i("mi",null,"A"),i("msub",null,[i("mi",null,"x"),i("mn",null,"2")]),i("mo",null,"+"),i("mi",null,"b")])],-1))]),l[3]||(l[3]=n("。",-1))]),l[109]||(l[109]=t('<h4 id="args" tabindex="-1">Args <a class="header-anchor" href="#args" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>in1_features</strong>: 每个第一输入样本的大小，必须 &gt; 0</li><li><strong>in2_features</strong>: 每个第二输入样本的大小，必须 &gt; 0</li><li><strong>out_features</strong>: 每个输出样本的大小，必须 &gt; 0</li><li><strong>bias</strong>: 如果设置为 <code>False</code>，该层将不会学习加性偏置。</li><li><strong>Default</strong>: <code>True</code></li></ul><h4 id="shape" tabindex="-1">Shape <a class="header-anchor" href="#shape" aria-label="Permalink to &quot;Shape&quot;">​</a></h4>',3)),i("ul",null,[i("li",null,[l[10]||(l[10]=n("输入1： ",-1)),i("mjx-container",h,[(a(),s("svg",p,[...l[4]||(l[4]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1333.7,0)"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(834,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3190.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[5]||(l[5]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mo",null,"∗"),i("mo",null,","),i("msub",null,[i("mi",null,"H"),i("mtext",null,"in1")]),i("mo",{stretchy:"false"},")")])],-1))]),l[11]||(l[11]=n(" where ",-1)),i("mjx-container",d,[(a(),s("svg",k,[...l[6]||(l[6]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(834,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2135.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(3190.8,0)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1834,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2140,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3084,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3473,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4029,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4421,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4865,0)" style="stroke-width:3;"></path></g></g></g>',1)])])),l[7]||(l[7]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("msub",null,[i("mi",null,"H"),i("mtext",null,"in1")]),i("mo",null,"="),i("mtext",null,"in1_features")])],-1))]),l[12]||(l[12]=n(" and ",-1)),i("mjx-container",c,[(a(),s("svg",u,[...l[8]||(l[8]=[i("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[i("g",{"data-mml-node":"math"},[i("g",{"data-mml-node":"mo"},[i("path",{"data-c":"2217",d:"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z",style:{"stroke-width":"3"}})])])],-1)])])),l[9]||(l[9]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",null,"∗")])],-1))]),l[13]||(l[13]=n(" means any number of additional dimensions including none. All but the last dimension 输入的所有维度都应相同。",-1))]),i("li",null,[l[18]||(l[18]=n("输入2： ",-1)),i("mjx-container",g,[(a(),s("svg",m,[...l[14]||(l[14]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1333.7,0)"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(834,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3190.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[15]||(l[15]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mo",null,"∗"),i("mo",null,","),i("msub",null,[i("mi",null,"H"),i("mtext",null,"in2")]),i("mo",{stretchy:"false"},")")])],-1))]),l[19]||(l[19]=n(" where ",-1)),i("mjx-container",T,[(a(),s("svg",b,[...l[16]||(l[16]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(834,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2135.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(3190.8,0)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1834,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2140,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3084,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3473,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4029,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4421,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4865,0)" style="stroke-width:3;"></path></g></g></g>',1)])])),l[17]||(l[17]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("msub",null,[i("mi",null,"H"),i("mtext",null,"in2")]),i("mo",null,"="),i("mtext",null,"in2_features")])],-1))]),l[20]||(l[20]=n(".",-1))]),i("li",null,[l[25]||(l[25]=n("输出： ",-1)),i("mjx-container",y,[(a(),s("svg",Q,[...l[21]||(l[21]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1333.7,0)"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3269.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[22]||(l[22]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mo",null,"∗"),i("mo",null,","),i("msub",null,[i("mi",null,"H"),i("mtext",null,"out")]),i("mo",{stretchy:"false"},")")])],-1))]),l[26]||(l[26]=n(" where ",-1)),i("mjx-container",f,[(a(),s("svg",E,[...l[23]||(l[23]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2213.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(3269.3,0)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1945,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2251,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2695,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3195,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3584,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4140,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4532,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4976,0)" style="stroke-width:3;"></path></g></g></g>',1)])])),l[24]||(l[24]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("msub",null,[i("mi",null,"H"),i("mtext",null,"out")]),i("mo",null,"="),i("mtext",null,"out_features")])],-1))]),l[27]||(l[27]=n(" 并且除了最后一个维度外，所有维度的形状都与输入相同。",-1))])]),l[110]||(l[110]=i("h4",{id:"attributes",tabindex:"-1"},[n("Attributes "),i("a",{class:"header-anchor",href:"#attributes","aria-label":'Permalink to "Attributes"'},"​")],-1)),i("ul",null,[i("li",null,[l[34]||(l[34]=i("strong",null,"weight",-1)),l[35]||(l[35]=n(": 形状为 ... 的模块的可学习权重 ",-1)),i("mjx-container",F,[(a(),s("svg",w,[...l[28]||(l[28]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(389,0)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1945,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2251,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2695,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3195,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3584,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4140,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4532,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4976,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5759,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(6203.7,0)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1834,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2140,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3084,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3473,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4029,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4421,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4865,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(11462.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(11907.3,0)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1834,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2140,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3084,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3473,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4029,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4421,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4865,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(17166.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[29]||(l[29]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mtext",null,"out_features"),i("mo",null,","),i("mtext",null,"in1_features"),i("mo",null,","),i("mtext",null,"in2_features"),i("mo",{stretchy:"false"},")")])],-1))]),l[36]||(l[36]=n(". The values are initialized from ",-1)),i("mjx-container",_,[(a(),s("svg",x,[...l[30]||(l[30]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="55" d="M8 592Q8 616 70 649T193 683Q246 683 246 631Q246 587 205 492T124 297T83 143Q83 101 100 75T154 48Q202 48 287 135T450 342T560 553Q589 635 593 640Q603 656 626 668T669 683H670Q687 683 687 672T670 616T617 463T547 220Q525 137 521 68Q521 54 522 50T533 42L543 47Q573 61 588 61Q604 61 604 47Q599 16 506 -22Q486 -28 468 -28T436 -18T421 18Q421 92 468 258Q468 259 467 257T459 248Q426 206 391 167T303 81T194 6T83 -22Q66 -22 58 -20Q25 -11 4 19T-17 99Q-17 146 8 220T64 358T120 488T146 586Q146 604 141 608T123 613H120Q99 613 72 597T25 580Q8 580 8 592Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1076,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msqrt" transform="translate(1854,0)"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z" style="stroke-width:3;"></path></g><rect width="521" height="60" x="853" y="849"></rect></g><g data-mml-node="mo" transform="translate(3228,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msqrt" transform="translate(3672.7,0)"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z" style="stroke-width:3;"></path></g><rect width="521" height="60" x="853" y="849"></rect></g><g data-mml-node="mo" transform="translate(5046.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[31]||(l[31]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mrow",{"data-mjx-texclass":"ORD"},[i("mi",{"data-mjx-variant":"-tex-calligraphic",mathvariant:"script"},"U")]),i("mo",{stretchy:"false"},"("),i("mo",null,"−"),i("msqrt",null,[i("mi",null,"k")]),i("mo",null,","),i("msqrt",null,[i("mi",null,"k")]),i("mo",{stretchy:"false"},")")])],-1))]),l[37]||(l[37]=n(", where ",-1)),i("mjx-container",H,[(a(),s("svg",v,[...l[32]||(l[32]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(798.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(1854.6,0)"><g data-mml-node="mn" transform="translate(1902.6,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(220,-345) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1834,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2140,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3084,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3473,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4029,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4421,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4865,0)" style="stroke-width:3;"></path></g><rect width="3918.7" height="60" x="120" y="220"></rect></g></g></g>',1)])])),l[33]||(l[33]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mi",null,"k"),i("mo",null,"="),i("mfrac",null,[i("mn",null,"1"),i("mtext",null,"in1_features")])])],-1))])]),i("li",null,[l[44]||(l[44]=i("strong",null,"bias",-1)),l[45]||(l[45]=n(": 形状为 ... 的模块的可学习偏置 ",-1)),i("mjx-container",C,[(a(),s("svg",V,[...l[38]||(l[38]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(389,0)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1945,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2251,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2695,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3195,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3584,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4140,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4532,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4976,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5759,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[39]||(l[39]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mtext",null,"out_features"),i("mo",{stretchy:"false"},")")])],-1))]),l[46]||(l[46]=n(". If ",-1)),l[47]||(l[47]=i("code",null,"bias",-1)),l[48]||(l[48]=n(" is ",-1)),l[49]||(l[49]=i("code",null,"True",-1)),l[50]||(l[50]=n(", the values are initialized from ",-1)),i("mjx-container",A,[(a(),s("svg",L,[...l[40]||(l[40]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="55" d="M8 592Q8 616 70 649T193 683Q246 683 246 631Q246 587 205 492T124 297T83 143Q83 101 100 75T154 48Q202 48 287 135T450 342T560 553Q589 635 593 640Q603 656 626 668T669 683H670Q687 683 687 672T670 616T617 463T547 220Q525 137 521 68Q521 54 522 50T533 42L543 47Q573 61 588 61Q604 61 604 47Q599 16 506 -22Q486 -28 468 -28T436 -18T421 18Q421 92 468 258Q468 259 467 257T459 248Q426 206 391 167T303 81T194 6T83 -22Q66 -22 58 -20Q25 -11 4 19T-17 99Q-17 146 8 220T64 358T120 488T146 586Q146 604 141 608T123 613H120Q99 613 72 597T25 580Q8 580 8 592Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1076,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msqrt" transform="translate(1854,0)"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z" style="stroke-width:3;"></path></g><rect width="521" height="60" x="853" y="849"></rect></g><g data-mml-node="mo" transform="translate(3228,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msqrt" transform="translate(3672.7,0)"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z" style="stroke-width:3;"></path></g><rect width="521" height="60" x="853" y="849"></rect></g><g data-mml-node="mo" transform="translate(5046.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[41]||(l[41]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mrow",{"data-mjx-texclass":"ORD"},[i("mi",{"data-mjx-variant":"-tex-calligraphic",mathvariant:"script"},"U")]),i("mo",{stretchy:"false"},"("),i("mo",null,"−"),i("msqrt",null,[i("mi",null,"k")]),i("mo",null,","),i("msqrt",null,[i("mi",null,"k")]),i("mo",{stretchy:"false"},")")])],-1))]),l[51]||(l[51]=n(", where ",-1)),i("mjx-container",B,[(a(),s("svg",q,[...l[42]||(l[42]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(798.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(1854.6,0)"><g data-mml-node="mn" transform="translate(1902.6,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(220,-345) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1834,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2140,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3084,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3473,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4029,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4421,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4865,0)" style="stroke-width:3;"></path></g><rect width="3918.7" height="60" x="120" y="220"></rect></g></g></g>',1)])])),l[43]||(l[43]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mi",null,"k"),i("mo",null,"="),i("mfrac",null,[i("mn",null,"1"),i("mtext",null,"in1_features")])])],-1))])])]),l[111]||(l[111]=t('<h4 id="examples" tabindex="-1">Examples <a class="header-anchor" href="#examples" aria-label="Permalink to &quot;Examples&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">m </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tp.nn.Bilinear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">30</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">40</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">input1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tp.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">input2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tp.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">30</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> m(input1, input2)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(output.size())</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.Size([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">40</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><details><summary>Methods</summary><h4 id="init-self-in1-features-int-in2-features-int-out-features-int-bias-bool-true-device-none-dtype-none-none-source" tabindex="-1"><code>__init__(self, in1_features: int, in2_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L180" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-in1-features-int-in2-features-int-out-features-int-bias-bool-true-device-none-dtype-none-none-source" aria-label="Permalink to &quot;`__init__(self, in1_features: int, in2_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L180)&quot;">​</a></h4><p>初始化内部 Module 状态，由 nn.Module 和 ScriptModule 共享。</p><hr><h4 id="add-module-self-name-str-module-optional-forwardref-module-none-source" tabindex="-1"><code>add_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L667" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#add-module-self-name-str-module-optional-forwardref-module-none-source" aria-label="Permalink to &quot;`add_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L667)&quot;">​</a></h4><p>将子模块添加到当前模块。</p><p>可以使用给定名称作为属性访问该模块。</p><h4 id="args-1" tabindex="-1">Args <a class="header-anchor" href="#args-1" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>name</strong> (<code>str</code>): 子模块的名称。可以使用给定名称 从该模块访问子模块</li><li><strong>module</strong> (<code>Module</code>): 要添加到模块的子模块。</li></ul><hr><h4 id="apply-self-fn-callable-forwardref-module-nonetype-self-source" tabindex="-1"><code>apply(self, fn: Callable[[ForwardRef(&#39;Module&#39;)], NoneType]) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L990" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#apply-self-fn-callable-forwardref-module-nonetype-self-source" aria-label="Permalink to &quot;`apply(self, fn: Callable[[ForwardRef(&#39;Module&#39;)], NoneType]) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L990)&quot;">​</a></h4><p>递归地将 <code>fn</code> 应用于每个子模块（由 <code>.children()</code> 返回）以及自身。</p><p>典型用途包括初始化模型的参数 (see also <code>nn-init-doc</code>).</p><h4 id="args-2" tabindex="-1">Args <a class="header-anchor" href="#args-2" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>fn</strong> (``Module<code> -&gt; None</code>): 应用于每个子模块的函数</li></ul><h4 id="returns" tabindex="-1">Returns <a class="header-anchor" href="#returns" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><h4 id="example" tabindex="-1">Example <a class="header-anchor" href="#example" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.no_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> init_weights</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m):</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        m.weight.fill_(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m.weight)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.apply(init_weights)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Sequential(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><hr><h4 id="bfloat16-self-self-source" tabindex="-1"><code>bfloat16(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1108" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#bfloat16-self-self-source" aria-label="Permalink to &quot;`bfloat16(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1108)&quot;">​</a></h4><p>将所有浮点参数和缓冲区转换为 <code>bfloat16</code> 数据类型。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-1" tabindex="-1">Returns <a class="header-anchor" href="#returns-1" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="buffers-self-recurse-bool-true-collections-abc-iterator-tensorplay-c-tensorbase-source" tabindex="-1"><code>buffers(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay._C.TensorBase]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2627" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#buffers-self-recurse-bool-true-collections-abc-iterator-tensorplay-c-tensorbase-source" aria-label="Permalink to &quot;`buffers(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay._C.TensorBase]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2627)&quot;">​</a></h4><p>返回模块缓冲区的迭代器。</p><h4 id="args-3" tabindex="-1">Args <a class="header-anchor" href="#args-3" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>recurse</strong> (<code>bool</code>): 如果为 True，则生成此模块的缓冲区 以及所有子模块的缓冲区。否则，仅生成 此模块的直接成员缓冲区。</li></ul><h4 id="yields" tabindex="-1">Yields <a class="header-anchor" href="#yields" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>tensorplay.Tensor: 模块缓冲区\n</code></pre><h4 id="example-1" tabindex="-1">Example <a class="header-anchor" href="#example-1" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> buf </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.buffers():</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(buf), buf.size())</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><hr><h4 id="children-self-collections-abc-iterator-module-source" tabindex="-1"><code>children(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2681" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#children-self-collections-abc-iterator-module-source" aria-label="Permalink to &quot;`children(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2681)&quot;">​</a></h4><p>返回直接子模块的迭代器。</p><h4 id="yields-1" tabindex="-1">Yields <a class="header-anchor" href="#yields-1" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><ul><li><strong>Module</strong>: 一个子模块</li></ul><hr><h4 id="compile-self-args-kwargs-source" tabindex="-1"><code>compile(self, *args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2944" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#compile-self-args-kwargs-source" aria-label="Permalink to &quot;`compile(self, *args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2944)&quot;">​</a></h4><p>使用 <code>tensorplay.compile</code> 编译此模块的前向传播。</p><p>此模块的 <code>__call__</code> 方法被编译，所有参数按原样传递 给 <code>tensorplay.compile</code>。</p><p>有关此函数的参数详情，请参阅 <code>tensorplay.compile</code>。</p><hr><h4 id="cpu-self-self-source" tabindex="-1"><code>cpu(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1050" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#cpu-self-self-source" aria-label="Permalink to &quot;`cpu(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1050)&quot;">​</a></h4><p>将所有模型参数和缓冲区移动到 CPU。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-2" tabindex="-1">Returns <a class="header-anchor" href="#returns-2" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="cuda-self-device-union-int-tensorplay-device-nonetype-none-self-source" tabindex="-1"><code>cuda(self, device: Union[int, tensorplay.Device, NoneType] = None) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1031" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#cuda-self-device-union-int-tensorplay-device-nonetype-none-self-source" aria-label="Permalink to &quot;`cuda(self, device: Union[int, tensorplay.Device, NoneType] = None) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1031)&quot;">​</a></h4><p>将所有模型参数和缓冲区移动到 GPU。</p><p>这也使得关联的参数和缓冲区成为不同的对象。所以 如果模块将在 GPU 上运行并进行优化， 应在构建优化器之前调用它。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="args-4" tabindex="-1">Args <a class="header-anchor" href="#args-4" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>device</strong> (<code>int, optional</code>): 如果指定，所有参数将被 复制到该设备</li></ul><h4 id="returns-3" tabindex="-1">Returns <a class="header-anchor" href="#returns-3" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="double-self-self-source" tabindex="-1"><code>double(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1086" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#double-self-self-source" aria-label="Permalink to &quot;`double(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1086)&quot;">​</a></h4><p>将所有浮点参数和缓冲区转换为 <code>double</code> 数据类型。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-4" tabindex="-1">Returns <a class="header-anchor" href="#returns-4" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="eval-self-self-source" tabindex="-1"><code>eval(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2808" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#eval-self-self-source" aria-label="Permalink to &quot;`eval(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2808)&quot;">​</a></h4><p>将模块设置为评估模式。</p><p>这仅对某些模块有影响。请参阅特定模块的文档 了解它们在训练/评估模式下的行为细节， 即它们是否受影响，例如 <code>Dropout</code>、<code>BatchNorm</code> 等。</p><p>这相当于 <code>self.train(False) &lt;tensorplay.nn.Module.train&gt;</code>。</p><p>有关 <code>.eval()</code> 和其他类似机制的比较， <code>.eval()</code> and several similar mechanisms that may be confused with it.</p><h4 id="returns-5" tabindex="-1">Returns <a class="header-anchor" href="#returns-5" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="extra-repr-self-str-source" tabindex="-1"><code>extra_repr(self) -&gt; str</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L221" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#extra-repr-self-str-source" aria-label="Permalink to &quot;`extra_repr(self) -&gt; str` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L221)&quot;">​</a></h4><p>返回模块的额外表示。</p><hr><h4 id="float-self-self-source" tabindex="-1"><code>float(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1075" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#float-self-self-source" aria-label="Permalink to &quot;`float(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1075)&quot;">​</a></h4><p>将所有浮点参数和缓冲区转换为 <code>float</code> 数据类型。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-6" tabindex="-1">Returns <a class="header-anchor" href="#returns-6" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="forward-self-input1-tensorplay-c-tensorbase-input2-tensorplay-c-tensorbase-tensorplay-c-tensorbase-source" tabindex="-1"><code>forward(self, input1: tensorplay._C.TensorBase, input2: tensorplay._C.TensorBase) -&gt; tensorplay._C.TensorBase</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L215" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#forward-self-input1-tensorplay-c-tensorbase-input2-tensorplay-c-tensorbase-tensorplay-c-tensorbase-source" aria-label="Permalink to &quot;`forward(self, input1: tensorplay._C.TensorBase, input2: tensorplay._C.TensorBase) -&gt; tensorplay._C.TensorBase` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L215)&quot;">​</a></h4><p>运行前向传播。</p><hr><h4 id="get-buffer-self-target-str-tensor-source" tabindex="-1"><code>get_buffer(self, target: str) -&gt; &#39;Tensor&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L881" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-buffer-self-target-str-tensor-source" aria-label="Permalink to &quot;`get_buffer(self, target: str) -&gt; &#39;Tensor&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L881)&quot;">​</a></h4><p>如果存在，则返回由 <code>target</code> 指定的缓冲区，否则抛出错误。</p><p>See the docstring for <code>get_submodule</code> for a more detailed explanation of this method&#39;s functionality as well as how to correctly specify <code>target</code>.</p><h4 id="args-5" tabindex="-1">Args <a class="header-anchor" href="#args-5" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: 缓冲区的完全限定字符串名称 to look for. (See <code>get_submodule</code> for how to specify a fully-qualified string.)</li></ul><h4 id="returns-7" tabindex="-1">Returns <a class="header-anchor" href="#returns-7" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>tensorplay.Tensor: 由 ``target`` 引用的缓冲区\n</code></pre><h4 id="raises" tabindex="-1">Raises <a class="header-anchor" href="#raises" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>AttributeError</strong>: If the target string references an invalid path or resolves to something that is not a buffer</li></ul><hr><h4 id="get-extra-state-self-any-source" tabindex="-1"><code>get_extra_state(self) -&gt; Any</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L917" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-extra-state-self-any-source" aria-label="Permalink to &quot;`get_extra_state(self) -&gt; Any` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L917)&quot;">​</a></h4><p>返回要包含在模块 state_dict 中的任何额外状态。</p><p>Implement this and a corresponding <code>set_extra_state</code> for your module if you need to store extra state. This function is called when building the module&#39;s <code>state_dict()</code>.</p><p>Note that extra state should be picklable to ensure working serialization of the state_dict. We only provide backwards compatibility guarantees for serializing Tensors; other objects may break backwards compatibility if their serialized pickled form changes.</p><h4 id="returns-8" tabindex="-1">Returns <a class="header-anchor" href="#returns-8" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>object</strong>: Any extra state to store in the module&#39;s state_dict</li></ul><hr><h4 id="get-parameter-self-target-str-parameter-source" tabindex="-1"><code>get_parameter(self, target: str) -&gt; &#39;Parameter&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L845" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-parameter-self-target-str-parameter-source" aria-label="Permalink to &quot;`get_parameter(self, target: str) -&gt; &#39;Parameter&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L845)&quot;">​</a></h4><p>如果存在，则返回由 <code>target</code> 指定的参数，否则抛出错误。</p><p>See the docstring for <code>get_submodule</code> for a more detailed explanation of this method&#39;s functionality as well as how to correctly specify <code>target</code>.</p><h4 id="args-6" tabindex="-1">Args <a class="header-anchor" href="#args-6" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: The fully-qualified string name of the Parameter to look for. (See <code>get_submodule</code> for how to specify a fully-qualified string.)</li></ul><h4 id="returns-9" tabindex="-1">Returns <a class="header-anchor" href="#returns-9" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>tensorplay.nn.Parameter: The Parameter referenced by ``target``\n</code></pre><h4 id="raises-1" tabindex="-1">Raises <a class="header-anchor" href="#raises-1" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>AttributeError</strong>: If the target string references an invalid path or resolves to something that is not an <code>nn.Parameter</code></li></ul><hr><h4 id="get-submodule-self-target-str-module-source" tabindex="-1"><code>get_submodule(self, target: str) -&gt; &#39;Module&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L699" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-submodule-self-target-str-module-source" aria-label="Permalink to &quot;`get_submodule(self, target: str) -&gt; &#39;Module&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L699)&quot;">​</a></h4><p>Return the submodule given by <code>target</code> if it exists, otherwise throw an error.</p><p>For example, let&#39;s say you have an <code>nn.Module</code> <code>A</code> that looks like this:</p><p>.. code-block:: text</p><ul><li><strong>A</strong> (<code> (net_b</code>): Module( (net_c): Module( (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2)) ) (linear): Linear(in_features=100, out_features=200, bias=True) ) )</li></ul><p>(The diagram shows an <code>nn.Module</code> <code>A</code>. <code>A</code> which has a nested submodule <code>net_b</code>, which itself has two submodules <code>net_c</code> and <code>linear</code>. <code>net_c</code> then has a submodule <code>conv</code>.)</p><p>To check whether or not we have the <code>linear</code> submodule, we would call <code>get_submodule(&quot;net_b.linear&quot;)</code>. To check whether we have the <code>conv</code> submodule, we would call <code>get_submodule(&quot;net_b.net_c.conv&quot;)</code>.</p><p>The runtime of <code>get_submodule</code> is bounded by the degree of module nesting in <code>target</code>. A query against <code>named_modules</code> achieves the same result, but it is O(N) in the number of transitive modules. So, for a simple check to see if some submodule exists, <code>get_submodule</code> should always be used.</p><h4 id="args-7" tabindex="-1">Args <a class="header-anchor" href="#args-7" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: The fully-qualified string name of the submodule to look for. (See above example for how to specify a fully-qualified string.)</li></ul><h4 id="returns-10" tabindex="-1">Returns <a class="header-anchor" href="#returns-10" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>tensorplay.nn.Module: The submodule referenced by ``target``\n</code></pre><h4 id="raises-2" tabindex="-1">Raises <a class="header-anchor" href="#raises-2" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>AttributeError</strong>: If at any point along the path resulting from the target string the (sub)path resolves to a non-existent attribute name or an object that is not an instance of <code>nn.Module</code>.</li></ul><hr><h4 id="half-self-self-source" tabindex="-1"><code>half(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1097" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#half-self-self-source" aria-label="Permalink to &quot;`half(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1097)&quot;">​</a></h4><p>Casts all floating point parameters and buffers to <code>half</code> datatype.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-11" tabindex="-1">Returns <a class="header-anchor" href="#returns-11" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="load-state-dict-self-state-dict-collections-abc-mapping-str-typing-any-strict-bool-true-assign-bool-false-source" tabindex="-1"><code>load_state_dict(self, state_dict: collections.abc.Mapping[str, typing.Any], strict: bool = True, assign: bool = False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2436" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-collections-abc-mapping-str-typing-any-strict-bool-true-assign-bool-false-source" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: collections.abc.Mapping[str, typing.Any], strict: bool = True, assign: bool = False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2436)&quot;">​</a></h4><p>Copy parameters and buffers from <code>state_dict</code> into this module and its descendants.</p><p>If <code>strict</code> is <code>True</code>, then the keys of <code>state_dict</code> must exactly match the keys returned by this module&#39;s <code>~tensorplay.nn.Module.state_dict</code> function.</p><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>If <code>assign</code> is <code>True</code> the optimizer must be created after the call to <code>load_state_dict</code> unless <code>~tensorplay.__future__.get_swap_module_params_on_conversion</code> is <code>True</code>.</p></div><h4 id="args-8" tabindex="-1">Args <a class="header-anchor" href="#args-8" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): a dict containing parameters and persistent buffers.</li><li><strong>strict</strong> (<code>bool, optional</code>): whether to strictly enforce that the keys in <code>state_dict</code> match the keys returned by this module&#39;s <code>~tensorplay.nn.Module.state_dict</code> function. 默认值： <code>True</code></li><li><strong>assign</strong> (<code>bool, optional</code>): When set to <code>False</code>, the properties of the tensors in the current module are preserved whereas setting it to <code>True</code> preserves properties of the Tensors in the state dict. The only exception is the <code>requires_grad</code> field of <code>~tensorplay.nn.Parameter</code> for which the value from the module is preserved. 默认值： <code>False</code></li></ul><h4 id="returns-12" tabindex="-1">Returns <a class="header-anchor" href="#returns-12" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n    * ``missing_keys`` is a list of str containing any keys that are expected\n        by this module but missing from the provided ``state_dict``.\n    * ``unexpected_keys`` is a list of str containing the keys that are not\n        expected by this module but present in the provided ``state_dict``.\n</code></pre><h4 id="note" tabindex="-1">Note <a class="header-anchor" href="#note" aria-label="Permalink to &quot;Note&quot;">​</a></h4><pre><code>If a parameter or buffer is registered as ``None`` and its corresponding key\nexists in `state_dict`, `load_state_dict` will raise a\n``RuntimeError``.\n</code></pre><hr><h4 id="modules-self-collections-abc-iterator-module-source" tabindex="-1"><code>modules(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2710" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#modules-self-collections-abc-iterator-module-source" aria-label="Permalink to &quot;`modules(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2710)&quot;">​</a></h4><p>Return an iterator over all modules in the network.</p><h4 id="yields-2" tabindex="-1">Yields <a class="header-anchor" href="#yields-2" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><ul><li><strong>Module</strong>: a module in the network</li></ul><h4 id="note-1" tabindex="-1">Note <a class="header-anchor" href="#note-1" aria-label="Permalink to &quot;Note&quot;">​</a></h4><pre><code>Duplicate modules are returned only once. In the following\nexample, ``l`` will be returned only once.\n</code></pre><h4 id="example-2" tabindex="-1">Example <a class="header-anchor" href="#example-2" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(l, l)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx, m </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(net.modules()):</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(idx, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;-&gt;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, m)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Sequential(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><hr><h4 id="named-buffers-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-c-tensorbase-source" tabindex="-1"><code>named_buffers(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay._C.TensorBase]]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2650" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-buffers-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-c-tensorbase-source" aria-label="Permalink to &quot;`named_buffers(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay._C.TensorBase]]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2650)&quot;">​</a></h4><p>Return an iterator over 模块缓冲区s, yielding both the name of the buffer as well as the buffer itself.</p><h4 id="args-9" tabindex="-1">Args <a class="header-anchor" href="#args-9" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>prefix</strong> (<code>str</code>): prefix to prepend to all buffer names.</li><li><strong>recurse</strong> (<code>bool, optional</code>): 如果为 True，则生成此模块的缓冲区 以及所有子模块的缓冲区。否则，仅生成 此模块的直接成员缓冲区。 Defaults to True.</li><li><strong>remove_duplicate</strong> (<code>bool, optional</code>): whether to remove the duplicated buffers in the result. Defaults to True.</li></ul><h4 id="yields-3" tabindex="-1">Yields <a class="header-anchor" href="#yields-3" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, tensorplay.Tensor): Tuple containing the name and buffer\n</code></pre><h4 id="example-3" tabindex="-1">Example <a class="header-anchor" href="#example-3" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, buf </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.named_buffers():</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;running_var&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(buf.size())</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h4 id="named-children-self-collections-abc-iterator-tuple-str-module-source" tabindex="-1"><code>named_children(self) -&gt; collections.abc.Iterator[tuple[str, &#39;Module&#39;]]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2690" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-children-self-collections-abc-iterator-tuple-str-module-source" aria-label="Permalink to &quot;`named_children(self) -&gt; collections.abc.Iterator[tuple[str, &#39;Module&#39;]]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2690)&quot;">​</a></h4><p>Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p><h4 id="yields-4" tabindex="-1">Yields <a class="header-anchor" href="#yields-4" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, Module): Tuple containing a name and child module\n</code></pre><h4 id="example-4" tabindex="-1">Example <a class="header-anchor" href="#example-4" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, module </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.named_children():</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;conv4&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;conv5&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(module)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h4 id="named-modules-self-memo-optional-set-module-none-prefix-str-remove-duplicate-bool-true-source" tabindex="-1"><code>named_modules(self, memo: Optional[set[&#39;Module&#39;]] = None, prefix: str = &#39;&#39;, remove_duplicate: bool = True)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2737" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-modules-self-memo-optional-set-module-none-prefix-str-remove-duplicate-bool-true-source" aria-label="Permalink to &quot;`named_modules(self, memo: Optional[set[&#39;Module&#39;]] = None, prefix: str = &#39;&#39;, remove_duplicate: bool = True)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2737)&quot;">​</a></h4><p>Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p><h4 id="args-10" tabindex="-1">Args <a class="header-anchor" href="#args-10" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>memo</strong>: a memo to store the set of modules already added to the result</li><li><strong>prefix</strong>: a prefix that will be added to the name of the module</li><li><strong>remove_duplicate</strong>: whether to remove the duplicated module instances in the result or not</li></ul><h4 id="yields-5" tabindex="-1">Yields <a class="header-anchor" href="#yields-5" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, Module): Tuple of name and module\n</code></pre><h4 id="note-2" tabindex="-1">Note <a class="header-anchor" href="#note-2" aria-label="Permalink to &quot;Note&quot;">​</a></h4><pre><code>Duplicate modules are returned only once. In the following\nexample, ``l`` will be returned only once.\n</code></pre><h4 id="example-5" tabindex="-1">Example <a class="header-anchor" href="#example-5" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(l, l)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx, m </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(net.named_modules()):</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(idx, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;-&gt;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, m)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Sequential(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;0&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><hr><h4 id="named-parameters-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-nn-parameter-parameter-source" tabindex="-1"><code>named_parameters(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay.nn.parameter.Parameter]]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2595" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-parameters-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-nn-parameter-parameter-source" aria-label="Permalink to &quot;`named_parameters(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay.nn.parameter.Parameter]]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2595)&quot;">​</a></h4><p>Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p><h4 id="args-11" tabindex="-1">Args <a class="header-anchor" href="#args-11" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>prefix</strong> (<code>str</code>): prefix to prepend to all parameter names.</li><li><strong>recurse</strong> (<code>bool</code>): if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that 此模块的直接成员缓冲区。</li><li><strong>remove_duplicate</strong> (<code>bool, optional</code>): whether to remove the duplicated parameters in the result. Defaults to True.</li></ul><h4 id="yields-6" tabindex="-1">Yields <a class="header-anchor" href="#yields-6" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, Parameter): Tuple containing the name and parameter\n</code></pre><h4 id="example-6" tabindex="-1">Example <a class="header-anchor" href="#example-6" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.named_parameters():</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;bias&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(param.size())</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h4 id="parameters-self-recurse-bool-true-collections-abc-iterator-tensorplay-nn-parameter-parameter-source" tabindex="-1"><code>parameters(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay.nn.parameter.Parameter]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2570" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#parameters-self-recurse-bool-true-collections-abc-iterator-tensorplay-nn-parameter-parameter-source" aria-label="Permalink to &quot;`parameters(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay.nn.parameter.Parameter]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2570)&quot;">​</a></h4><p>Return an iterator over module parameters.</p><p>This is typically passed to an optimizer.</p><h4 id="args-12" tabindex="-1">Args <a class="header-anchor" href="#args-12" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>recurse</strong> (<code>bool</code>): if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that 此模块的直接成员缓冲区。</li></ul><h4 id="yields-7" tabindex="-1">Yields <a class="header-anchor" href="#yields-7" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><ul><li><strong>Parameter</strong>: module parameter</li></ul><h4 id="example-7" tabindex="-1">Example <a class="header-anchor" href="#example-7" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.parameters():</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(param), param.size())</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><hr><h4 id="register-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-tensorplay-utils-hooks-removablehandle-source" tabindex="-1"><code>register_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]]) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1336" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-tensorplay-utils-hooks-removablehandle-source" aria-label="Permalink to &quot;`register_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]]) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1336)&quot;">​</a></h4><p>Register a backward hook on the module.</p><p>This function is deprecated in favor of <code>~tensorplay.nn.Module.register_full_backward_hook</code> and the behavior of this function will change in future versions.</p><h4 id="returns-13" tabindex="-1">Returns <a class="header-anchor" href="#returns-13" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-buffer-self-name-str-tensor-optional-tensorplay-c-tensorbase-persistent-bool-true-none-source" tabindex="-1"><code>register_buffer(self, name: str, tensor: Optional[tensorplay._C.TensorBase], persistent: bool = True) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L553" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-buffer-self-name-str-tensor-optional-tensorplay-c-tensorbase-persistent-bool-true-none-source" aria-label="Permalink to &quot;`register_buffer(self, name: str, tensor: Optional[tensorplay._C.TensorBase], persistent: bool = True) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L553)&quot;">​</a></h4><p>Add a buffer to the module.</p><p>This is typically used to register a buffer that should not be considered a model parameter. For example, BatchNorm&#39;s <code>running_mean</code> is not a parameter, but is part of the module&#39;s state. Buffers, by default, are persistent and will be saved alongside parameters. This behavior can be changed by setting <code>persistent</code> to <code>False</code>. The only difference between a persistent buffer and a non-persistent buffer is that the latter will not be a part of this module&#39;s <code>state_dict</code>.</p><p>Buffers can be accessed as attributes using given names.</p><h4 id="args-13" tabindex="-1">Args <a class="header-anchor" href="#args-13" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>name</strong> (<code>str</code>): name of the buffer. The buffer can be accessed from this module using the given name</li><li><strong>tensor</strong> (<code>Tensor or None</code>): buffer to be registered. If <code>None</code>, then operations that run on buffers, such as <code>cuda</code>, are ignored. If <code>None</code>, the buffer is <strong>not</strong> included in the module&#39;s <code>state_dict</code>.</li><li><strong>persistent</strong> (<code>bool</code>): whether the buffer is part of this module&#39;s <code>state_dict</code>.</li></ul><h4 id="example-8" tabindex="-1">Example <a class="header-anchor" href="#example-8" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.register_buffer(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;running_mean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, tensorplay.zeros(num_features))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><hr><h4 id="register-forward-hook-self-hook-union-callable-t-tuple-any-any-optional-any-callable-t-tuple-any-dict-str-any-any-optional-any-prepend-bool-false-with-kwargs-bool-false-always-call-bool-false-tensorplay-utils-hooks-removablehandle-source" tabindex="-1"><code>register_forward_hook(self, hook: Union[Callable[[~T, tuple[Any, ...], Any], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1592" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-forward-hook-self-hook-union-callable-t-tuple-any-any-optional-any-callable-t-tuple-any-dict-str-any-any-optional-any-prepend-bool-false-with-kwargs-bool-false-always-call-bool-false-tensorplay-utils-hooks-removablehandle-source" aria-label="Permalink to &quot;`register_forward_hook(self, hook: Union[Callable[[~T, tuple[Any, ...], Any], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1592)&quot;">​</a></h4><p>Register a forward hook on the module.</p><p>The hook will be called every time after <code>forward</code> has computed an output.</p><p>If <code>with_kwargs</code> is <code>False</code> or not specified, the input contains only the positional arguments given to the module. Keyword arguments won&#39;t be passed to the hooks and only to the <code>forward</code>. The hook can modify the output. It can modify the input inplace but it will not have effect on forward since this is called after <code>forward</code> is called. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args, output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> modified output</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>If <code>with_kwargs</code> is <code>True</code>, the forward hook will be passed the <code>kwargs</code> given to the forward function and be expected to return the output possibly modified. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args, kwargs, output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> modified output</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="args-14" tabindex="-1">Args <a class="header-anchor" href="#args-14" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If <code>True</code>, the provided <code>hook</code> will be fired before all existing <code>forward</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>forward</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>forward</code> hooks registered with <code>register_module_forward_hook</code> will fire before all hooks registered by this method.</li><li><strong>Default</strong>: <code>False</code></li><li><strong>with_kwargs</strong> (<code>bool</code>): If <code>True</code>, the <code>hook</code> will be passed the kwargs given to the forward function.</li><li><strong>Default</strong>: <code>False</code></li><li><strong>always_call</strong> (<code>bool</code>): If <code>True</code> the <code>hook</code> will be run regardless of whether an exception is raised while calling the Module.</li><li><strong>Default</strong>: <code>False</code></li></ul><h4 id="returns-14" tabindex="-1">Returns <a class="header-anchor" href="#returns-14" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-forward-pre-hook-self-hook-union-callable-t-tuple-any-optional-any-callable-t-tuple-any-dict-str-any-optional-tuple-any-dict-str-any-prepend-bool-false-with-kwargs-bool-false-tensorplay-utils-hooks-removablehandle-source" tabindex="-1"><code>register_forward_pre_hook(self, hook: Union[Callable[[~T, tuple[Any, ...]], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any]], Optional[tuple[Any, dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1526" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-forward-pre-hook-self-hook-union-callable-t-tuple-any-optional-any-callable-t-tuple-any-dict-str-any-optional-tuple-any-dict-str-any-prepend-bool-false-with-kwargs-bool-false-tensorplay-utils-hooks-removablehandle-source" aria-label="Permalink to &quot;`register_forward_pre_hook(self, hook: Union[Callable[[~T, tuple[Any, ...]], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any]], Optional[tuple[Any, dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1526)&quot;">​</a></h4><p>Register a forward pre-hook on the module.</p><p>The hook will be called every time before <code>forward</code> is invoked.</p><p>If <code>with_kwargs</code> is false or not specified, the input contains only the positional arguments given to the module. Keyword arguments won&#39;t be passed to the hooks and only to the <code>forward</code>. The hook can modify the input. User can either return a tuple or a single modified value in the hook. We will wrap the value into a tuple if a single value is returned (unless that value is already a tuple). The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> modified </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>If <code>with_kwargs</code> is true, the forward pre-hook will be passed the kwargs given to the forward function. And if the hook modifies the input, both the args and kwargs should be returned. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args, kwargs) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> of modified </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> kwargs</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="args-15" tabindex="-1">Args <a class="header-anchor" href="#args-15" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If true, the provided <code>hook</code> will be fired before all existing <code>forward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>forward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>forward_pre</code> hooks registered with <code>register_module_forward_pre_hook</code> will fire before all hooks registered by this method.</li><li><strong>Default</strong>: <code>False</code></li><li><strong>with_kwargs</strong> (<code>bool</code>): If true, the <code>hook</code> will be passed the kwargs given to the forward function.</li><li><strong>Default</strong>: <code>False</code></li></ul><h4 id="returns-15" tabindex="-1">Returns <a class="header-anchor" href="#returns-15" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-full-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source" tabindex="-1"><code>register_full_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1362" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-full-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source" aria-label="Permalink to &quot;`register_full_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1362)&quot;">​</a></h4><p>Register a backward hook on the module.</p><p>The hook will be called every time the gradients with respect to a module are computed, and its firing rules are as follows:</p><pre><code>1. Ordinarily, the hook fires when the gradients are computed with respect to the module inputs.\n2. If none of the module inputs require gradients, the hook will fire when the gradients are computed\n   with respect to module outputs.\n3. If none of the module outputs require gradients, then the hooks will not fire.\n</code></pre><p>The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, grad_input, grad_output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Tensor) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">or</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The <code>grad_input</code> and <code>grad_output</code> are tuples that contain the gradients with respect to the inputs and outputs respectively. The hook should not modify its arguments, but it can optionally return a new gradient with respect to the input that will be used in place of <code>grad_input</code> in subsequent computations. <code>grad_input</code> will only correspond to the inputs given as positional arguments and all kwarg arguments are ignored. Entries in <code>grad_input</code> and <code>grad_output</code> will be <code>None</code> for all non-Tensor arguments.</p><p>For technical reasons, when this hook is applied to a Module, its forward function will receive a view of each Tensor passed to the Module. Similarly the caller will receive a view of each Tensor returned by the Module&#39;s forward function.</p><p>.. warning</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Modifying inputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> outputs inplace </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> allowed when using backward hooks </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">will </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">raise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> an error.</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="args-16" tabindex="-1">Args <a class="header-anchor" href="#args-16" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user-defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If true, the provided <code>hook</code> will be fired before all existing <code>backward</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>backward</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>backward</code> hooks registered with <code>register_module_full_backward_hook</code> will fire before all hooks registered by this method.</li></ul><h4 id="returns-16" tabindex="-1">Returns <a class="header-anchor" href="#returns-16" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-full-backward-pre-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source" tabindex="-1"><code>register_full_backward_pre_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1287" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-full-backward-pre-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source" aria-label="Permalink to &quot;`register_full_backward_pre_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1287)&quot;">​</a></h4><p>Register a backward pre-hook on the module.</p><p>The hook will be called every time the gradients for the module are computed. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, grad_output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tuple[Tensor] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">or</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The <code>grad_output</code> is a tuple. The hook should not modify its arguments, but it can optionally return a new gradient with respect to the output that will be used in place of <code>grad_output</code> in subsequent computations. Entries in <code>grad_output</code> will be <code>None</code> for all non-Tensor arguments.</p><p>For technical reasons, when this hook is applied to a Module, its forward function will receive a view of each Tensor passed to the Module. Similarly the caller will receive a view of each Tensor returned by the Module&#39;s forward function.</p><p>.. warning</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Modifying inputs inplace </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> allowed when using backward hooks </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">will </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">raise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> an error.</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="args-17" tabindex="-1">Args <a class="header-anchor" href="#args-17" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user-defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If true, the provided <code>hook</code> will be fired before all existing <code>backward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>backward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>backward_pre</code> hooks registered with <code>register_module_full_backward_pre_hook</code> will fire before all hooks registered by this method.</li></ul><h4 id="returns-17" tabindex="-1">Returns <a class="header-anchor" href="#returns-17" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-load-state-dict-post-hook-self-hook-source" tabindex="-1"><code>register_load_state_dict_post_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2226" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-load-state-dict-post-hook-self-hook-source" aria-label="Permalink to &quot;`register_load_state_dict_post_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2226)&quot;">​</a></h4><p>Register a post-hook to be run after module&#39;s <code>~nn.Module.load_state_dict</code> is called.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, incompatible_keys) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The <code>module</code> argument is the current module that this hook is registered on, and the <code>incompatible_keys</code> argument is a <code>NamedTuple</code> consisting of attributes <code>missing_keys</code> and <code>unexpected_keys</code>. <code>missing_keys</code> is a <code>list</code> of <code>str</code> containing the missing keys and <code>unexpected_keys</code> is a <code>list</code> of <code>str</code> containing the unexpected keys.</p><p>The given incompatible_keys can be modified inplace if needed.</p><p>Note that the checks performed when calling <code>load_state_dict</code> with <code>strict=True</code> are affected by modifications the hook makes to <code>missing_keys</code> or <code>unexpected_keys</code>, as expected. Additions to either set of keys will result in an error being thrown when <code>strict=True</code>, and clearing out both missing and unexpected keys will avoid an error.</p><h4 id="returns-18" tabindex="-1">Returns <a class="header-anchor" href="#returns-18" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-load-state-dict-pre-hook-self-hook-source" tabindex="-1"><code>register_load_state_dict_pre_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2214" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-load-state-dict-pre-hook-self-hook-source" aria-label="Permalink to &quot;`register_load_state_dict_pre_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2214)&quot;">​</a></h4><p>Register a pre-hook to be run before module&#39;s <code>~nn.Module.load_state_dict</code> is called.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # noqa: B950</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="arguments" tabindex="-1">Arguments <a class="header-anchor" href="#arguments" aria-label="Permalink to &quot;Arguments&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): Callable hook that will be invoked before loading the state dict.</li></ul><hr><h4 id="register-module-self-name-str-module-optional-forwardref-module-none-source" tabindex="-1"><code>register_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L695" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-module-self-name-str-module-optional-forwardref-module-none-source" aria-label="Permalink to &quot;`register_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L695)&quot;">​</a></h4><p>Alias for <code>add_module</code>.</p><hr><h4 id="register-parameter-self-name-str-param-optional-tensorplay-nn-parameter-parameter-none-source" tabindex="-1"><code>register_parameter(self, name: str, param: Optional[tensorplay.nn.parameter.Parameter]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L617" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-parameter-self-name-str-param-optional-tensorplay-nn-parameter-parameter-none-source" aria-label="Permalink to &quot;`register_parameter(self, name: str, param: Optional[tensorplay.nn.parameter.Parameter]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L617)&quot;">​</a></h4><p>Add a parameter to the module.</p><p>The parameter can be accessed as an attribute using given name.</p><h4 id="args-18" tabindex="-1">Args <a class="header-anchor" href="#args-18" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>name</strong> (<code>str</code>): name of the parameter. The parameter can be accessed from this module using the given name</li><li><strong>param</strong> (<code>Parameter or None</code>): parameter to be added to the module. If <code>None</code>, then operations that run on parameters, such as <code>cuda</code>, are ignored. If <code>None</code>, the parameter is <strong>not</strong> included in the module&#39;s <code>state_dict</code>.</li></ul><hr><h4 id="register-state-dict-post-hook-self-hook-source" tabindex="-1"><code>register_state_dict_post_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2017" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-state-dict-post-hook-self-hook-source" aria-label="Permalink to &quot;`register_state_dict_post_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2017)&quot;">​</a></h4><p>Register a post-hook for the <code>~tensorplay.nn.Module.state_dict</code> method.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, state_dict, prefix, local_metadata) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The registered hooks can modify the <code>state_dict</code> inplace.</p><hr><h4 id="register-state-dict-pre-hook-self-hook-source" tabindex="-1"><code>register_state_dict_pre_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2041" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-state-dict-pre-hook-self-hook-source" aria-label="Permalink to &quot;`register_state_dict_pre_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2041)&quot;">​</a></h4><p>Register a pre-hook for the <code>~tensorplay.nn.Module.state_dict</code> method.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, prefix, keep_vars) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The registered hooks can be used to perform pre-processing before the <code>state_dict</code> call is made.</p><hr><h4 id="requires-grad-self-requires-grad-bool-true-self-source" tabindex="-1"><code>requires_grad_(self, requires_grad: bool = True) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2826" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#requires-grad-self-requires-grad-bool-true-self-source" aria-label="Permalink to &quot;`requires_grad_(self, requires_grad: bool = True) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2826)&quot;">​</a></h4><p>Change if autograd should record operations on parameters in this module.</p><p>This method sets the parameters&#39; <code>requires_grad</code> attributes in-place.</p><p>This method is helpful for freezing part of the module for finetuning or training parts of a model individually (e.g., GAN training).</p><p>有关 <code>.eval()</code> 和其他类似机制的比较， <code>.requires_grad_()</code> and several similar mechanisms that may be confused with it.</p><h4 id="args-19" tabindex="-1">Args <a class="header-anchor" href="#args-19" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>requires_grad</strong> (<code>bool</code>): whether autograd should record operations on parameters in this module. 默认值： <code>True</code>.</li></ul><h4 id="returns-19" tabindex="-1">Returns <a class="header-anchor" href="#returns-19" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="reset-parameters-self-none-source" tabindex="-1"><code>reset_parameters(self) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L206" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#reset-parameters-self-none-source" aria-label="Permalink to &quot;`reset_parameters(self) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L206)&quot;">​</a></h4><p>Resets parameters based on their initialization used in <code>__init__</code>.</p><hr><h4 id="set-extra-state-self-state-any-none-source" tabindex="-1"><code>set_extra_state(self, state: Any) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L938" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#set-extra-state-self-state-any-none-source" aria-label="Permalink to &quot;`set_extra_state(self, state: Any) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L938)&quot;">​</a></h4><p>Set extra state contained in the loaded <code>state_dict</code>.</p><p>This function is called from <code>load_state_dict</code> to handle any extra state found within the <code>state_dict</code>. Implement this function and a corresponding <code>get_extra_state</code> for your module if you need to store extra state within its <code>state_dict</code>.</p><h4 id="args-20" tabindex="-1">Args <a class="header-anchor" href="#args-20" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state</strong> (<code>dict</code>): Extra state from the <code>state_dict</code></li></ul><hr><h4 id="set-submodule-self-target-str-module-module-strict-bool-false-none-source" tabindex="-1"><code>set_submodule(self, target: str, module: &#39;Module&#39;, strict: bool = False) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L764" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#set-submodule-self-target-str-module-module-strict-bool-false-none-source" aria-label="Permalink to &quot;`set_submodule(self, target: str, module: &#39;Module&#39;, strict: bool = False) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L764)&quot;">​</a></h4><p>Set the submodule given by <code>target</code> if it exists, otherwise throw an error.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>If <code>strict</code> is set to <code>False</code> (default), the method will replace an existing submodule or create a new submodule if the parent module exists. If <code>strict</code> is set to <code>True</code>, the method will only attempt to replace an existing submodule and throw an error if the submodule does not exist.</p></div><p>For example, let&#39;s say you have an <code>nn.Module</code> <code>A</code> that looks like this:</p><p>.. code-block:: text</p><ul><li><strong>A</strong> (<code> (net_b</code>): Module( (net_c): Module( (conv): Conv2d(3, 3, 3) ) (linear): Linear(3, 3) ) )</li></ul><p>(The diagram shows an <code>nn.Module</code> <code>A</code>. <code>A</code> has a nested submodule <code>net_b</code>, which itself has two submodules <code>net_c</code> and <code>linear</code>. <code>net_c</code> then has a submodule <code>conv</code>.)</p><p>To override the <code>Conv2d</code> with a new submodule <code>Linear</code>, you could call <code>set_submodule(&quot;net_b.net_c.conv&quot;, nn.Linear(1, 1))</code> where <code>strict</code> could be <code>True</code> or <code>False</code></p><p>To add a new submodule <code>Conv2d</code> to the existing <code>net_b</code> module, you would call <code>set_submodule(&quot;net_b.conv&quot;, nn.Conv2d(1, 1, 1))</code>.</p><p>In the above if you set <code>strict=True</code> and call <code>set_submodule(&quot;net_b.conv&quot;, nn.Conv2d(1, 1, 1), strict=True)</code>, an AttributeError will be raised because <code>net_b</code> does not have a submodule named <code>conv</code>.</p><h4 id="args-21" tabindex="-1">Args <a class="header-anchor" href="#args-21" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: The fully-qualified string name of the submodule to look for. (See above example for how to specify a fully-qualified string.)</li><li><strong>module</strong>: The module to set the submodule to.</li><li><strong>strict</strong>: If <code>False</code>, the method will replace an existing submodule or create a new submodule if the parent module exists. If <code>True</code>, the method will only attempt to replace an existing submodule and throw an error if the submodule doesn&#39;t already exist.</li></ul><h4 id="raises-3" tabindex="-1">Raises <a class="header-anchor" href="#raises-3" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the <code>target</code> string is empty or if <code>module</code> is not an instance of <code>nn.Module</code>.</li><li><strong>AttributeError</strong>: If at any point along the path resulting from the <code>target</code> string the (sub)path resolves to a non-existent attribute name or an object that is not an instance of <code>nn.Module</code>.</li></ul><hr><h4 id="share-memory-self-self-source" tabindex="-1"><code>share_memory(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2877" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#share-memory-self-self-source" aria-label="Permalink to &quot;`share_memory(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2877)&quot;">​</a></h4><p>See <code>tensorplay.Tensor.share_memory_</code>.</p><hr><h4 id="state-dict-self-args-destination-none-prefix-keep-vars-false-source" tabindex="-1"><code>state_dict(self, *args, destination=None, prefix=&#39;&#39;, keep_vars=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2105" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-args-destination-none-prefix-keep-vars-false-source" aria-label="Permalink to &quot;`state_dict(self, *args, destination=None, prefix=&#39;&#39;, keep_vars=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2105)&quot;">​</a></h4><p>Return a dictionary containing references to the whole state of the module.</p><p>Both parameters and persistent buffers (e.g. running averages) are included. Keys are corresponding parameter and buffer names. Parameters and buffers set to <code>None</code> are not included.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>The returned object is a shallow copy. It contains references to the module&#39;s parameters and buffers.</p></div><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>Currently <code>state_dict()</code> also accepts positional arguments for <code>destination</code>, <code>prefix</code> and <code>keep_vars</code> in order. However, this is being deprecated and keyword arguments will be enforced in future releases.</p></div><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>Please avoid the use of argument <code>destination</code> as it is not designed for end-users.</p></div><h4 id="args-22" tabindex="-1">Args <a class="header-anchor" href="#args-22" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>destination</strong> (<code>dict, optional</code>): If provided, the state of module will be updated into the dict and the same object is returned. Otherwise, an <code>OrderedDict</code> will be created and returned.</li><li><strong>Default</strong>: <code>None</code>.</li><li><strong>prefix</strong> (<code>str, optional</code>): a prefix added to parameter and buffer names to compose the keys in state_dict. 默认值： <code>&#39;&#39;</code>.</li><li><strong>keep_vars</strong> (<code>bool, optional</code>): by default the <code>~tensorplay.Tensor</code> s returned in the state dict are detached from autograd. If it&#39;s set to <code>True</code>, detaching will not be performed.</li><li><strong>Default</strong>: <code>False</code>.</li></ul><h4 id="returns-20" tabindex="-1">Returns <a class="header-anchor" href="#returns-20" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>dict</strong>: a dictionary containing a whole state of the module</li></ul><h4 id="example-9" tabindex="-1">Example <a class="header-anchor" href="#example-9" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">module.state_dict().keys()</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;bias&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;weight&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><hr><h4 id="to-self-args-kwargs-source" tabindex="-1"><code>to(self, *args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1151" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#to-self-args-kwargs-source" aria-label="Permalink to &quot;`to(self, *args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1151)&quot;">​</a></h4><p>Move and/or cast the parameters and buffers.</p><p>This can be called as</p><p>.. function:: to(device=None, dtype=None, non_blocking=False) :noindex:</p><p>.. function:: to(dtype, non_blocking=False) :noindex:</p><p>.. function:: to(tensor, non_blocking=False) :noindex:</p><p>.. function:: to(memory_format=tensorplay.channels_last) :noindex:</p><p>Its signature is similar to <code>tensorplay.Tensor.to</code>, but only accepts floating point or complex <code>dtype</code>\\ s. In addition, this method will only cast the floating point or complex parameters and buffers to <code>dtype</code> (if given). The integral parameters and buffers will be moved <code>device</code>, if that is given, but with dtypes unchanged. When <code>non_blocking</code> is set, it tries to convert/move asynchronously with respect to the host if possible, e.g., moving CPU Tensors with pinned memory to CUDA devices.</p><p>See below for examples.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="args-23" tabindex="-1">Args <a class="header-anchor" href="#args-23" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>device</strong> (<code>tensorplay.device</code>): the desired device of the parameters and buffers in this module</li><li><strong>dtype</strong> (<code>tensorplay.dtype</code>): the desired floating point or complex dtype of the parameters and buffers in this module</li><li><strong>tensor</strong> (<code>tensorplay.Tensor</code>): Tensor whose dtype and device are the desired dtype and device for all parameters and buffers in this module</li><li><strong>memory_format</strong> (<code>tensorplay.memory_format</code>): the desired memory format for 4D parameters and buffers in this module (keyword only argument)</li></ul><h4 id="returns-21" tabindex="-1">Returns <a class="header-anchor" href="#returns-21" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><h4 id="examples-1" tabindex="-1">Examples <a class="header-anchor" href="#examples-1" aria-label="Permalink to &quot;Examples&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +IGNORE_WANT(&quot;non-deterministic&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1913</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5113</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2325</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.to(tensorplay.double)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1913</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5113</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2325</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.float64)</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +REQUIRES(env:TENSORPLAY_DOCTEST_CUDA1)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpu1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.device(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cuda:1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.to(gpu1, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.half, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">non_blocking</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1914</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5112</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2324</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.float16, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">device</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;cuda:1&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.device(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cpu&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.to(cpu)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1914</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5112</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2324</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.float16)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).to(tensorplay.cdouble)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3741</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2382</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5593</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4443</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.complex128)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear(tensorplay.ones(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.cdouble))</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6122</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1150</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6122</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1150</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6122</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1150</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.complex128)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br></div></div><hr><h4 id="to-empty-self-device-union-str-tensorplay-device-int-nonetype-recurse-bool-true-self-source" tabindex="-1"><code>to_empty(self, *, device: Union[str, tensorplay.Device, int, NoneType], recurse: bool = True) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1119" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#to-empty-self-device-union-str-tensorplay-device-int-nonetype-recurse-bool-true-self-source" aria-label="Permalink to &quot;`to_empty(self, *, device: Union[str, tensorplay.Device, int, NoneType], recurse: bool = True) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1119)&quot;">​</a></h4><p>Move the parameters and buffers to the specified device without copying storage.</p><h4 id="args-24" tabindex="-1">Args <a class="header-anchor" href="#args-24" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>device</strong> (<code>tensorplay.device</code>): The desired device of the parameters and buffers in this module.</li><li><strong>recurse</strong> (<code>bool</code>): Whether parameters and buffers of submodules should be recursively moved to the specified device.</li></ul><h4 id="returns-22" tabindex="-1">Returns <a class="header-anchor" href="#returns-22" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="train-self-mode-bool-true-self-source" tabindex="-1"><code>train(self, mode: bool = True) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2786" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#train-self-mode-bool-true-self-source" aria-label="Permalink to &quot;`train(self, mode: bool = True) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2786)&quot;">​</a></h4><p>Set the module in training mode.</p><p>这仅对某些模块有影响。请参阅特定模块的文档 了解它们在训练/评估模式下的行为细节， mode, i.e., whether they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>, 等。</p><h4 id="args-25" tabindex="-1">Args <a class="header-anchor" href="#args-25" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>mode</strong> (<code>bool</code>): whether to set training mode (<code>True</code>) or evaluation mode (<code>False</code>). 默认值： <code>True</code>.</li></ul><h4 id="returns-23" tabindex="-1">Returns <a class="header-anchor" href="#returns-23" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="type-self-dst-type-union-tensorplay-dtype-str-self-source" tabindex="-1"><code>type(self, dst_type: Union[tensorplay.DType, str]) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1061" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#type-self-dst-type-union-tensorplay-dtype-str-self-source" aria-label="Permalink to &quot;`type(self, dst_type: Union[tensorplay.DType, str]) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1061)&quot;">​</a></h4><p>Casts all parameters and buffers to <code>dst_type</code>.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="args-26" tabindex="-1">Args <a class="header-anchor" href="#args-26" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>dst_type</strong> (<code>type or string</code>): the desired type</li></ul><h4 id="returns-24" tabindex="-1">Returns <a class="header-anchor" href="#returns-24" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="zero-grad-self-set-to-none-bool-true-none-source" tabindex="-1"><code>zero_grad(self, set_to_none: bool = True) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2849" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#zero-grad-self-set-to-none-bool-true-none-source" aria-label="Permalink to &quot;`zero_grad(self, set_to_none: bool = True) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2849)&quot;">​</a></h4><p>Reset gradients of all model parameters.</p><p>See similar function under <code>tensorplay.optim.Optimizer</code> for more context.</p><h4 id="args-27" tabindex="-1">Args <a class="header-anchor" href="#args-27" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>set_to_none</strong> (<code>bool</code>): instead of setting to zero, set the grads to None. See <code>tensorplay.optim.Optimizer.zero_grad</code> for details.</li></ul><hr></details><h3 id="class-identity-source" tabindex="-1"><code>class Identity</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L19" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-identity-source" aria-label="Permalink to &quot;`class Identity` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L19)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Identity(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args: Any, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs: Any) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>Module</code></p><p>一个参数不敏感的占位符恒等运算符。</p><h4 id="args-28" tabindex="-1">Args <a class="header-anchor" href="#args-28" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>args</strong>: any argument (unused)</li><li><strong>kwargs</strong>: any keyword argument (unused)</li></ul><h4 id="shape-1" tabindex="-1">Shape <a class="header-anchor" href="#shape-1" aria-label="Permalink to &quot;Shape&quot;">​</a></h4>',10)),i("ul",null,[i("li",null,[l[56]||(l[56]=n("Input: ",-1)),i("mjx-container",M,[(a(),s("svg",D,[...l[52]||(l[52]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[53]||(l[53]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mo",null,"∗"),i("mo",{stretchy:"false"},")")])],-1))]),l[57]||(l[57]=n(", where ",-1)),i("mjx-container",P,[(a(),s("svg",Z,[...l[54]||(l[54]=[i("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[i("g",{"data-mml-node":"math"},[i("g",{"data-mml-node":"mo"},[i("path",{"data-c":"2217",d:"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z",style:{"stroke-width":"3"}})])])],-1)])])),l[55]||(l[55]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",null,"∗")])],-1))]),l[58]||(l[58]=n(" means any number of dimensions.",-1))]),i("li",null,[l[61]||(l[61]=n("输出： ",-1)),i("mjx-container",R,[(a(),s("svg",N,[...l[59]||(l[59]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[60]||(l[60]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mo",null,"∗"),i("mo",{stretchy:"false"},")")])],-1))]),l[62]||(l[62]=n(", same shape as the input.",-1))])]),l[112]||(l[112]=t('<h4 id="examples-2" tabindex="-1">Examples <a class="header-anchor" href="#examples-2" aria-label="Permalink to &quot;Examples&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">m </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tp.nn.Identity(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">54</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">unused_argument1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">unused_argument2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tp.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> m(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(output.size())</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.Size([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><details><summary>Methods</summary><h4 id="init-self-args-any-kwargs-any-none-source" tabindex="-1"><code>__init__(self, *args: Any, **kwargs: Any) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L40" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-args-any-kwargs-any-none-source" aria-label="Permalink to &quot;`__init__(self, *args: Any, **kwargs: Any) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L40)&quot;">​</a></h4><p>初始化内部 Module 状态，由 nn.Module 和 ScriptModule 共享。</p><hr><h4 id="add-module-self-name-str-module-optional-forwardref-module-none-source-1" tabindex="-1"><code>add_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L667" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#add-module-self-name-str-module-optional-forwardref-module-none-source-1" aria-label="Permalink to &quot;`add_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L667)&quot;">​</a></h4><p>将子模块添加到当前模块。</p><p>可以使用给定名称作为属性访问该模块。</p><h4 id="args-29" tabindex="-1">Args <a class="header-anchor" href="#args-29" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>name</strong> (<code>str</code>): 子模块的名称。可以使用给定名称 从该模块访问子模块</li><li><strong>module</strong> (<code>Module</code>): 要添加到模块的子模块。</li></ul><hr><h4 id="apply-self-fn-callable-forwardref-module-nonetype-self-source-1" tabindex="-1"><code>apply(self, fn: Callable[[ForwardRef(&#39;Module&#39;)], NoneType]) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L990" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#apply-self-fn-callable-forwardref-module-nonetype-self-source-1" aria-label="Permalink to &quot;`apply(self, fn: Callable[[ForwardRef(&#39;Module&#39;)], NoneType]) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L990)&quot;">​</a></h4><p>递归地将 <code>fn</code> 应用于每个子模块（由 <code>.children()</code> 返回）以及自身。</p><p>典型用途包括初始化模型的参数 (see also <code>nn-init-doc</code>).</p><h4 id="args-30" tabindex="-1">Args <a class="header-anchor" href="#args-30" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>fn</strong> (``Module<code> -&gt; None</code>): 应用于每个子模块的函数</li></ul><h4 id="returns-25" tabindex="-1">Returns <a class="header-anchor" href="#returns-25" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><h4 id="example-10" tabindex="-1">Example <a class="header-anchor" href="#example-10" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.no_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> init_weights</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m):</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        m.weight.fill_(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m.weight)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.apply(init_weights)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Sequential(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><hr><h4 id="bfloat16-self-self-source-1" tabindex="-1"><code>bfloat16(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1108" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#bfloat16-self-self-source-1" aria-label="Permalink to &quot;`bfloat16(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1108)&quot;">​</a></h4><p>将所有浮点参数和缓冲区转换为 <code>bfloat16</code> 数据类型。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-26" tabindex="-1">Returns <a class="header-anchor" href="#returns-26" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="buffers-self-recurse-bool-true-collections-abc-iterator-tensorplay-c-tensorbase-source-1" tabindex="-1"><code>buffers(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay._C.TensorBase]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2627" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#buffers-self-recurse-bool-true-collections-abc-iterator-tensorplay-c-tensorbase-source-1" aria-label="Permalink to &quot;`buffers(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay._C.TensorBase]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2627)&quot;">​</a></h4><p>返回模块缓冲区的迭代器。</p><h4 id="args-31" tabindex="-1">Args <a class="header-anchor" href="#args-31" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>recurse</strong> (<code>bool</code>): 如果为 True，则生成此模块的缓冲区 以及所有子模块的缓冲区。否则，仅生成 此模块的直接成员缓冲区。</li></ul><h4 id="yields-8" tabindex="-1">Yields <a class="header-anchor" href="#yields-8" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>tensorplay.Tensor: 模块缓冲区\n</code></pre><h4 id="example-11" tabindex="-1">Example <a class="header-anchor" href="#example-11" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> buf </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.buffers():</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(buf), buf.size())</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><hr><h4 id="children-self-collections-abc-iterator-module-source-1" tabindex="-1"><code>children(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2681" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#children-self-collections-abc-iterator-module-source-1" aria-label="Permalink to &quot;`children(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2681)&quot;">​</a></h4><p>返回直接子模块的迭代器。</p><h4 id="yields-9" tabindex="-1">Yields <a class="header-anchor" href="#yields-9" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><ul><li><strong>Module</strong>: 一个子模块</li></ul><hr><h4 id="compile-self-args-kwargs-source-1" tabindex="-1"><code>compile(self, *args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2944" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#compile-self-args-kwargs-source-1" aria-label="Permalink to &quot;`compile(self, *args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2944)&quot;">​</a></h4><p>使用 <code>tensorplay.compile</code> 编译此模块的前向传播。</p><p>此模块的 <code>__call__</code> 方法被编译，所有参数按原样传递 给 <code>tensorplay.compile</code>。</p><p>有关此函数的参数详情，请参阅 <code>tensorplay.compile</code>。</p><hr><h4 id="cpu-self-self-source-1" tabindex="-1"><code>cpu(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1050" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#cpu-self-self-source-1" aria-label="Permalink to &quot;`cpu(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1050)&quot;">​</a></h4><p>将所有模型参数和缓冲区移动到 CPU。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-27" tabindex="-1">Returns <a class="header-anchor" href="#returns-27" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="cuda-self-device-union-int-tensorplay-device-nonetype-none-self-source-1" tabindex="-1"><code>cuda(self, device: Union[int, tensorplay.Device, NoneType] = None) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1031" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#cuda-self-device-union-int-tensorplay-device-nonetype-none-self-source-1" aria-label="Permalink to &quot;`cuda(self, device: Union[int, tensorplay.Device, NoneType] = None) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1031)&quot;">​</a></h4><p>将所有模型参数和缓冲区移动到 GPU。</p><p>这也使得关联的参数和缓冲区成为不同的对象。所以 如果模块将在 GPU 上运行并进行优化， 应在构建优化器之前调用它。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="args-32" tabindex="-1">Args <a class="header-anchor" href="#args-32" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>device</strong> (<code>int, optional</code>): 如果指定，所有参数将被 复制到该设备</li></ul><h4 id="returns-28" tabindex="-1">Returns <a class="header-anchor" href="#returns-28" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="double-self-self-source-1" tabindex="-1"><code>double(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1086" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#double-self-self-source-1" aria-label="Permalink to &quot;`double(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1086)&quot;">​</a></h4><p>将所有浮点参数和缓冲区转换为 <code>double</code> 数据类型。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-29" tabindex="-1">Returns <a class="header-anchor" href="#returns-29" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="eval-self-self-source-1" tabindex="-1"><code>eval(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2808" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#eval-self-self-source-1" aria-label="Permalink to &quot;`eval(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2808)&quot;">​</a></h4><p>将模块设置为评估模式。</p><p>这仅对某些模块有影响。请参阅特定模块的文档 了解它们在训练/评估模式下的行为细节， 即它们是否受影响，例如 <code>Dropout</code>、<code>BatchNorm</code> 等。</p><p>这相当于 <code>self.train(False) &lt;tensorplay.nn.Module.train&gt;</code>。</p><p>有关 <code>.eval()</code> 和其他类似机制的比较， <code>.eval()</code> and several similar mechanisms that may be confused with it.</p><h4 id="returns-30" tabindex="-1">Returns <a class="header-anchor" href="#returns-30" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="extra-repr-self-str-source-1" tabindex="-1"><code>extra_repr(self) -&gt; str</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2884" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#extra-repr-self-str-source-1" aria-label="Permalink to &quot;`extra_repr(self) -&gt; str` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2884)&quot;">​</a></h4><p>返回模块的额外表示。</p><p>To print customized extra information, you should re-implement this method in your own modules. Both single-line and multi-line strings are acceptable.</p><hr><h4 id="float-self-self-source-1" tabindex="-1"><code>float(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1075" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#float-self-self-source-1" aria-label="Permalink to &quot;`float(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1075)&quot;">​</a></h4><p>将所有浮点参数和缓冲区转换为 <code>float</code> 数据类型。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-31" tabindex="-1">Returns <a class="header-anchor" href="#returns-31" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="forward-self-input-tensorplay-c-tensorbase-tensorplay-c-tensorbase-source" tabindex="-1"><code>forward(self, input: tensorplay._C.TensorBase) -&gt; tensorplay._C.TensorBase</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L43" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#forward-self-input-tensorplay-c-tensorbase-tensorplay-c-tensorbase-source" aria-label="Permalink to &quot;`forward(self, input: tensorplay._C.TensorBase) -&gt; tensorplay._C.TensorBase` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L43)&quot;">​</a></h4><p>运行前向传播。</p><hr><h4 id="get-buffer-self-target-str-tensor-source-1" tabindex="-1"><code>get_buffer(self, target: str) -&gt; &#39;Tensor&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L881" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-buffer-self-target-str-tensor-source-1" aria-label="Permalink to &quot;`get_buffer(self, target: str) -&gt; &#39;Tensor&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L881)&quot;">​</a></h4><p>如果存在，则返回由 <code>target</code> 指定的缓冲区，否则抛出错误。</p><p>See the docstring for <code>get_submodule</code> for a more detailed explanation of this method&#39;s functionality as well as how to correctly specify <code>target</code>.</p><h4 id="args-33" tabindex="-1">Args <a class="header-anchor" href="#args-33" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: 缓冲区的完全限定字符串名称 to look for. (See <code>get_submodule</code> for how to specify a fully-qualified string.)</li></ul><h4 id="returns-32" tabindex="-1">Returns <a class="header-anchor" href="#returns-32" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>tensorplay.Tensor: 由 ``target`` 引用的缓冲区\n</code></pre><h4 id="raises-4" tabindex="-1">Raises <a class="header-anchor" href="#raises-4" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>AttributeError</strong>: If the target string references an invalid path or resolves to something that is not a buffer</li></ul><hr><h4 id="get-extra-state-self-any-source-1" tabindex="-1"><code>get_extra_state(self) -&gt; Any</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L917" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-extra-state-self-any-source-1" aria-label="Permalink to &quot;`get_extra_state(self) -&gt; Any` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L917)&quot;">​</a></h4><p>返回要包含在模块 state_dict 中的任何额外状态。</p><p>Implement this and a corresponding <code>set_extra_state</code> for your module if you need to store extra state. This function is called when building the module&#39;s <code>state_dict()</code>.</p><p>Note that extra state should be picklable to ensure working serialization of the state_dict. We only provide backwards compatibility guarantees for serializing Tensors; other objects may break backwards compatibility if their serialized pickled form changes.</p><h4 id="returns-33" tabindex="-1">Returns <a class="header-anchor" href="#returns-33" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>object</strong>: Any extra state to store in the module&#39;s state_dict</li></ul><hr><h4 id="get-parameter-self-target-str-parameter-source-1" tabindex="-1"><code>get_parameter(self, target: str) -&gt; &#39;Parameter&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L845" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-parameter-self-target-str-parameter-source-1" aria-label="Permalink to &quot;`get_parameter(self, target: str) -&gt; &#39;Parameter&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L845)&quot;">​</a></h4><p>如果存在，则返回由 <code>target</code> 指定的参数，否则抛出错误。</p><p>See the docstring for <code>get_submodule</code> for a more detailed explanation of this method&#39;s functionality as well as how to correctly specify <code>target</code>.</p><h4 id="args-34" tabindex="-1">Args <a class="header-anchor" href="#args-34" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: The fully-qualified string name of the Parameter to look for. (See <code>get_submodule</code> for how to specify a fully-qualified string.)</li></ul><h4 id="returns-34" tabindex="-1">Returns <a class="header-anchor" href="#returns-34" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>tensorplay.nn.Parameter: The Parameter referenced by ``target``\n</code></pre><h4 id="raises-5" tabindex="-1">Raises <a class="header-anchor" href="#raises-5" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>AttributeError</strong>: If the target string references an invalid path or resolves to something that is not an <code>nn.Parameter</code></li></ul><hr><h4 id="get-submodule-self-target-str-module-source-1" tabindex="-1"><code>get_submodule(self, target: str) -&gt; &#39;Module&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L699" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-submodule-self-target-str-module-source-1" aria-label="Permalink to &quot;`get_submodule(self, target: str) -&gt; &#39;Module&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L699)&quot;">​</a></h4><p>Return the submodule given by <code>target</code> if it exists, otherwise throw an error.</p><p>For example, let&#39;s say you have an <code>nn.Module</code> <code>A</code> that looks like this:</p><p>.. code-block:: text</p><ul><li><strong>A</strong> (<code> (net_b</code>): Module( (net_c): Module( (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2)) ) (linear): Linear(in_features=100, out_features=200, bias=True) ) )</li></ul><p>(The diagram shows an <code>nn.Module</code> <code>A</code>. <code>A</code> which has a nested submodule <code>net_b</code>, which itself has two submodules <code>net_c</code> and <code>linear</code>. <code>net_c</code> then has a submodule <code>conv</code>.)</p><p>To check whether or not we have the <code>linear</code> submodule, we would call <code>get_submodule(&quot;net_b.linear&quot;)</code>. To check whether we have the <code>conv</code> submodule, we would call <code>get_submodule(&quot;net_b.net_c.conv&quot;)</code>.</p><p>The runtime of <code>get_submodule</code> is bounded by the degree of module nesting in <code>target</code>. A query against <code>named_modules</code> achieves the same result, but it is O(N) in the number of transitive modules. So, for a simple check to see if some submodule exists, <code>get_submodule</code> should always be used.</p><h4 id="args-35" tabindex="-1">Args <a class="header-anchor" href="#args-35" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: The fully-qualified string name of the submodule to look for. (See above example for how to specify a fully-qualified string.)</li></ul><h4 id="returns-35" tabindex="-1">Returns <a class="header-anchor" href="#returns-35" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>tensorplay.nn.Module: The submodule referenced by ``target``\n</code></pre><h4 id="raises-6" tabindex="-1">Raises <a class="header-anchor" href="#raises-6" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>AttributeError</strong>: If at any point along the path resulting from the target string the (sub)path resolves to a non-existent attribute name or an object that is not an instance of <code>nn.Module</code>.</li></ul><hr><h4 id="half-self-self-source-1" tabindex="-1"><code>half(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1097" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#half-self-self-source-1" aria-label="Permalink to &quot;`half(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1097)&quot;">​</a></h4><p>Casts all floating point parameters and buffers to <code>half</code> datatype.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-36" tabindex="-1">Returns <a class="header-anchor" href="#returns-36" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="load-state-dict-self-state-dict-collections-abc-mapping-str-typing-any-strict-bool-true-assign-bool-false-source-1" tabindex="-1"><code>load_state_dict(self, state_dict: collections.abc.Mapping[str, typing.Any], strict: bool = True, assign: bool = False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2436" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-collections-abc-mapping-str-typing-any-strict-bool-true-assign-bool-false-source-1" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: collections.abc.Mapping[str, typing.Any], strict: bool = True, assign: bool = False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2436)&quot;">​</a></h4><p>Copy parameters and buffers from <code>state_dict</code> into this module and its descendants.</p><p>If <code>strict</code> is <code>True</code>, then the keys of <code>state_dict</code> must exactly match the keys returned by this module&#39;s <code>~tensorplay.nn.Module.state_dict</code> function.</p><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>If <code>assign</code> is <code>True</code> the optimizer must be created after the call to <code>load_state_dict</code> unless <code>~tensorplay.__future__.get_swap_module_params_on_conversion</code> is <code>True</code>.</p></div><h4 id="args-36" tabindex="-1">Args <a class="header-anchor" href="#args-36" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): a dict containing parameters and persistent buffers.</li><li><strong>strict</strong> (<code>bool, optional</code>): whether to strictly enforce that the keys in <code>state_dict</code> match the keys returned by this module&#39;s <code>~tensorplay.nn.Module.state_dict</code> function. 默认值： <code>True</code></li><li><strong>assign</strong> (<code>bool, optional</code>): When set to <code>False</code>, the properties of the tensors in the current module are preserved whereas setting it to <code>True</code> preserves properties of the Tensors in the state dict. The only exception is the <code>requires_grad</code> field of <code>~tensorplay.nn.Parameter</code> for which the value from the module is preserved. 默认值： <code>False</code></li></ul><h4 id="returns-37" tabindex="-1">Returns <a class="header-anchor" href="#returns-37" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n    * ``missing_keys`` is a list of str containing any keys that are expected\n        by this module but missing from the provided ``state_dict``.\n    * ``unexpected_keys`` is a list of str containing the keys that are not\n        expected by this module but present in the provided ``state_dict``.\n</code></pre><h4 id="note-3" tabindex="-1">Note <a class="header-anchor" href="#note-3" aria-label="Permalink to &quot;Note&quot;">​</a></h4><pre><code>If a parameter or buffer is registered as ``None`` and its corresponding key\nexists in `state_dict`, `load_state_dict` will raise a\n``RuntimeError``.\n</code></pre><hr><h4 id="modules-self-collections-abc-iterator-module-source-1" tabindex="-1"><code>modules(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2710" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#modules-self-collections-abc-iterator-module-source-1" aria-label="Permalink to &quot;`modules(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2710)&quot;">​</a></h4><p>Return an iterator over all modules in the network.</p><h4 id="yields-10" tabindex="-1">Yields <a class="header-anchor" href="#yields-10" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><ul><li><strong>Module</strong>: a module in the network</li></ul><h4 id="note-4" tabindex="-1">Note <a class="header-anchor" href="#note-4" aria-label="Permalink to &quot;Note&quot;">​</a></h4><pre><code>Duplicate modules are returned only once. In the following\nexample, ``l`` will be returned only once.\n</code></pre><h4 id="example-12" tabindex="-1">Example <a class="header-anchor" href="#example-12" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(l, l)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx, m </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(net.modules()):</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(idx, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;-&gt;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, m)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Sequential(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><hr><h4 id="named-buffers-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-c-tensorbase-source-1" tabindex="-1"><code>named_buffers(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay._C.TensorBase]]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2650" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-buffers-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-c-tensorbase-source-1" aria-label="Permalink to &quot;`named_buffers(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay._C.TensorBase]]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2650)&quot;">​</a></h4><p>Return an iterator over 模块缓冲区s, yielding both the name of the buffer as well as the buffer itself.</p><h4 id="args-37" tabindex="-1">Args <a class="header-anchor" href="#args-37" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>prefix</strong> (<code>str</code>): prefix to prepend to all buffer names.</li><li><strong>recurse</strong> (<code>bool, optional</code>): 如果为 True，则生成此模块的缓冲区 以及所有子模块的缓冲区。否则，仅生成 此模块的直接成员缓冲区。 Defaults to True.</li><li><strong>remove_duplicate</strong> (<code>bool, optional</code>): whether to remove the duplicated buffers in the result. Defaults to True.</li></ul><h4 id="yields-11" tabindex="-1">Yields <a class="header-anchor" href="#yields-11" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, tensorplay.Tensor): Tuple containing the name and buffer\n</code></pre><h4 id="example-13" tabindex="-1">Example <a class="header-anchor" href="#example-13" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, buf </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.named_buffers():</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;running_var&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(buf.size())</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h4 id="named-children-self-collections-abc-iterator-tuple-str-module-source-1" tabindex="-1"><code>named_children(self) -&gt; collections.abc.Iterator[tuple[str, &#39;Module&#39;]]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2690" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-children-self-collections-abc-iterator-tuple-str-module-source-1" aria-label="Permalink to &quot;`named_children(self) -&gt; collections.abc.Iterator[tuple[str, &#39;Module&#39;]]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2690)&quot;">​</a></h4><p>Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p><h4 id="yields-12" tabindex="-1">Yields <a class="header-anchor" href="#yields-12" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, Module): Tuple containing a name and child module\n</code></pre><h4 id="example-14" tabindex="-1">Example <a class="header-anchor" href="#example-14" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, module </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.named_children():</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;conv4&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;conv5&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(module)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h4 id="named-modules-self-memo-optional-set-module-none-prefix-str-remove-duplicate-bool-true-source-1" tabindex="-1"><code>named_modules(self, memo: Optional[set[&#39;Module&#39;]] = None, prefix: str = &#39;&#39;, remove_duplicate: bool = True)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2737" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-modules-self-memo-optional-set-module-none-prefix-str-remove-duplicate-bool-true-source-1" aria-label="Permalink to &quot;`named_modules(self, memo: Optional[set[&#39;Module&#39;]] = None, prefix: str = &#39;&#39;, remove_duplicate: bool = True)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2737)&quot;">​</a></h4><p>Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p><h4 id="args-38" tabindex="-1">Args <a class="header-anchor" href="#args-38" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>memo</strong>: a memo to store the set of modules already added to the result</li><li><strong>prefix</strong>: a prefix that will be added to the name of the module</li><li><strong>remove_duplicate</strong>: whether to remove the duplicated module instances in the result or not</li></ul><h4 id="yields-13" tabindex="-1">Yields <a class="header-anchor" href="#yields-13" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, Module): Tuple of name and module\n</code></pre><h4 id="note-5" tabindex="-1">Note <a class="header-anchor" href="#note-5" aria-label="Permalink to &quot;Note&quot;">​</a></h4><pre><code>Duplicate modules are returned only once. In the following\nexample, ``l`` will be returned only once.\n</code></pre><h4 id="example-15" tabindex="-1">Example <a class="header-anchor" href="#example-15" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(l, l)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx, m </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(net.named_modules()):</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(idx, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;-&gt;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, m)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Sequential(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;0&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><hr><h4 id="named-parameters-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-nn-parameter-parameter-source-1" tabindex="-1"><code>named_parameters(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay.nn.parameter.Parameter]]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2595" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-parameters-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-nn-parameter-parameter-source-1" aria-label="Permalink to &quot;`named_parameters(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay.nn.parameter.Parameter]]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2595)&quot;">​</a></h4><p>Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p><h4 id="args-39" tabindex="-1">Args <a class="header-anchor" href="#args-39" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>prefix</strong> (<code>str</code>): prefix to prepend to all parameter names.</li><li><strong>recurse</strong> (<code>bool</code>): if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that 此模块的直接成员缓冲区。</li><li><strong>remove_duplicate</strong> (<code>bool, optional</code>): whether to remove the duplicated parameters in the result. Defaults to True.</li></ul><h4 id="yields-14" tabindex="-1">Yields <a class="header-anchor" href="#yields-14" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, Parameter): Tuple containing the name and parameter\n</code></pre><h4 id="example-16" tabindex="-1">Example <a class="header-anchor" href="#example-16" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.named_parameters():</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;bias&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(param.size())</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h4 id="parameters-self-recurse-bool-true-collections-abc-iterator-tensorplay-nn-parameter-parameter-source-1" tabindex="-1"><code>parameters(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay.nn.parameter.Parameter]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2570" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#parameters-self-recurse-bool-true-collections-abc-iterator-tensorplay-nn-parameter-parameter-source-1" aria-label="Permalink to &quot;`parameters(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay.nn.parameter.Parameter]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2570)&quot;">​</a></h4><p>Return an iterator over module parameters.</p><p>This is typically passed to an optimizer.</p><h4 id="args-40" tabindex="-1">Args <a class="header-anchor" href="#args-40" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>recurse</strong> (<code>bool</code>): if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that 此模块的直接成员缓冲区。</li></ul><h4 id="yields-15" tabindex="-1">Yields <a class="header-anchor" href="#yields-15" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><ul><li><strong>Parameter</strong>: module parameter</li></ul><h4 id="example-17" tabindex="-1">Example <a class="header-anchor" href="#example-17" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.parameters():</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(param), param.size())</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><hr><h4 id="register-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-tensorplay-utils-hooks-removablehandle-source-1" tabindex="-1"><code>register_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]]) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1336" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-tensorplay-utils-hooks-removablehandle-source-1" aria-label="Permalink to &quot;`register_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]]) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1336)&quot;">​</a></h4><p>Register a backward hook on the module.</p><p>This function is deprecated in favor of <code>~tensorplay.nn.Module.register_full_backward_hook</code> and the behavior of this function will change in future versions.</p><h4 id="returns-38" tabindex="-1">Returns <a class="header-anchor" href="#returns-38" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-buffer-self-name-str-tensor-optional-tensorplay-c-tensorbase-persistent-bool-true-none-source-1" tabindex="-1"><code>register_buffer(self, name: str, tensor: Optional[tensorplay._C.TensorBase], persistent: bool = True) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L553" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-buffer-self-name-str-tensor-optional-tensorplay-c-tensorbase-persistent-bool-true-none-source-1" aria-label="Permalink to &quot;`register_buffer(self, name: str, tensor: Optional[tensorplay._C.TensorBase], persistent: bool = True) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L553)&quot;">​</a></h4><p>Add a buffer to the module.</p><p>This is typically used to register a buffer that should not be considered a model parameter. For example, BatchNorm&#39;s <code>running_mean</code> is not a parameter, but is part of the module&#39;s state. Buffers, by default, are persistent and will be saved alongside parameters. This behavior can be changed by setting <code>persistent</code> to <code>False</code>. The only difference between a persistent buffer and a non-persistent buffer is that the latter will not be a part of this module&#39;s <code>state_dict</code>.</p><p>Buffers can be accessed as attributes using given names.</p><h4 id="args-41" tabindex="-1">Args <a class="header-anchor" href="#args-41" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>name</strong> (<code>str</code>): name of the buffer. The buffer can be accessed from this module using the given name</li><li><strong>tensor</strong> (<code>Tensor or None</code>): buffer to be registered. If <code>None</code>, then operations that run on buffers, such as <code>cuda</code>, are ignored. If <code>None</code>, the buffer is <strong>not</strong> included in the module&#39;s <code>state_dict</code>.</li><li><strong>persistent</strong> (<code>bool</code>): whether the buffer is part of this module&#39;s <code>state_dict</code>.</li></ul><h4 id="example-18" tabindex="-1">Example <a class="header-anchor" href="#example-18" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.register_buffer(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;running_mean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, tensorplay.zeros(num_features))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><hr><h4 id="register-forward-hook-self-hook-union-callable-t-tuple-any-any-optional-any-callable-t-tuple-any-dict-str-any-any-optional-any-prepend-bool-false-with-kwargs-bool-false-always-call-bool-false-tensorplay-utils-hooks-removablehandle-source-1" tabindex="-1"><code>register_forward_hook(self, hook: Union[Callable[[~T, tuple[Any, ...], Any], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1592" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-forward-hook-self-hook-union-callable-t-tuple-any-any-optional-any-callable-t-tuple-any-dict-str-any-any-optional-any-prepend-bool-false-with-kwargs-bool-false-always-call-bool-false-tensorplay-utils-hooks-removablehandle-source-1" aria-label="Permalink to &quot;`register_forward_hook(self, hook: Union[Callable[[~T, tuple[Any, ...], Any], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1592)&quot;">​</a></h4><p>Register a forward hook on the module.</p><p>The hook will be called every time after <code>forward</code> has computed an output.</p><p>If <code>with_kwargs</code> is <code>False</code> or not specified, the input contains only the positional arguments given to the module. Keyword arguments won&#39;t be passed to the hooks and only to the <code>forward</code>. The hook can modify the output. It can modify the input inplace but it will not have effect on forward since this is called after <code>forward</code> is called. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args, output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> modified output</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>If <code>with_kwargs</code> is <code>True</code>, the forward hook will be passed the <code>kwargs</code> given to the forward function and be expected to return the output possibly modified. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args, kwargs, output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> modified output</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="args-42" tabindex="-1">Args <a class="header-anchor" href="#args-42" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If <code>True</code>, the provided <code>hook</code> will be fired before all existing <code>forward</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>forward</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>forward</code> hooks registered with <code>register_module_forward_hook</code> will fire before all hooks registered by this method.</li><li><strong>Default</strong>: <code>False</code></li><li><strong>with_kwargs</strong> (<code>bool</code>): If <code>True</code>, the <code>hook</code> will be passed the kwargs given to the forward function.</li><li><strong>Default</strong>: <code>False</code></li><li><strong>always_call</strong> (<code>bool</code>): If <code>True</code> the <code>hook</code> will be run regardless of whether an exception is raised while calling the Module.</li><li><strong>Default</strong>: <code>False</code></li></ul><h4 id="returns-39" tabindex="-1">Returns <a class="header-anchor" href="#returns-39" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-forward-pre-hook-self-hook-union-callable-t-tuple-any-optional-any-callable-t-tuple-any-dict-str-any-optional-tuple-any-dict-str-any-prepend-bool-false-with-kwargs-bool-false-tensorplay-utils-hooks-removablehandle-source-1" tabindex="-1"><code>register_forward_pre_hook(self, hook: Union[Callable[[~T, tuple[Any, ...]], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any]], Optional[tuple[Any, dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1526" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-forward-pre-hook-self-hook-union-callable-t-tuple-any-optional-any-callable-t-tuple-any-dict-str-any-optional-tuple-any-dict-str-any-prepend-bool-false-with-kwargs-bool-false-tensorplay-utils-hooks-removablehandle-source-1" aria-label="Permalink to &quot;`register_forward_pre_hook(self, hook: Union[Callable[[~T, tuple[Any, ...]], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any]], Optional[tuple[Any, dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1526)&quot;">​</a></h4><p>Register a forward pre-hook on the module.</p><p>The hook will be called every time before <code>forward</code> is invoked.</p><p>If <code>with_kwargs</code> is false or not specified, the input contains only the positional arguments given to the module. Keyword arguments won&#39;t be passed to the hooks and only to the <code>forward</code>. The hook can modify the input. User can either return a tuple or a single modified value in the hook. We will wrap the value into a tuple if a single value is returned (unless that value is already a tuple). The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> modified </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>If <code>with_kwargs</code> is true, the forward pre-hook will be passed the kwargs given to the forward function. And if the hook modifies the input, both the args and kwargs should be returned. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args, kwargs) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> of modified </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> kwargs</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="args-43" tabindex="-1">Args <a class="header-anchor" href="#args-43" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If true, the provided <code>hook</code> will be fired before all existing <code>forward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>forward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>forward_pre</code> hooks registered with <code>register_module_forward_pre_hook</code> will fire before all hooks registered by this method.</li><li><strong>Default</strong>: <code>False</code></li><li><strong>with_kwargs</strong> (<code>bool</code>): If true, the <code>hook</code> will be passed the kwargs given to the forward function.</li><li><strong>Default</strong>: <code>False</code></li></ul><h4 id="returns-40" tabindex="-1">Returns <a class="header-anchor" href="#returns-40" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-full-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source-1" tabindex="-1"><code>register_full_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1362" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-full-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source-1" aria-label="Permalink to &quot;`register_full_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1362)&quot;">​</a></h4><p>Register a backward hook on the module.</p><p>The hook will be called every time the gradients with respect to a module are computed, and its firing rules are as follows:</p><pre><code>1. Ordinarily, the hook fires when the gradients are computed with respect to the module inputs.\n2. If none of the module inputs require gradients, the hook will fire when the gradients are computed\n   with respect to module outputs.\n3. If none of the module outputs require gradients, then the hooks will not fire.\n</code></pre><p>The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, grad_input, grad_output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Tensor) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">or</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The <code>grad_input</code> and <code>grad_output</code> are tuples that contain the gradients with respect to the inputs and outputs respectively. The hook should not modify its arguments, but it can optionally return a new gradient with respect to the input that will be used in place of <code>grad_input</code> in subsequent computations. <code>grad_input</code> will only correspond to the inputs given as positional arguments and all kwarg arguments are ignored. Entries in <code>grad_input</code> and <code>grad_output</code> will be <code>None</code> for all non-Tensor arguments.</p><p>For technical reasons, when this hook is applied to a Module, its forward function will receive a view of each Tensor passed to the Module. Similarly the caller will receive a view of each Tensor returned by the Module&#39;s forward function.</p><p>.. warning</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Modifying inputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> outputs inplace </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> allowed when using backward hooks </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">will </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">raise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> an error.</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="args-44" tabindex="-1">Args <a class="header-anchor" href="#args-44" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user-defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If true, the provided <code>hook</code> will be fired before all existing <code>backward</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>backward</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>backward</code> hooks registered with <code>register_module_full_backward_hook</code> will fire before all hooks registered by this method.</li></ul><h4 id="returns-41" tabindex="-1">Returns <a class="header-anchor" href="#returns-41" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-full-backward-pre-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source-1" tabindex="-1"><code>register_full_backward_pre_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1287" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-full-backward-pre-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source-1" aria-label="Permalink to &quot;`register_full_backward_pre_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1287)&quot;">​</a></h4><p>Register a backward pre-hook on the module.</p><p>The hook will be called every time the gradients for the module are computed. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, grad_output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tuple[Tensor] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">or</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The <code>grad_output</code> is a tuple. The hook should not modify its arguments, but it can optionally return a new gradient with respect to the output that will be used in place of <code>grad_output</code> in subsequent computations. Entries in <code>grad_output</code> will be <code>None</code> for all non-Tensor arguments.</p><p>For technical reasons, when this hook is applied to a Module, its forward function will receive a view of each Tensor passed to the Module. Similarly the caller will receive a view of each Tensor returned by the Module&#39;s forward function.</p><p>.. warning</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Modifying inputs inplace </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> allowed when using backward hooks </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">will </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">raise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> an error.</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="args-45" tabindex="-1">Args <a class="header-anchor" href="#args-45" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user-defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If true, the provided <code>hook</code> will be fired before all existing <code>backward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>backward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>backward_pre</code> hooks registered with <code>register_module_full_backward_pre_hook</code> will fire before all hooks registered by this method.</li></ul><h4 id="returns-42" tabindex="-1">Returns <a class="header-anchor" href="#returns-42" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-load-state-dict-post-hook-self-hook-source-1" tabindex="-1"><code>register_load_state_dict_post_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2226" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-load-state-dict-post-hook-self-hook-source-1" aria-label="Permalink to &quot;`register_load_state_dict_post_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2226)&quot;">​</a></h4><p>Register a post-hook to be run after module&#39;s <code>~nn.Module.load_state_dict</code> is called.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, incompatible_keys) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The <code>module</code> argument is the current module that this hook is registered on, and the <code>incompatible_keys</code> argument is a <code>NamedTuple</code> consisting of attributes <code>missing_keys</code> and <code>unexpected_keys</code>. <code>missing_keys</code> is a <code>list</code> of <code>str</code> containing the missing keys and <code>unexpected_keys</code> is a <code>list</code> of <code>str</code> containing the unexpected keys.</p><p>The given incompatible_keys can be modified inplace if needed.</p><p>Note that the checks performed when calling <code>load_state_dict</code> with <code>strict=True</code> are affected by modifications the hook makes to <code>missing_keys</code> or <code>unexpected_keys</code>, as expected. Additions to either set of keys will result in an error being thrown when <code>strict=True</code>, and clearing out both missing and unexpected keys will avoid an error.</p><h4 id="returns-43" tabindex="-1">Returns <a class="header-anchor" href="#returns-43" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-load-state-dict-pre-hook-self-hook-source-1" tabindex="-1"><code>register_load_state_dict_pre_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2214" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-load-state-dict-pre-hook-self-hook-source-1" aria-label="Permalink to &quot;`register_load_state_dict_pre_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2214)&quot;">​</a></h4><p>Register a pre-hook to be run before module&#39;s <code>~nn.Module.load_state_dict</code> is called.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # noqa: B950</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="arguments-1" tabindex="-1">Arguments <a class="header-anchor" href="#arguments-1" aria-label="Permalink to &quot;Arguments&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): Callable hook that will be invoked before loading the state dict.</li></ul><hr><h4 id="register-module-self-name-str-module-optional-forwardref-module-none-source-1" tabindex="-1"><code>register_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L695" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-module-self-name-str-module-optional-forwardref-module-none-source-1" aria-label="Permalink to &quot;`register_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L695)&quot;">​</a></h4><p>Alias for <code>add_module</code>.</p><hr><h4 id="register-parameter-self-name-str-param-optional-tensorplay-nn-parameter-parameter-none-source-1" tabindex="-1"><code>register_parameter(self, name: str, param: Optional[tensorplay.nn.parameter.Parameter]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L617" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-parameter-self-name-str-param-optional-tensorplay-nn-parameter-parameter-none-source-1" aria-label="Permalink to &quot;`register_parameter(self, name: str, param: Optional[tensorplay.nn.parameter.Parameter]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L617)&quot;">​</a></h4><p>Add a parameter to the module.</p><p>The parameter can be accessed as an attribute using given name.</p><h4 id="args-46" tabindex="-1">Args <a class="header-anchor" href="#args-46" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>name</strong> (<code>str</code>): name of the parameter. The parameter can be accessed from this module using the given name</li><li><strong>param</strong> (<code>Parameter or None</code>): parameter to be added to the module. If <code>None</code>, then operations that run on parameters, such as <code>cuda</code>, are ignored. If <code>None</code>, the parameter is <strong>not</strong> included in the module&#39;s <code>state_dict</code>.</li></ul><hr><h4 id="register-state-dict-post-hook-self-hook-source-1" tabindex="-1"><code>register_state_dict_post_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2017" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-state-dict-post-hook-self-hook-source-1" aria-label="Permalink to &quot;`register_state_dict_post_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2017)&quot;">​</a></h4><p>Register a post-hook for the <code>~tensorplay.nn.Module.state_dict</code> method.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, state_dict, prefix, local_metadata) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The registered hooks can modify the <code>state_dict</code> inplace.</p><hr><h4 id="register-state-dict-pre-hook-self-hook-source-1" tabindex="-1"><code>register_state_dict_pre_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2041" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-state-dict-pre-hook-self-hook-source-1" aria-label="Permalink to &quot;`register_state_dict_pre_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2041)&quot;">​</a></h4><p>Register a pre-hook for the <code>~tensorplay.nn.Module.state_dict</code> method.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, prefix, keep_vars) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The registered hooks can be used to perform pre-processing before the <code>state_dict</code> call is made.</p><hr><h4 id="requires-grad-self-requires-grad-bool-true-self-source-1" tabindex="-1"><code>requires_grad_(self, requires_grad: bool = True) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2826" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#requires-grad-self-requires-grad-bool-true-self-source-1" aria-label="Permalink to &quot;`requires_grad_(self, requires_grad: bool = True) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2826)&quot;">​</a></h4><p>Change if autograd should record operations on parameters in this module.</p><p>This method sets the parameters&#39; <code>requires_grad</code> attributes in-place.</p><p>This method is helpful for freezing part of the module for finetuning or training parts of a model individually (e.g., GAN training).</p><p>有关 <code>.eval()</code> 和其他类似机制的比较， <code>.requires_grad_()</code> and several similar mechanisms that may be confused with it.</p><h4 id="args-47" tabindex="-1">Args <a class="header-anchor" href="#args-47" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>requires_grad</strong> (<code>bool</code>): whether autograd should record operations on parameters in this module. 默认值： <code>True</code>.</li></ul><h4 id="returns-44" tabindex="-1">Returns <a class="header-anchor" href="#returns-44" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="set-extra-state-self-state-any-none-source-1" tabindex="-1"><code>set_extra_state(self, state: Any) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L938" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#set-extra-state-self-state-any-none-source-1" aria-label="Permalink to &quot;`set_extra_state(self, state: Any) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L938)&quot;">​</a></h4><p>Set extra state contained in the loaded <code>state_dict</code>.</p><p>This function is called from <code>load_state_dict</code> to handle any extra state found within the <code>state_dict</code>. Implement this function and a corresponding <code>get_extra_state</code> for your module if you need to store extra state within its <code>state_dict</code>.</p><h4 id="args-48" tabindex="-1">Args <a class="header-anchor" href="#args-48" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state</strong> (<code>dict</code>): Extra state from the <code>state_dict</code></li></ul><hr><h4 id="set-submodule-self-target-str-module-module-strict-bool-false-none-source-1" tabindex="-1"><code>set_submodule(self, target: str, module: &#39;Module&#39;, strict: bool = False) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L764" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#set-submodule-self-target-str-module-module-strict-bool-false-none-source-1" aria-label="Permalink to &quot;`set_submodule(self, target: str, module: &#39;Module&#39;, strict: bool = False) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L764)&quot;">​</a></h4><p>Set the submodule given by <code>target</code> if it exists, otherwise throw an error.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>If <code>strict</code> is set to <code>False</code> (default), the method will replace an existing submodule or create a new submodule if the parent module exists. If <code>strict</code> is set to <code>True</code>, the method will only attempt to replace an existing submodule and throw an error if the submodule does not exist.</p></div><p>For example, let&#39;s say you have an <code>nn.Module</code> <code>A</code> that looks like this:</p><p>.. code-block:: text</p><ul><li><strong>A</strong> (<code> (net_b</code>): Module( (net_c): Module( (conv): Conv2d(3, 3, 3) ) (linear): Linear(3, 3) ) )</li></ul><p>(The diagram shows an <code>nn.Module</code> <code>A</code>. <code>A</code> has a nested submodule <code>net_b</code>, which itself has two submodules <code>net_c</code> and <code>linear</code>. <code>net_c</code> then has a submodule <code>conv</code>.)</p><p>To override the <code>Conv2d</code> with a new submodule <code>Linear</code>, you could call <code>set_submodule(&quot;net_b.net_c.conv&quot;, nn.Linear(1, 1))</code> where <code>strict</code> could be <code>True</code> or <code>False</code></p><p>To add a new submodule <code>Conv2d</code> to the existing <code>net_b</code> module, you would call <code>set_submodule(&quot;net_b.conv&quot;, nn.Conv2d(1, 1, 1))</code>.</p><p>In the above if you set <code>strict=True</code> and call <code>set_submodule(&quot;net_b.conv&quot;, nn.Conv2d(1, 1, 1), strict=True)</code>, an AttributeError will be raised because <code>net_b</code> does not have a submodule named <code>conv</code>.</p><h4 id="args-49" tabindex="-1">Args <a class="header-anchor" href="#args-49" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: The fully-qualified string name of the submodule to look for. (See above example for how to specify a fully-qualified string.)</li><li><strong>module</strong>: The module to set the submodule to.</li><li><strong>strict</strong>: If <code>False</code>, the method will replace an existing submodule or create a new submodule if the parent module exists. If <code>True</code>, the method will only attempt to replace an existing submodule and throw an error if the submodule doesn&#39;t already exist.</li></ul><h4 id="raises-7" tabindex="-1">Raises <a class="header-anchor" href="#raises-7" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the <code>target</code> string is empty or if <code>module</code> is not an instance of <code>nn.Module</code>.</li><li><strong>AttributeError</strong>: If at any point along the path resulting from the <code>target</code> string the (sub)path resolves to a non-existent attribute name or an object that is not an instance of <code>nn.Module</code>.</li></ul><hr><h4 id="share-memory-self-self-source-1" tabindex="-1"><code>share_memory(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2877" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#share-memory-self-self-source-1" aria-label="Permalink to &quot;`share_memory(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2877)&quot;">​</a></h4><p>See <code>tensorplay.Tensor.share_memory_</code>.</p><hr><h4 id="state-dict-self-args-destination-none-prefix-keep-vars-false-source-1" tabindex="-1"><code>state_dict(self, *args, destination=None, prefix=&#39;&#39;, keep_vars=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2105" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-args-destination-none-prefix-keep-vars-false-source-1" aria-label="Permalink to &quot;`state_dict(self, *args, destination=None, prefix=&#39;&#39;, keep_vars=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2105)&quot;">​</a></h4><p>Return a dictionary containing references to the whole state of the module.</p><p>Both parameters and persistent buffers (e.g. running averages) are included. Keys are corresponding parameter and buffer names. Parameters and buffers set to <code>None</code> are not included.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>The returned object is a shallow copy. It contains references to the module&#39;s parameters and buffers.</p></div><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>Currently <code>state_dict()</code> also accepts positional arguments for <code>destination</code>, <code>prefix</code> and <code>keep_vars</code> in order. However, this is being deprecated and keyword arguments will be enforced in future releases.</p></div><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>Please avoid the use of argument <code>destination</code> as it is not designed for end-users.</p></div><h4 id="args-50" tabindex="-1">Args <a class="header-anchor" href="#args-50" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>destination</strong> (<code>dict, optional</code>): If provided, the state of module will be updated into the dict and the same object is returned. Otherwise, an <code>OrderedDict</code> will be created and returned.</li><li><strong>Default</strong>: <code>None</code>.</li><li><strong>prefix</strong> (<code>str, optional</code>): a prefix added to parameter and buffer names to compose the keys in state_dict. 默认值： <code>&#39;&#39;</code>.</li><li><strong>keep_vars</strong> (<code>bool, optional</code>): by default the <code>~tensorplay.Tensor</code> s returned in the state dict are detached from autograd. If it&#39;s set to <code>True</code>, detaching will not be performed.</li><li><strong>Default</strong>: <code>False</code>.</li></ul><h4 id="returns-45" tabindex="-1">Returns <a class="header-anchor" href="#returns-45" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>dict</strong>: a dictionary containing a whole state of the module</li></ul><h4 id="example-19" tabindex="-1">Example <a class="header-anchor" href="#example-19" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">module.state_dict().keys()</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;bias&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;weight&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><hr><h4 id="to-self-args-kwargs-source-1" tabindex="-1"><code>to(self, *args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1151" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#to-self-args-kwargs-source-1" aria-label="Permalink to &quot;`to(self, *args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1151)&quot;">​</a></h4><p>Move and/or cast the parameters and buffers.</p><p>This can be called as</p><p>.. function:: to(device=None, dtype=None, non_blocking=False) :noindex:</p><p>.. function:: to(dtype, non_blocking=False) :noindex:</p><p>.. function:: to(tensor, non_blocking=False) :noindex:</p><p>.. function:: to(memory_format=tensorplay.channels_last) :noindex:</p><p>Its signature is similar to <code>tensorplay.Tensor.to</code>, but only accepts floating point or complex <code>dtype</code>\\ s. In addition, this method will only cast the floating point or complex parameters and buffers to <code>dtype</code> (if given). The integral parameters and buffers will be moved <code>device</code>, if that is given, but with dtypes unchanged. When <code>non_blocking</code> is set, it tries to convert/move asynchronously with respect to the host if possible, e.g., moving CPU Tensors with pinned memory to CUDA devices.</p><p>See below for examples.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="args-51" tabindex="-1">Args <a class="header-anchor" href="#args-51" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>device</strong> (<code>tensorplay.device</code>): the desired device of the parameters and buffers in this module</li><li><strong>dtype</strong> (<code>tensorplay.dtype</code>): the desired floating point or complex dtype of the parameters and buffers in this module</li><li><strong>tensor</strong> (<code>tensorplay.Tensor</code>): Tensor whose dtype and device are the desired dtype and device for all parameters and buffers in this module</li><li><strong>memory_format</strong> (<code>tensorplay.memory_format</code>): the desired memory format for 4D parameters and buffers in this module (keyword only argument)</li></ul><h4 id="returns-46" tabindex="-1">Returns <a class="header-anchor" href="#returns-46" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><h4 id="examples-3" tabindex="-1">Examples <a class="header-anchor" href="#examples-3" aria-label="Permalink to &quot;Examples&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +IGNORE_WANT(&quot;non-deterministic&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1913</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5113</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2325</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.to(tensorplay.double)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1913</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5113</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2325</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.float64)</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +REQUIRES(env:TENSORPLAY_DOCTEST_CUDA1)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpu1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.device(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cuda:1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.to(gpu1, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.half, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">non_blocking</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1914</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5112</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2324</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.float16, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">device</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;cuda:1&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.device(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cpu&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.to(cpu)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1914</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5112</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2324</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.float16)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).to(tensorplay.cdouble)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3741</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2382</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5593</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4443</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.complex128)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear(tensorplay.ones(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.cdouble))</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6122</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1150</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6122</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1150</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6122</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1150</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.complex128)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br></div></div><hr><h4 id="to-empty-self-device-union-str-tensorplay-device-int-nonetype-recurse-bool-true-self-source-1" tabindex="-1"><code>to_empty(self, *, device: Union[str, tensorplay.Device, int, NoneType], recurse: bool = True) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1119" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#to-empty-self-device-union-str-tensorplay-device-int-nonetype-recurse-bool-true-self-source-1" aria-label="Permalink to &quot;`to_empty(self, *, device: Union[str, tensorplay.Device, int, NoneType], recurse: bool = True) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1119)&quot;">​</a></h4><p>Move the parameters and buffers to the specified device without copying storage.</p><h4 id="args-52" tabindex="-1">Args <a class="header-anchor" href="#args-52" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>device</strong> (<code>tensorplay.device</code>): The desired device of the parameters and buffers in this module.</li><li><strong>recurse</strong> (<code>bool</code>): Whether parameters and buffers of submodules should be recursively moved to the specified device.</li></ul><h4 id="returns-47" tabindex="-1">Returns <a class="header-anchor" href="#returns-47" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="train-self-mode-bool-true-self-source-1" tabindex="-1"><code>train(self, mode: bool = True) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2786" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#train-self-mode-bool-true-self-source-1" aria-label="Permalink to &quot;`train(self, mode: bool = True) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2786)&quot;">​</a></h4><p>Set the module in training mode.</p><p>这仅对某些模块有影响。请参阅特定模块的文档 了解它们在训练/评估模式下的行为细节， mode, i.e., whether they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>, 等。</p><h4 id="args-53" tabindex="-1">Args <a class="header-anchor" href="#args-53" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>mode</strong> (<code>bool</code>): whether to set training mode (<code>True</code>) or evaluation mode (<code>False</code>). 默认值： <code>True</code>.</li></ul><h4 id="returns-48" tabindex="-1">Returns <a class="header-anchor" href="#returns-48" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="type-self-dst-type-union-tensorplay-dtype-str-self-source-1" tabindex="-1"><code>type(self, dst_type: Union[tensorplay.DType, str]) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1061" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#type-self-dst-type-union-tensorplay-dtype-str-self-source-1" aria-label="Permalink to &quot;`type(self, dst_type: Union[tensorplay.DType, str]) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1061)&quot;">​</a></h4><p>Casts all parameters and buffers to <code>dst_type</code>.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="args-54" tabindex="-1">Args <a class="header-anchor" href="#args-54" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>dst_type</strong> (<code>type or string</code>): the desired type</li></ul><h4 id="returns-49" tabindex="-1">Returns <a class="header-anchor" href="#returns-49" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="zero-grad-self-set-to-none-bool-true-none-source-1" tabindex="-1"><code>zero_grad(self, set_to_none: bool = True) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2849" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#zero-grad-self-set-to-none-bool-true-none-source-1" aria-label="Permalink to &quot;`zero_grad(self, set_to_none: bool = True) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2849)&quot;">​</a></h4><p>Reset gradients of all model parameters.</p><p>See similar function under <code>tensorplay.optim.Optimizer</code> for more context.</p><h4 id="args-55" tabindex="-1">Args <a class="header-anchor" href="#args-55" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>set_to_none</strong> (<code>bool</code>): instead of setting to zero, set the grads to None. See <code>tensorplay.optim.Optimizer.zero_grad</code> for details.</li></ul><hr></details><h3 id="class-linear-source" tabindex="-1"><code>class Linear</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L50" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-linear-source" aria-label="Permalink to &quot;`class Linear` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L50)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(in_features: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, out_features: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, bias: </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">device</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>Module</code></p>',6)),i("p",null,[l[65]||(l[65]=n("Applies an affine linear transformation to the incoming data: ",-1)),i("mjx-container",S,[(a(),s("svg",I,[...l[63]||(l[63]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="msup" transform="translate(2395.6,0)"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(783,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3948.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(4948.8,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[64]||(l[64]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mi",null,"y"),i("mo",null,"="),i("mi",null,"x"),i("msup",null,[i("mi",null,"A"),i("mi",null,"T")]),i("mo",null,"+"),i("mi",null,"b")])],-1))]),l[66]||(l[66]=n(".",-1))]),l[113]||(l[113]=t('<h4 id="args-56" tabindex="-1">Args <a class="header-anchor" href="#args-56" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>in_features</strong>: 每个输入样本的大小</li><li><strong>out_features</strong>: size of each output sample</li><li><strong>bias</strong>: 如果设置为 <code>False</code>，该层将不会学习加性偏置。</li><li><strong>Default</strong>: <code>True</code></li></ul><h4 id="shape-2" tabindex="-1">Shape <a class="header-anchor" href="#shape-2" aria-label="Permalink to &quot;Shape&quot;">​</a></h4>',3)),i("ul",null,[i("li",null,[l[73]||(l[73]=n("Input: ",-1)),i("mjx-container",j,[(a(),s("svg",O,[...l[67]||(l[67]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1333.7,0)"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2837.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[68]||(l[68]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mo",null,"∗"),i("mo",null,","),i("msub",null,[i("mi",null,"H"),i("mtext",null,"in")]),i("mo",{stretchy:"false"},")")])],-1))]),l[74]||(l[74]=n(" where ",-1)),i("mjx-container",z,[(a(),s("svg",U,[...l[69]||(l[69]=[i("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[i("g",{"data-mml-node":"math"},[i("g",{"data-mml-node":"mo"},[i("path",{"data-c":"2217",d:"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z",style:{"stroke-width":"3"}})])])],-1)])])),l[70]||(l[70]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",null,"∗")])],-1))]),l[75]||(l[75]=n(" means any number of dimensions including none and ",-1)),i("mjx-container",Y,[(a(),s("svg",G,[...l[71]||(l[71]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1781.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(2837.3,0)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1640,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2084,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(2973,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(3529,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(3921,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4365,0)" style="stroke-width:3;"></path></g></g></g>',1)])])),l[72]||(l[72]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("msub",null,[i("mi",null,"H"),i("mtext",null,"in")]),i("mo",null,"="),i("mtext",null,"in_features")])],-1))]),l[76]||(l[76]=n(".",-1))]),i("li",null,[l[81]||(l[81]=n("输出： ",-1)),i("mjx-container",J,[(a(),s("svg",K,[...l[77]||(l[77]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1333.7,0)"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3269.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[78]||(l[78]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mo",null,"∗"),i("mo",null,","),i("msub",null,[i("mi",null,"H"),i("mtext",null,"out")]),i("mo",{stretchy:"false"},")")])],-1))]),l[82]||(l[82]=n(" where all but the last dimension are the same shape as the input and ",-1)),i("mjx-container",W,[(a(),s("svg",X,[...l[79]||(l[79]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(864,-150) scale(0.707)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2213.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(3269.3,0)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1945,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2251,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2695,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3195,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3584,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4140,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4532,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4976,0)" style="stroke-width:3;"></path></g></g></g>',1)])])),l[80]||(l[80]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("msub",null,[i("mi",null,"H"),i("mtext",null,"out")]),i("mo",null,"="),i("mtext",null,"out_features")])],-1))]),l[83]||(l[83]=n(".",-1))])]),l[114]||(l[114]=i("h4",{id:"attributes-1",tabindex:"-1"},[n("Attributes "),i("a",{class:"header-anchor",href:"#attributes-1","aria-label":'Permalink to "Attributes"'},"​")],-1)),i("ul",null,[i("li",null,[l[90]||(l[90]=i("strong",null,"weight",-1)),l[91]||(l[91]=n(": 形状为 ... 的模块的可学习权重 ",-1)),i("mjx-container",$,[(a(),s("svg",ee,[...l[84]||(l[84]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(389,0)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1945,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2251,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2695,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3195,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3584,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4140,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4532,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4976,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5759,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(6203.7,0)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1640,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2084,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(2973,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(3529,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(3921,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4365,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(10962.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[85]||(l[85]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mtext",null,"out_features"),i("mo",null,","),i("mtext",null,"in_features"),i("mo",{stretchy:"false"},")")])],-1))]),l[92]||(l[92]=n(". The values are initialized from ",-1)),i("mjx-container",se,[(a(),s("svg",ae,[...l[86]||(l[86]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="55" d="M8 592Q8 616 70 649T193 683Q246 683 246 631Q246 587 205 492T124 297T83 143Q83 101 100 75T154 48Q202 48 287 135T450 342T560 553Q589 635 593 640Q603 656 626 668T669 683H670Q687 683 687 672T670 616T617 463T547 220Q525 137 521 68Q521 54 522 50T533 42L543 47Q573 61 588 61Q604 61 604 47Q599 16 506 -22Q486 -28 468 -28T436 -18T421 18Q421 92 468 258Q468 259 467 257T459 248Q426 206 391 167T303 81T194 6T83 -22Q66 -22 58 -20Q25 -11 4 19T-17 99Q-17 146 8 220T64 358T120 488T146 586Q146 604 141 608T123 613H120Q99 613 72 597T25 580Q8 580 8 592Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1076,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msqrt" transform="translate(1854,0)"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z" style="stroke-width:3;"></path></g><rect width="521" height="60" x="853" y="849"></rect></g><g data-mml-node="mo" transform="translate(3228,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msqrt" transform="translate(3672.7,0)"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z" style="stroke-width:3;"></path></g><rect width="521" height="60" x="853" y="849"></rect></g><g data-mml-node="mo" transform="translate(5046.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[87]||(l[87]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mrow",{"data-mjx-texclass":"ORD"},[i("mi",{"data-mjx-variant":"-tex-calligraphic",mathvariant:"script"},"U")]),i("mo",{stretchy:"false"},"("),i("mo",null,"−"),i("msqrt",null,[i("mi",null,"k")]),i("mo",null,","),i("msqrt",null,[i("mi",null,"k")]),i("mo",{stretchy:"false"},")")])],-1))]),l[93]||(l[93]=n(", where ",-1)),i("mjx-container",te,[(a(),s("svg",ie,[...l[88]||(l[88]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(798.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(1854.6,0)"><g data-mml-node="mn" transform="translate(1725.8,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(220,-345) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1640,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2084,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(2973,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(3529,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(3921,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4365,0)" style="stroke-width:3;"></path></g><rect width="3565.1" height="60" x="120" y="220"></rect></g></g></g>',1)])])),l[89]||(l[89]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mi",null,"k"),i("mo",null,"="),i("mfrac",null,[i("mn",null,"1"),i("mtext",null,"in_features")])])],-1))])]),i("li",null,[l[100]||(l[100]=i("strong",null,"bias",-1)),l[101]||(l[101]=n(": 形状为 ... 的模块的可学习偏置 ",-1)),i("mjx-container",ne,[(a(),s("svg",le,[...l[94]||(l[94]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(389,0)"><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1945,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2251,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2695,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3195,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(3584,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4140,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4532,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4976,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5759,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[95]||(l[95]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mo",{stretchy:"false"},"("),i("mtext",null,"out_features"),i("mo",{stretchy:"false"},")")])],-1))]),l[102]||(l[102]=n(". If ",-1)),l[103]||(l[103]=i("code",null,"bias",-1)),l[104]||(l[104]=n(" is ",-1)),l[105]||(l[105]=i("code",null,"True",-1)),l[106]||(l[106]=n(", the values are initialized from ",-1)),i("mjx-container",oe,[(a(),s("svg",re,[...l[96]||(l[96]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="55" d="M8 592Q8 616 70 649T193 683Q246 683 246 631Q246 587 205 492T124 297T83 143Q83 101 100 75T154 48Q202 48 287 135T450 342T560 553Q589 635 593 640Q603 656 626 668T669 683H670Q687 683 687 672T670 616T617 463T547 220Q525 137 521 68Q521 54 522 50T533 42L543 47Q573 61 588 61Q604 61 604 47Q599 16 506 -22Q486 -28 468 -28T436 -18T421 18Q421 92 468 258Q468 259 467 257T459 248Q426 206 391 167T303 81T194 6T83 -22Q66 -22 58 -20Q25 -11 4 19T-17 99Q-17 146 8 220T64 358T120 488T146 586Q146 604 141 608T123 613H120Q99 613 72 597T25 580Q8 580 8 592Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1076,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msqrt" transform="translate(1854,0)"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z" style="stroke-width:3;"></path></g><rect width="521" height="60" x="853" y="849"></rect></g><g data-mml-node="mo" transform="translate(3228,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msqrt" transform="translate(3672.7,0)"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z" style="stroke-width:3;"></path></g><rect width="521" height="60" x="853" y="849"></rect></g><g data-mml-node="mo" transform="translate(5046.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),l[97]||(l[97]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mrow",{"data-mjx-texclass":"ORD"},[i("mi",{"data-mjx-variant":"-tex-calligraphic",mathvariant:"script"},"U")]),i("mo",{stretchy:"false"},"("),i("mo",null,"−"),i("msqrt",null,[i("mi",null,"k")]),i("mo",null,","),i("msqrt",null,[i("mi",null,"k")]),i("mo",{stretchy:"false"},")")])],-1))]),l[107]||(l[107]=n(" where ",-1)),i("mjx-container",he,[(a(),s("svg",pe,[...l[98]||(l[98]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(798.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(1854.6,0)"><g data-mml-node="mn" transform="translate(1725.8,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(220,-345) scale(0.707)"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(1334,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1640,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2084,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2584,0)" style="stroke-width:3;"></path><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(2973,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(3529,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(3921,0)" style="stroke-width:3;"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(4365,0)" style="stroke-width:3;"></path></g><rect width="3565.1" height="60" x="120" y="220"></rect></g></g></g>',1)])])),l[99]||(l[99]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mi",null,"k"),i("mo",null,"="),i("mfrac",null,[i("mn",null,"1"),i("mtext",null,"in_features")])])],-1))])])]),l[115]||(l[115]=t('<h4 id="examples-4" tabindex="-1">Examples <a class="header-anchor" href="#examples-4" aria-label="Permalink to &quot;Examples&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">m </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tp.nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">30</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tp.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> m(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(output.size())</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.Size([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">30</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><details><summary>Methods</summary><h4 id="init-self-in-features-int-out-features-int-bias-bool-true-device-none-dtype-none-none-source" tabindex="-1"><code>__init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L89" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-in-features-int-out-features-int-bias-bool-true-device-none-dtype-none-none-source" aria-label="Permalink to &quot;`__init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L89)&quot;">​</a></h4><p>初始化内部 Module 状态，由 nn.Module 和 ScriptModule 共享。</p><hr><h4 id="add-module-self-name-str-module-optional-forwardref-module-none-source-2" tabindex="-1"><code>add_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L667" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#add-module-self-name-str-module-optional-forwardref-module-none-source-2" aria-label="Permalink to &quot;`add_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L667)&quot;">​</a></h4><p>将子模块添加到当前模块。</p><p>可以使用给定名称作为属性访问该模块。</p><h4 id="args-57" tabindex="-1">Args <a class="header-anchor" href="#args-57" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>name</strong> (<code>str</code>): 子模块的名称。可以使用给定名称 从该模块访问子模块</li><li><strong>module</strong> (<code>Module</code>): 要添加到模块的子模块。</li></ul><hr><h4 id="apply-self-fn-callable-forwardref-module-nonetype-self-source-2" tabindex="-1"><code>apply(self, fn: Callable[[ForwardRef(&#39;Module&#39;)], NoneType]) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L990" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#apply-self-fn-callable-forwardref-module-nonetype-self-source-2" aria-label="Permalink to &quot;`apply(self, fn: Callable[[ForwardRef(&#39;Module&#39;)], NoneType]) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L990)&quot;">​</a></h4><p>递归地将 <code>fn</code> 应用于每个子模块（由 <code>.children()</code> 返回）以及自身。</p><p>典型用途包括初始化模型的参数 (see also <code>nn-init-doc</code>).</p><h4 id="args-58" tabindex="-1">Args <a class="header-anchor" href="#args-58" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>fn</strong> (``Module<code> -&gt; None</code>): 应用于每个子模块的函数</li></ul><h4 id="returns-50" tabindex="-1">Returns <a class="header-anchor" href="#returns-50" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><h4 id="example-20" tabindex="-1">Example <a class="header-anchor" href="#example-20" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.no_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> init_weights</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m):</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        m.weight.fill_(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m.weight)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.apply(init_weights)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">., </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Sequential(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><hr><h4 id="bfloat16-self-self-source-2" tabindex="-1"><code>bfloat16(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1108" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#bfloat16-self-self-source-2" aria-label="Permalink to &quot;`bfloat16(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1108)&quot;">​</a></h4><p>将所有浮点参数和缓冲区转换为 <code>bfloat16</code> 数据类型。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-51" tabindex="-1">Returns <a class="header-anchor" href="#returns-51" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="buffers-self-recurse-bool-true-collections-abc-iterator-tensorplay-c-tensorbase-source-2" tabindex="-1"><code>buffers(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay._C.TensorBase]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2627" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#buffers-self-recurse-bool-true-collections-abc-iterator-tensorplay-c-tensorbase-source-2" aria-label="Permalink to &quot;`buffers(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay._C.TensorBase]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2627)&quot;">​</a></h4><p>返回模块缓冲区的迭代器。</p><h4 id="args-59" tabindex="-1">Args <a class="header-anchor" href="#args-59" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>recurse</strong> (<code>bool</code>): 如果为 True，则生成此模块的缓冲区 以及所有子模块的缓冲区。否则，仅生成 此模块的直接成员缓冲区。</li></ul><h4 id="yields-16" tabindex="-1">Yields <a class="header-anchor" href="#yields-16" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>tensorplay.Tensor: 模块缓冲区\n</code></pre><h4 id="example-21" tabindex="-1">Example <a class="header-anchor" href="#example-21" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> buf </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.buffers():</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(buf), buf.size())</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><hr><h4 id="children-self-collections-abc-iterator-module-source-2" tabindex="-1"><code>children(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2681" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#children-self-collections-abc-iterator-module-source-2" aria-label="Permalink to &quot;`children(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2681)&quot;">​</a></h4><p>返回直接子模块的迭代器。</p><h4 id="yields-17" tabindex="-1">Yields <a class="header-anchor" href="#yields-17" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><ul><li><strong>Module</strong>: 一个子模块</li></ul><hr><h4 id="compile-self-args-kwargs-source-2" tabindex="-1"><code>compile(self, *args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2944" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#compile-self-args-kwargs-source-2" aria-label="Permalink to &quot;`compile(self, *args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2944)&quot;">​</a></h4><p>使用 <code>tensorplay.compile</code> 编译此模块的前向传播。</p><p>此模块的 <code>__call__</code> 方法被编译，所有参数按原样传递 给 <code>tensorplay.compile</code>。</p><p>有关此函数的参数详情，请参阅 <code>tensorplay.compile</code>。</p><hr><h4 id="cpu-self-self-source-2" tabindex="-1"><code>cpu(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1050" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#cpu-self-self-source-2" aria-label="Permalink to &quot;`cpu(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1050)&quot;">​</a></h4><p>将所有模型参数和缓冲区移动到 CPU。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-52" tabindex="-1">Returns <a class="header-anchor" href="#returns-52" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="cuda-self-device-union-int-tensorplay-device-nonetype-none-self-source-2" tabindex="-1"><code>cuda(self, device: Union[int, tensorplay.Device, NoneType] = None) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1031" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#cuda-self-device-union-int-tensorplay-device-nonetype-none-self-source-2" aria-label="Permalink to &quot;`cuda(self, device: Union[int, tensorplay.Device, NoneType] = None) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1031)&quot;">​</a></h4><p>将所有模型参数和缓冲区移动到 GPU。</p><p>这也使得关联的参数和缓冲区成为不同的对象。所以 如果模块将在 GPU 上运行并进行优化， 应在构建优化器之前调用它。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="args-60" tabindex="-1">Args <a class="header-anchor" href="#args-60" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>device</strong> (<code>int, optional</code>): 如果指定，所有参数将被 复制到该设备</li></ul><h4 id="returns-53" tabindex="-1">Returns <a class="header-anchor" href="#returns-53" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="double-self-self-source-2" tabindex="-1"><code>double(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1086" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#double-self-self-source-2" aria-label="Permalink to &quot;`double(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1086)&quot;">​</a></h4><p>将所有浮点参数和缓冲区转换为 <code>double</code> 数据类型。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-54" tabindex="-1">Returns <a class="header-anchor" href="#returns-54" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="eval-self-self-source-2" tabindex="-1"><code>eval(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2808" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#eval-self-self-source-2" aria-label="Permalink to &quot;`eval(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2808)&quot;">​</a></h4><p>将模块设置为评估模式。</p><p>这仅对某些模块有影响。请参阅特定模块的文档 了解它们在训练/评估模式下的行为细节， 即它们是否受影响，例如 <code>Dropout</code>、<code>BatchNorm</code> 等。</p><p>这相当于 <code>self.train(False) &lt;tensorplay.nn.Module.train&gt;</code>。</p><p>有关 <code>.eval()</code> 和其他类似机制的比较， <code>.eval()</code> and several similar mechanisms that may be confused with it.</p><h4 id="returns-55" tabindex="-1">Returns <a class="header-anchor" href="#returns-55" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="extra-repr-self-str-source-2" tabindex="-1"><code>extra_repr(self) -&gt; str</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L129" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#extra-repr-self-str-source-2" aria-label="Permalink to &quot;`extra_repr(self) -&gt; str` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L129)&quot;">​</a></h4><p>返回模块的额外表示。</p><hr><h4 id="float-self-self-source-2" tabindex="-1"><code>float(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1075" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#float-self-self-source-2" aria-label="Permalink to &quot;`float(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1075)&quot;">​</a></h4><p>将所有浮点参数和缓冲区转换为 <code>float</code> 数据类型。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-56" tabindex="-1">Returns <a class="header-anchor" href="#returns-56" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="forward-self-input-tensorplay-c-tensorbase-tensorplay-c-tensorbase-source-1" tabindex="-1"><code>forward(self, input: tensorplay._C.TensorBase) -&gt; tensorplay._C.TensorBase</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L123" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#forward-self-input-tensorplay-c-tensorbase-tensorplay-c-tensorbase-source-1" aria-label="Permalink to &quot;`forward(self, input: tensorplay._C.TensorBase) -&gt; tensorplay._C.TensorBase` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L123)&quot;">​</a></h4><p>运行前向传播。</p><hr><h4 id="get-buffer-self-target-str-tensor-source-2" tabindex="-1"><code>get_buffer(self, target: str) -&gt; &#39;Tensor&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L881" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-buffer-self-target-str-tensor-source-2" aria-label="Permalink to &quot;`get_buffer(self, target: str) -&gt; &#39;Tensor&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L881)&quot;">​</a></h4><p>如果存在，则返回由 <code>target</code> 指定的缓冲区，否则抛出错误。</p><p>See the docstring for <code>get_submodule</code> for a more detailed explanation of this method&#39;s functionality as well as how to correctly specify <code>target</code>.</p><h4 id="args-61" tabindex="-1">Args <a class="header-anchor" href="#args-61" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: 缓冲区的完全限定字符串名称 to look for. (See <code>get_submodule</code> for how to specify a fully-qualified string.)</li></ul><h4 id="returns-57" tabindex="-1">Returns <a class="header-anchor" href="#returns-57" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>tensorplay.Tensor: 由 ``target`` 引用的缓冲区\n</code></pre><h4 id="raises-8" tabindex="-1">Raises <a class="header-anchor" href="#raises-8" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>AttributeError</strong>: If the target string references an invalid path or resolves to something that is not a buffer</li></ul><hr><h4 id="get-extra-state-self-any-source-2" tabindex="-1"><code>get_extra_state(self) -&gt; Any</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L917" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-extra-state-self-any-source-2" aria-label="Permalink to &quot;`get_extra_state(self) -&gt; Any` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L917)&quot;">​</a></h4><p>返回要包含在模块 state_dict 中的任何额外状态。</p><p>Implement this and a corresponding <code>set_extra_state</code> for your module if you need to store extra state. This function is called when building the module&#39;s <code>state_dict()</code>.</p><p>Note that extra state should be picklable to ensure working serialization of the state_dict. We only provide backwards compatibility guarantees for serializing Tensors; other objects may break backwards compatibility if their serialized pickled form changes.</p><h4 id="returns-58" tabindex="-1">Returns <a class="header-anchor" href="#returns-58" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>object</strong>: Any extra state to store in the module&#39;s state_dict</li></ul><hr><h4 id="get-parameter-self-target-str-parameter-source-2" tabindex="-1"><code>get_parameter(self, target: str) -&gt; &#39;Parameter&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L845" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-parameter-self-target-str-parameter-source-2" aria-label="Permalink to &quot;`get_parameter(self, target: str) -&gt; &#39;Parameter&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L845)&quot;">​</a></h4><p>如果存在，则返回由 <code>target</code> 指定的参数，否则抛出错误。</p><p>See the docstring for <code>get_submodule</code> for a more detailed explanation of this method&#39;s functionality as well as how to correctly specify <code>target</code>.</p><h4 id="args-62" tabindex="-1">Args <a class="header-anchor" href="#args-62" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: The fully-qualified string name of the Parameter to look for. (See <code>get_submodule</code> for how to specify a fully-qualified string.)</li></ul><h4 id="returns-59" tabindex="-1">Returns <a class="header-anchor" href="#returns-59" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>tensorplay.nn.Parameter: The Parameter referenced by ``target``\n</code></pre><h4 id="raises-9" tabindex="-1">Raises <a class="header-anchor" href="#raises-9" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>AttributeError</strong>: If the target string references an invalid path or resolves to something that is not an <code>nn.Parameter</code></li></ul><hr><h4 id="get-submodule-self-target-str-module-source-2" tabindex="-1"><code>get_submodule(self, target: str) -&gt; &#39;Module&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L699" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-submodule-self-target-str-module-source-2" aria-label="Permalink to &quot;`get_submodule(self, target: str) -&gt; &#39;Module&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L699)&quot;">​</a></h4><p>Return the submodule given by <code>target</code> if it exists, otherwise throw an error.</p><p>For example, let&#39;s say you have an <code>nn.Module</code> <code>A</code> that looks like this:</p><p>.. code-block:: text</p><ul><li><strong>A</strong> (<code> (net_b</code>): Module( (net_c): Module( (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2)) ) (linear): Linear(in_features=100, out_features=200, bias=True) ) )</li></ul><p>(The diagram shows an <code>nn.Module</code> <code>A</code>. <code>A</code> which has a nested submodule <code>net_b</code>, which itself has two submodules <code>net_c</code> and <code>linear</code>. <code>net_c</code> then has a submodule <code>conv</code>.)</p><p>To check whether or not we have the <code>linear</code> submodule, we would call <code>get_submodule(&quot;net_b.linear&quot;)</code>. To check whether we have the <code>conv</code> submodule, we would call <code>get_submodule(&quot;net_b.net_c.conv&quot;)</code>.</p><p>The runtime of <code>get_submodule</code> is bounded by the degree of module nesting in <code>target</code>. A query against <code>named_modules</code> achieves the same result, but it is O(N) in the number of transitive modules. So, for a simple check to see if some submodule exists, <code>get_submodule</code> should always be used.</p><h4 id="args-63" tabindex="-1">Args <a class="header-anchor" href="#args-63" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: The fully-qualified string name of the submodule to look for. (See above example for how to specify a fully-qualified string.)</li></ul><h4 id="returns-60" tabindex="-1">Returns <a class="header-anchor" href="#returns-60" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>tensorplay.nn.Module: The submodule referenced by ``target``\n</code></pre><h4 id="raises-10" tabindex="-1">Raises <a class="header-anchor" href="#raises-10" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>AttributeError</strong>: If at any point along the path resulting from the target string the (sub)path resolves to a non-existent attribute name or an object that is not an instance of <code>nn.Module</code>.</li></ul><hr><h4 id="half-self-self-source-2" tabindex="-1"><code>half(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1097" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#half-self-self-source-2" aria-label="Permalink to &quot;`half(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1097)&quot;">​</a></h4><p>Casts all floating point parameters and buffers to <code>half</code> datatype.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="returns-61" tabindex="-1">Returns <a class="header-anchor" href="#returns-61" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="load-state-dict-self-state-dict-collections-abc-mapping-str-typing-any-strict-bool-true-assign-bool-false-source-2" tabindex="-1"><code>load_state_dict(self, state_dict: collections.abc.Mapping[str, typing.Any], strict: bool = True, assign: bool = False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2436" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-collections-abc-mapping-str-typing-any-strict-bool-true-assign-bool-false-source-2" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: collections.abc.Mapping[str, typing.Any], strict: bool = True, assign: bool = False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2436)&quot;">​</a></h4><p>Copy parameters and buffers from <code>state_dict</code> into this module and its descendants.</p><p>If <code>strict</code> is <code>True</code>, then the keys of <code>state_dict</code> must exactly match the keys returned by this module&#39;s <code>~tensorplay.nn.Module.state_dict</code> function.</p><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>If <code>assign</code> is <code>True</code> the optimizer must be created after the call to <code>load_state_dict</code> unless <code>~tensorplay.__future__.get_swap_module_params_on_conversion</code> is <code>True</code>.</p></div><h4 id="args-64" tabindex="-1">Args <a class="header-anchor" href="#args-64" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): a dict containing parameters and persistent buffers.</li><li><strong>strict</strong> (<code>bool, optional</code>): whether to strictly enforce that the keys in <code>state_dict</code> match the keys returned by this module&#39;s <code>~tensorplay.nn.Module.state_dict</code> function. 默认值： <code>True</code></li><li><strong>assign</strong> (<code>bool, optional</code>): When set to <code>False</code>, the properties of the tensors in the current module are preserved whereas setting it to <code>True</code> preserves properties of the Tensors in the state dict. The only exception is the <code>requires_grad</code> field of <code>~tensorplay.nn.Parameter</code> for which the value from the module is preserved. 默认值： <code>False</code></li></ul><h4 id="returns-62" tabindex="-1">Returns <a class="header-anchor" href="#returns-62" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n    * ``missing_keys`` is a list of str containing any keys that are expected\n        by this module but missing from the provided ``state_dict``.\n    * ``unexpected_keys`` is a list of str containing the keys that are not\n        expected by this module but present in the provided ``state_dict``.\n</code></pre><h4 id="note-6" tabindex="-1">Note <a class="header-anchor" href="#note-6" aria-label="Permalink to &quot;Note&quot;">​</a></h4><pre><code>If a parameter or buffer is registered as ``None`` and its corresponding key\nexists in `state_dict`, `load_state_dict` will raise a\n``RuntimeError``.\n</code></pre><hr><h4 id="modules-self-collections-abc-iterator-module-source-2" tabindex="-1"><code>modules(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2710" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#modules-self-collections-abc-iterator-module-source-2" aria-label="Permalink to &quot;`modules(self) -&gt; collections.abc.Iterator[&#39;Module&#39;]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2710)&quot;">​</a></h4><p>Return an iterator over all modules in the network.</p><h4 id="yields-18" tabindex="-1">Yields <a class="header-anchor" href="#yields-18" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><ul><li><strong>Module</strong>: a module in the network</li></ul><h4 id="note-7" tabindex="-1">Note <a class="header-anchor" href="#note-7" aria-label="Permalink to &quot;Note&quot;">​</a></h4><pre><code>Duplicate modules are returned only once. In the following\nexample, ``l`` will be returned only once.\n</code></pre><h4 id="example-22" tabindex="-1">Example <a class="header-anchor" href="#example-22" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(l, l)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx, m </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(net.modules()):</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(idx, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;-&gt;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, m)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Sequential(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><hr><h4 id="named-buffers-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-c-tensorbase-source-2" tabindex="-1"><code>named_buffers(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay._C.TensorBase]]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2650" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-buffers-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-c-tensorbase-source-2" aria-label="Permalink to &quot;`named_buffers(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay._C.TensorBase]]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2650)&quot;">​</a></h4><p>Return an iterator over 模块缓冲区s, yielding both the name of the buffer as well as the buffer itself.</p><h4 id="args-65" tabindex="-1">Args <a class="header-anchor" href="#args-65" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>prefix</strong> (<code>str</code>): prefix to prepend to all buffer names.</li><li><strong>recurse</strong> (<code>bool, optional</code>): 如果为 True，则生成此模块的缓冲区 以及所有子模块的缓冲区。否则，仅生成 此模块的直接成员缓冲区。 Defaults to True.</li><li><strong>remove_duplicate</strong> (<code>bool, optional</code>): whether to remove the duplicated buffers in the result. Defaults to True.</li></ul><h4 id="yields-19" tabindex="-1">Yields <a class="header-anchor" href="#yields-19" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, tensorplay.Tensor): Tuple containing the name and buffer\n</code></pre><h4 id="example-23" tabindex="-1">Example <a class="header-anchor" href="#example-23" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, buf </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.named_buffers():</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;running_var&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(buf.size())</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h4 id="named-children-self-collections-abc-iterator-tuple-str-module-source-2" tabindex="-1"><code>named_children(self) -&gt; collections.abc.Iterator[tuple[str, &#39;Module&#39;]]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2690" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-children-self-collections-abc-iterator-tuple-str-module-source-2" aria-label="Permalink to &quot;`named_children(self) -&gt; collections.abc.Iterator[tuple[str, &#39;Module&#39;]]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2690)&quot;">​</a></h4><p>Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p><h4 id="yields-20" tabindex="-1">Yields <a class="header-anchor" href="#yields-20" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, Module): Tuple containing a name and child module\n</code></pre><h4 id="example-24" tabindex="-1">Example <a class="header-anchor" href="#example-24" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, module </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.named_children():</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;conv4&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;conv5&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(module)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h4 id="named-modules-self-memo-optional-set-module-none-prefix-str-remove-duplicate-bool-true-source-2" tabindex="-1"><code>named_modules(self, memo: Optional[set[&#39;Module&#39;]] = None, prefix: str = &#39;&#39;, remove_duplicate: bool = True)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2737" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-modules-self-memo-optional-set-module-none-prefix-str-remove-duplicate-bool-true-source-2" aria-label="Permalink to &quot;`named_modules(self, memo: Optional[set[&#39;Module&#39;]] = None, prefix: str = &#39;&#39;, remove_duplicate: bool = True)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2737)&quot;">​</a></h4><p>Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p><h4 id="args-66" tabindex="-1">Args <a class="header-anchor" href="#args-66" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>memo</strong>: a memo to store the set of modules already added to the result</li><li><strong>prefix</strong>: a prefix that will be added to the name of the module</li><li><strong>remove_duplicate</strong>: whether to remove the duplicated module instances in the result or not</li></ul><h4 id="yields-21" tabindex="-1">Yields <a class="header-anchor" href="#yields-21" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, Module): Tuple of name and module\n</code></pre><h4 id="note-8" tabindex="-1">Note <a class="header-anchor" href="#note-8" aria-label="Permalink to &quot;Note&quot;">​</a></h4><pre><code>Duplicate modules are returned only once. In the following\nexample, ``l`` will be returned only once.\n</code></pre><h4 id="example-25" tabindex="-1">Example <a class="header-anchor" href="#example-25" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(l, l)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx, m </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(net.named_modules()):</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(idx, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;-&gt;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, m)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Sequential(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> -&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;0&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><hr><h4 id="named-parameters-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-nn-parameter-parameter-source-2" tabindex="-1"><code>named_parameters(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay.nn.parameter.Parameter]]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2595" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#named-parameters-self-prefix-str-recurse-bool-true-remove-duplicate-bool-true-collections-abc-iterator-tuple-str-tensorplay-nn-parameter-parameter-source-2" aria-label="Permalink to &quot;`named_parameters(self, prefix: str = &#39;&#39;, recurse: bool = True, remove_duplicate: bool = True) -&gt; collections.abc.Iterator[tuple[str, tensorplay.nn.parameter.Parameter]]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2595)&quot;">​</a></h4><p>Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p><h4 id="args-67" tabindex="-1">Args <a class="header-anchor" href="#args-67" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>prefix</strong> (<code>str</code>): prefix to prepend to all parameter names.</li><li><strong>recurse</strong> (<code>bool</code>): if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that 此模块的直接成员缓冲区。</li><li><strong>remove_duplicate</strong> (<code>bool, optional</code>): whether to remove the duplicated parameters in the result. Defaults to True.</li></ul><h4 id="yields-22" tabindex="-1">Yields <a class="header-anchor" href="#yields-22" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><pre><code>(str, Parameter): Tuple containing the name and parameter\n</code></pre><h4 id="example-26" tabindex="-1">Example <a class="header-anchor" href="#example-26" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.named_parameters():</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;bias&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(param.size())</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h4 id="parameters-self-recurse-bool-true-collections-abc-iterator-tensorplay-nn-parameter-parameter-source-2" tabindex="-1"><code>parameters(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay.nn.parameter.Parameter]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2570" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#parameters-self-recurse-bool-true-collections-abc-iterator-tensorplay-nn-parameter-parameter-source-2" aria-label="Permalink to &quot;`parameters(self, recurse: bool = True) -&gt; collections.abc.Iterator[tensorplay.nn.parameter.Parameter]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2570)&quot;">​</a></h4><p>Return an iterator over module parameters.</p><p>This is typically passed to an optimizer.</p><h4 id="args-68" tabindex="-1">Args <a class="header-anchor" href="#args-68" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>recurse</strong> (<code>bool</code>): if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that 此模块的直接成员缓冲区。</li></ul><h4 id="yields-23" tabindex="-1">Yields <a class="header-anchor" href="#yields-23" aria-label="Permalink to &quot;Yields&quot;">​</a></h4><ul><li><strong>Parameter</strong>: module parameter</li></ul><h4 id="example-27" tabindex="-1">Example <a class="header-anchor" href="#example-27" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.parameters():</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(param), param.size())</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;class</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;tensorplay.Tensor&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">L</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><hr><h4 id="register-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-tensorplay-utils-hooks-removablehandle-source-2" tabindex="-1"><code>register_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]]) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1336" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-tensorplay-utils-hooks-removablehandle-source-2" aria-label="Permalink to &quot;`register_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]]) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1336)&quot;">​</a></h4><p>Register a backward hook on the module.</p><p>This function is deprecated in favor of <code>~tensorplay.nn.Module.register_full_backward_hook</code> and the behavior of this function will change in future versions.</p><h4 id="returns-63" tabindex="-1">Returns <a class="header-anchor" href="#returns-63" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-buffer-self-name-str-tensor-optional-tensorplay-c-tensorbase-persistent-bool-true-none-source-2" tabindex="-1"><code>register_buffer(self, name: str, tensor: Optional[tensorplay._C.TensorBase], persistent: bool = True) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L553" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-buffer-self-name-str-tensor-optional-tensorplay-c-tensorbase-persistent-bool-true-none-source-2" aria-label="Permalink to &quot;`register_buffer(self, name: str, tensor: Optional[tensorplay._C.TensorBase], persistent: bool = True) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L553)&quot;">​</a></h4><p>Add a buffer to the module.</p><p>This is typically used to register a buffer that should not be considered a model parameter. For example, BatchNorm&#39;s <code>running_mean</code> is not a parameter, but is part of the module&#39;s state. Buffers, by default, are persistent and will be saved alongside parameters. This behavior can be changed by setting <code>persistent</code> to <code>False</code>. The only difference between a persistent buffer and a non-persistent buffer is that the latter will not be a part of this module&#39;s <code>state_dict</code>.</p><p>Buffers can be accessed as attributes using given names.</p><h4 id="args-69" tabindex="-1">Args <a class="header-anchor" href="#args-69" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>name</strong> (<code>str</code>): name of the buffer. The buffer can be accessed from this module using the given name</li><li><strong>tensor</strong> (<code>Tensor or None</code>): buffer to be registered. If <code>None</code>, then operations that run on buffers, such as <code>cuda</code>, are ignored. If <code>None</code>, the buffer is <strong>not</strong> included in the module&#39;s <code>state_dict</code>.</li><li><strong>persistent</strong> (<code>bool</code>): whether the buffer is part of this module&#39;s <code>state_dict</code>.</li></ul><h4 id="example-28" tabindex="-1">Example <a class="header-anchor" href="#example-28" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.register_buffer(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;running_mean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, tensorplay.zeros(num_features))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><hr><h4 id="register-forward-hook-self-hook-union-callable-t-tuple-any-any-optional-any-callable-t-tuple-any-dict-str-any-any-optional-any-prepend-bool-false-with-kwargs-bool-false-always-call-bool-false-tensorplay-utils-hooks-removablehandle-source-2" tabindex="-1"><code>register_forward_hook(self, hook: Union[Callable[[~T, tuple[Any, ...], Any], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1592" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-forward-hook-self-hook-union-callable-t-tuple-any-any-optional-any-callable-t-tuple-any-dict-str-any-any-optional-any-prepend-bool-false-with-kwargs-bool-false-always-call-bool-false-tensorplay-utils-hooks-removablehandle-source-2" aria-label="Permalink to &quot;`register_forward_hook(self, hook: Union[Callable[[~T, tuple[Any, ...], Any], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1592)&quot;">​</a></h4><p>Register a forward hook on the module.</p><p>The hook will be called every time after <code>forward</code> has computed an output.</p><p>If <code>with_kwargs</code> is <code>False</code> or not specified, the input contains only the positional arguments given to the module. Keyword arguments won&#39;t be passed to the hooks and only to the <code>forward</code>. The hook can modify the output. It can modify the input inplace but it will not have effect on forward since this is called after <code>forward</code> is called. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args, output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> modified output</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>If <code>with_kwargs</code> is <code>True</code>, the forward hook will be passed the <code>kwargs</code> given to the forward function and be expected to return the output possibly modified. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args, kwargs, output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> modified output</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="args-70" tabindex="-1">Args <a class="header-anchor" href="#args-70" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If <code>True</code>, the provided <code>hook</code> will be fired before all existing <code>forward</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>forward</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>forward</code> hooks registered with <code>register_module_forward_hook</code> will fire before all hooks registered by this method.</li><li><strong>Default</strong>: <code>False</code></li><li><strong>with_kwargs</strong> (<code>bool</code>): If <code>True</code>, the <code>hook</code> will be passed the kwargs given to the forward function.</li><li><strong>Default</strong>: <code>False</code></li><li><strong>always_call</strong> (<code>bool</code>): If <code>True</code> the <code>hook</code> will be run regardless of whether an exception is raised while calling the Module.</li><li><strong>Default</strong>: <code>False</code></li></ul><h4 id="returns-64" tabindex="-1">Returns <a class="header-anchor" href="#returns-64" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-forward-pre-hook-self-hook-union-callable-t-tuple-any-optional-any-callable-t-tuple-any-dict-str-any-optional-tuple-any-dict-str-any-prepend-bool-false-with-kwargs-bool-false-tensorplay-utils-hooks-removablehandle-source-2" tabindex="-1"><code>register_forward_pre_hook(self, hook: Union[Callable[[~T, tuple[Any, ...]], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any]], Optional[tuple[Any, dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1526" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-forward-pre-hook-self-hook-union-callable-t-tuple-any-optional-any-callable-t-tuple-any-dict-str-any-optional-tuple-any-dict-str-any-prepend-bool-false-with-kwargs-bool-false-tensorplay-utils-hooks-removablehandle-source-2" aria-label="Permalink to &quot;`register_forward_pre_hook(self, hook: Union[Callable[[~T, tuple[Any, ...]], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any]], Optional[tuple[Any, dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1526)&quot;">​</a></h4><p>Register a forward pre-hook on the module.</p><p>The hook will be called every time before <code>forward</code> is invoked.</p><p>If <code>with_kwargs</code> is false or not specified, the input contains only the positional arguments given to the module. Keyword arguments won&#39;t be passed to the hooks and only to the <code>forward</code>. The hook can modify the input. User can either return a tuple or a single modified value in the hook. We will wrap the value into a tuple if a single value is returned (unless that value is already a tuple). The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> modified </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>If <code>with_kwargs</code> is true, the forward pre-hook will be passed the kwargs given to the forward function. And if the hook modifies the input, both the args and kwargs should be returned. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, args, kwargs) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> of modified </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> kwargs</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="args-71" tabindex="-1">Args <a class="header-anchor" href="#args-71" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If true, the provided <code>hook</code> will be fired before all existing <code>forward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>forward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>forward_pre</code> hooks registered with <code>register_module_forward_pre_hook</code> will fire before all hooks registered by this method.</li><li><strong>Default</strong>: <code>False</code></li><li><strong>with_kwargs</strong> (<code>bool</code>): If true, the <code>hook</code> will be passed the kwargs given to the forward function.</li><li><strong>Default</strong>: <code>False</code></li></ul><h4 id="returns-65" tabindex="-1">Returns <a class="header-anchor" href="#returns-65" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-full-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source-2" tabindex="-1"><code>register_full_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1362" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-full-backward-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source-2" aria-label="Permalink to &quot;`register_full_backward_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase], Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1362)&quot;">​</a></h4><p>Register a backward hook on the module.</p><p>The hook will be called every time the gradients with respect to a module are computed, and its firing rules are as follows:</p><pre><code>1. Ordinarily, the hook fires when the gradients are computed with respect to the module inputs.\n2. If none of the module inputs require gradients, the hook will fire when the gradients are computed\n   with respect to module outputs.\n3. If none of the module outputs require gradients, then the hooks will not fire.\n</code></pre><p>The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, grad_input, grad_output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Tensor) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">or</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The <code>grad_input</code> and <code>grad_output</code> are tuples that contain the gradients with respect to the inputs and outputs respectively. The hook should not modify its arguments, but it can optionally return a new gradient with respect to the input that will be used in place of <code>grad_input</code> in subsequent computations. <code>grad_input</code> will only correspond to the inputs given as positional arguments and all kwarg arguments are ignored. Entries in <code>grad_input</code> and <code>grad_output</code> will be <code>None</code> for all non-Tensor arguments.</p><p>For technical reasons, when this hook is applied to a Module, its forward function will receive a view of each Tensor passed to the Module. Similarly the caller will receive a view of each Tensor returned by the Module&#39;s forward function.</p><p>.. warning</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Modifying inputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> outputs inplace </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> allowed when using backward hooks </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">will </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">raise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> an error.</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="args-72" tabindex="-1">Args <a class="header-anchor" href="#args-72" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user-defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If true, the provided <code>hook</code> will be fired before all existing <code>backward</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>backward</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>backward</code> hooks registered with <code>register_module_full_backward_hook</code> will fire before all hooks registered by this method.</li></ul><h4 id="returns-66" tabindex="-1">Returns <a class="header-anchor" href="#returns-66" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-full-backward-pre-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source-2" tabindex="-1"><code>register_full_backward_pre_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1287" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-full-backward-pre-hook-self-hook-callable-forwardref-module-union-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-union-nonetype-tuple-tensorplay-c-tensorbase-tensorplay-c-tensorbase-prepend-bool-false-tensorplay-utils-hooks-removablehandle-source-2" aria-label="Permalink to &quot;`register_full_backward_pre_hook(self, hook: Callable[[ForwardRef(&#39;Module&#39;), Union[tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], Union[NoneType, tuple[tensorplay._C.TensorBase, ...], tensorplay._C.TensorBase]], prepend: bool = False) -&gt; tensorplay.utils.hooks.RemovableHandle` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1287)&quot;">​</a></h4><p>Register a backward pre-hook on the module.</p><p>The hook will be called every time the gradients for the module are computed. The hook should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, grad_output) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tuple[Tensor] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">or</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The <code>grad_output</code> is a tuple. The hook should not modify its arguments, but it can optionally return a new gradient with respect to the output that will be used in place of <code>grad_output</code> in subsequent computations. Entries in <code>grad_output</code> will be <code>None</code> for all non-Tensor arguments.</p><p>For technical reasons, when this hook is applied to a Module, its forward function will receive a view of each Tensor passed to the Module. Similarly the caller will receive a view of each Tensor returned by the Module&#39;s forward function.</p><p>.. warning</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Modifying inputs inplace </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> allowed when using backward hooks </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">will </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">raise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> an error.</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="args-73" tabindex="-1">Args <a class="header-anchor" href="#args-73" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): The user-defined hook to be registered.</li><li><strong>prepend</strong> (<code>bool</code>): If true, the provided <code>hook</code> will be fired before all existing <code>backward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Otherwise, the provided <code>hook</code> will be fired after all existing <code>backward_pre</code> hooks on this <code>tensorplay.nn.Module</code>. Note that global <code>backward_pre</code> hooks registered with <code>register_module_full_backward_pre_hook</code> will fire before all hooks registered by this method.</li></ul><h4 id="returns-67" tabindex="-1">Returns <a class="header-anchor" href="#returns-67" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-load-state-dict-post-hook-self-hook-source-2" tabindex="-1"><code>register_load_state_dict_post_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2226" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-load-state-dict-post-hook-self-hook-source-2" aria-label="Permalink to &quot;`register_load_state_dict_post_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2226)&quot;">​</a></h4><p>Register a post-hook to be run after module&#39;s <code>~nn.Module.load_state_dict</code> is called.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, incompatible_keys) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The <code>module</code> argument is the current module that this hook is registered on, and the <code>incompatible_keys</code> argument is a <code>NamedTuple</code> consisting of attributes <code>missing_keys</code> and <code>unexpected_keys</code>. <code>missing_keys</code> is a <code>list</code> of <code>str</code> containing the missing keys and <code>unexpected_keys</code> is a <code>list</code> of <code>str</code> containing the unexpected keys.</p><p>The given incompatible_keys can be modified inplace if needed.</p><p>Note that the checks performed when calling <code>load_state_dict</code> with <code>strict=True</code> are affected by modifications the hook makes to <code>missing_keys</code> or <code>unexpected_keys</code>, as expected. Additions to either set of keys will result in an error being thrown when <code>strict=True</code>, and clearing out both missing and unexpected keys will avoid an error.</p><h4 id="returns-68" tabindex="-1">Returns <a class="header-anchor" href="#returns-68" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>`tensorplay.utils.hooks.RemovableHandle`:\n    a handle that can be used to remove the added hook by calling\n    ``handle.remove()``\n</code></pre><hr><h4 id="register-load-state-dict-pre-hook-self-hook-source-2" tabindex="-1"><code>register_load_state_dict_pre_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2214" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-load-state-dict-pre-hook-self-hook-source-2" aria-label="Permalink to &quot;`register_load_state_dict_pre_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2214)&quot;">​</a></h4><p>Register a pre-hook to be run before module&#39;s <code>~nn.Module.load_state_dict</code> is called.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # noqa: B950</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="arguments-2" tabindex="-1">Arguments <a class="header-anchor" href="#arguments-2" aria-label="Permalink to &quot;Arguments&quot;">​</a></h4><ul><li><strong>hook</strong> (<code>Callable</code>): Callable hook that will be invoked before loading the state dict.</li></ul><hr><h4 id="register-module-self-name-str-module-optional-forwardref-module-none-source-2" tabindex="-1"><code>register_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L695" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-module-self-name-str-module-optional-forwardref-module-none-source-2" aria-label="Permalink to &quot;`register_module(self, name: str, module: Optional[ForwardRef(&#39;Module&#39;)]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L695)&quot;">​</a></h4><p>Alias for <code>add_module</code>.</p><hr><h4 id="register-parameter-self-name-str-param-optional-tensorplay-nn-parameter-parameter-none-source-2" tabindex="-1"><code>register_parameter(self, name: str, param: Optional[tensorplay.nn.parameter.Parameter]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L617" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-parameter-self-name-str-param-optional-tensorplay-nn-parameter-parameter-none-source-2" aria-label="Permalink to &quot;`register_parameter(self, name: str, param: Optional[tensorplay.nn.parameter.Parameter]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L617)&quot;">​</a></h4><p>Add a parameter to the module.</p><p>The parameter can be accessed as an attribute using given name.</p><h4 id="args-74" tabindex="-1">Args <a class="header-anchor" href="#args-74" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>name</strong> (<code>str</code>): name of the parameter. The parameter can be accessed from this module using the given name</li><li><strong>param</strong> (<code>Parameter or None</code>): parameter to be added to the module. If <code>None</code>, then operations that run on parameters, such as <code>cuda</code>, are ignored. If <code>None</code>, the parameter is <strong>not</strong> included in the module&#39;s <code>state_dict</code>.</li></ul><hr><h4 id="register-state-dict-post-hook-self-hook-source-2" tabindex="-1"><code>register_state_dict_post_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2017" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-state-dict-post-hook-self-hook-source-2" aria-label="Permalink to &quot;`register_state_dict_post_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2017)&quot;">​</a></h4><p>Register a post-hook for the <code>~tensorplay.nn.Module.state_dict</code> method.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, state_dict, prefix, local_metadata) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The registered hooks can modify the <code>state_dict</code> inplace.</p><hr><h4 id="register-state-dict-pre-hook-self-hook-source-2" tabindex="-1"><code>register_state_dict_pre_hook(self, hook)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2041" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#register-state-dict-pre-hook-self-hook-source-2" aria-label="Permalink to &quot;`register_state_dict_pre_hook(self, hook)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2041)&quot;">​</a></h4><p>Register a pre-hook for the <code>~tensorplay.nn.Module.state_dict</code> method.</p><p>It should have the following signature</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook(module, prefix, keep_vars) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>The registered hooks can be used to perform pre-processing before the <code>state_dict</code> call is made.</p><hr><h4 id="requires-grad-self-requires-grad-bool-true-self-source-2" tabindex="-1"><code>requires_grad_(self, requires_grad: bool = True) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2826" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#requires-grad-self-requires-grad-bool-true-self-source-2" aria-label="Permalink to &quot;`requires_grad_(self, requires_grad: bool = True) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2826)&quot;">​</a></h4><p>Change if autograd should record operations on parameters in this module.</p><p>This method sets the parameters&#39; <code>requires_grad</code> attributes in-place.</p><p>This method is helpful for freezing part of the module for finetuning or training parts of a model individually (e.g., GAN training).</p><p>有关 <code>.eval()</code> 和其他类似机制的比较， <code>.requires_grad_()</code> and several similar mechanisms that may be confused with it.</p><h4 id="args-75" tabindex="-1">Args <a class="header-anchor" href="#args-75" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>requires_grad</strong> (<code>bool</code>): whether autograd should record operations on parameters in this module. 默认值： <code>True</code>.</li></ul><h4 id="returns-69" tabindex="-1">Returns <a class="header-anchor" href="#returns-69" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="reset-parameters-self-none-source-1" tabindex="-1"><code>reset_parameters(self) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L110" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#reset-parameters-self-none-source-1" aria-label="Permalink to &quot;`reset_parameters(self) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/linear.py#L110)&quot;">​</a></h4><p>Resets parameters based on their initialization used in <code>__init__</code>.</p><hr><h4 id="set-extra-state-self-state-any-none-source-2" tabindex="-1"><code>set_extra_state(self, state: Any) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L938" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#set-extra-state-self-state-any-none-source-2" aria-label="Permalink to &quot;`set_extra_state(self, state: Any) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L938)&quot;">​</a></h4><p>Set extra state contained in the loaded <code>state_dict</code>.</p><p>This function is called from <code>load_state_dict</code> to handle any extra state found within the <code>state_dict</code>. Implement this function and a corresponding <code>get_extra_state</code> for your module if you need to store extra state within its <code>state_dict</code>.</p><h4 id="args-76" tabindex="-1">Args <a class="header-anchor" href="#args-76" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state</strong> (<code>dict</code>): Extra state from the <code>state_dict</code></li></ul><hr><h4 id="set-submodule-self-target-str-module-module-strict-bool-false-none-source-2" tabindex="-1"><code>set_submodule(self, target: str, module: &#39;Module&#39;, strict: bool = False) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L764" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#set-submodule-self-target-str-module-module-strict-bool-false-none-source-2" aria-label="Permalink to &quot;`set_submodule(self, target: str, module: &#39;Module&#39;, strict: bool = False) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L764)&quot;">​</a></h4><p>Set the submodule given by <code>target</code> if it exists, otherwise throw an error.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>If <code>strict</code> is set to <code>False</code> (default), the method will replace an existing submodule or create a new submodule if the parent module exists. If <code>strict</code> is set to <code>True</code>, the method will only attempt to replace an existing submodule and throw an error if the submodule does not exist.</p></div><p>For example, let&#39;s say you have an <code>nn.Module</code> <code>A</code> that looks like this:</p><p>.. code-block:: text</p><ul><li><strong>A</strong> (<code> (net_b</code>): Module( (net_c): Module( (conv): Conv2d(3, 3, 3) ) (linear): Linear(3, 3) ) )</li></ul><p>(The diagram shows an <code>nn.Module</code> <code>A</code>. <code>A</code> has a nested submodule <code>net_b</code>, which itself has two submodules <code>net_c</code> and <code>linear</code>. <code>net_c</code> then has a submodule <code>conv</code>.)</p><p>To override the <code>Conv2d</code> with a new submodule <code>Linear</code>, you could call <code>set_submodule(&quot;net_b.net_c.conv&quot;, nn.Linear(1, 1))</code> where <code>strict</code> could be <code>True</code> or <code>False</code></p><p>To add a new submodule <code>Conv2d</code> to the existing <code>net_b</code> module, you would call <code>set_submodule(&quot;net_b.conv&quot;, nn.Conv2d(1, 1, 1))</code>.</p><p>In the above if you set <code>strict=True</code> and call <code>set_submodule(&quot;net_b.conv&quot;, nn.Conv2d(1, 1, 1), strict=True)</code>, an AttributeError will be raised because <code>net_b</code> does not have a submodule named <code>conv</code>.</p><h4 id="args-77" tabindex="-1">Args <a class="header-anchor" href="#args-77" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>target</strong>: The fully-qualified string name of the submodule to look for. (See above example for how to specify a fully-qualified string.)</li><li><strong>module</strong>: The module to set the submodule to.</li><li><strong>strict</strong>: If <code>False</code>, the method will replace an existing submodule or create a new submodule if the parent module exists. If <code>True</code>, the method will only attempt to replace an existing submodule and throw an error if the submodule doesn&#39;t already exist.</li></ul><h4 id="raises-11" tabindex="-1">Raises <a class="header-anchor" href="#raises-11" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the <code>target</code> string is empty or if <code>module</code> is not an instance of <code>nn.Module</code>.</li><li><strong>AttributeError</strong>: If at any point along the path resulting from the <code>target</code> string the (sub)path resolves to a non-existent attribute name or an object that is not an instance of <code>nn.Module</code>.</li></ul><hr><h4 id="share-memory-self-self-source-2" tabindex="-1"><code>share_memory(self) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2877" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#share-memory-self-self-source-2" aria-label="Permalink to &quot;`share_memory(self) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2877)&quot;">​</a></h4><p>See <code>tensorplay.Tensor.share_memory_</code>.</p><hr><h4 id="state-dict-self-args-destination-none-prefix-keep-vars-false-source-2" tabindex="-1"><code>state_dict(self, *args, destination=None, prefix=&#39;&#39;, keep_vars=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2105" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-args-destination-none-prefix-keep-vars-false-source-2" aria-label="Permalink to &quot;`state_dict(self, *args, destination=None, prefix=&#39;&#39;, keep_vars=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2105)&quot;">​</a></h4><p>Return a dictionary containing references to the whole state of the module.</p><p>Both parameters and persistent buffers (e.g. running averages) are included. Keys are corresponding parameter and buffer names. Parameters and buffers set to <code>None</code> are not included.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>The returned object is a shallow copy. It contains references to the module&#39;s parameters and buffers.</p></div><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>Currently <code>state_dict()</code> also accepts positional arguments for <code>destination</code>, <code>prefix</code> and <code>keep_vars</code> in order. However, this is being deprecated and keyword arguments will be enforced in future releases.</p></div><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>Please avoid the use of argument <code>destination</code> as it is not designed for end-users.</p></div><h4 id="args-78" tabindex="-1">Args <a class="header-anchor" href="#args-78" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>destination</strong> (<code>dict, optional</code>): If provided, the state of module will be updated into the dict and the same object is returned. Otherwise, an <code>OrderedDict</code> will be created and returned.</li><li><strong>Default</strong>: <code>None</code>.</li><li><strong>prefix</strong> (<code>str, optional</code>): a prefix added to parameter and buffer names to compose the keys in state_dict. 默认值： <code>&#39;&#39;</code>.</li><li><strong>keep_vars</strong> (<code>bool, optional</code>): by default the <code>~tensorplay.Tensor</code> s returned in the state dict are detached from autograd. If it&#39;s set to <code>True</code>, detaching will not be performed.</li><li><strong>Default</strong>: <code>False</code>.</li></ul><h4 id="returns-70" tabindex="-1">Returns <a class="header-anchor" href="#returns-70" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>dict</strong>: a dictionary containing a whole state of the module</li></ul><h4 id="example-29" tabindex="-1">Example <a class="header-anchor" href="#example-29" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">module.state_dict().keys()</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;bias&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;weight&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><hr><h4 id="to-self-args-kwargs-source-2" tabindex="-1"><code>to(self, *args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1151" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#to-self-args-kwargs-source-2" aria-label="Permalink to &quot;`to(self, *args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1151)&quot;">​</a></h4><p>Move and/or cast the parameters and buffers.</p><p>This can be called as</p><p>.. function:: to(device=None, dtype=None, non_blocking=False) :noindex:</p><p>.. function:: to(dtype, non_blocking=False) :noindex:</p><p>.. function:: to(tensor, non_blocking=False) :noindex:</p><p>.. function:: to(memory_format=tensorplay.channels_last) :noindex:</p><p>Its signature is similar to <code>tensorplay.Tensor.to</code>, but only accepts floating point or complex <code>dtype</code>\\ s. In addition, this method will only cast the floating point or complex parameters and buffers to <code>dtype</code> (if given). The integral parameters and buffers will be moved <code>device</code>, if that is given, but with dtypes unchanged. When <code>non_blocking</code> is set, it tries to convert/move asynchronously with respect to the host if possible, e.g., moving CPU Tensors with pinned memory to CUDA devices.</p><p>See below for examples.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="args-79" tabindex="-1">Args <a class="header-anchor" href="#args-79" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>device</strong> (<code>tensorplay.device</code>): the desired device of the parameters and buffers in this module</li><li><strong>dtype</strong> (<code>tensorplay.dtype</code>): the desired floating point or complex dtype of the parameters and buffers in this module</li><li><strong>tensor</strong> (<code>tensorplay.Tensor</code>): Tensor whose dtype and device are the desired dtype and device for all parameters and buffers in this module</li><li><strong>memory_format</strong> (<code>tensorplay.memory_format</code>): the desired memory format for 4D parameters and buffers in this module (keyword only argument)</li></ul><h4 id="returns-71" tabindex="-1">Returns <a class="header-anchor" href="#returns-71" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><h4 id="examples-5" tabindex="-1">Examples <a class="header-anchor" href="#examples-5" aria-label="Permalink to &quot;Examples&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +IGNORE_WANT(&quot;non-deterministic&quot;)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1913</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5113</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2325</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.to(tensorplay.double)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1913</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5113</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2325</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.float64)</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +REQUIRES(env:TENSORPLAY_DOCTEST_CUDA1)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpu1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.device(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cuda:1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.to(gpu1, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.half, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">non_blocking</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1914</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5112</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2324</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.float16, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">device</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;cuda:1&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.device(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cpu&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.to(cpu)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Linear(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1914</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3420</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5112</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2324</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.float16)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).to(tensorplay.cdouble)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear.weight</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter containing:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3741</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2382</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [ </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5593</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4443</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.complex128)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">linear(tensorplay.ones(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.cdouble))</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6122</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1150</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6122</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1150</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6122</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1150</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensorplay.complex128)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br></div></div><hr><h4 id="to-empty-self-device-union-str-tensorplay-device-int-nonetype-recurse-bool-true-self-source-2" tabindex="-1"><code>to_empty(self, *, device: Union[str, tensorplay.Device, int, NoneType], recurse: bool = True) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1119" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#to-empty-self-device-union-str-tensorplay-device-int-nonetype-recurse-bool-true-self-source-2" aria-label="Permalink to &quot;`to_empty(self, *, device: Union[str, tensorplay.Device, int, NoneType], recurse: bool = True) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1119)&quot;">​</a></h4><p>Move the parameters and buffers to the specified device without copying storage.</p><h4 id="args-80" tabindex="-1">Args <a class="header-anchor" href="#args-80" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>device</strong> (<code>tensorplay.device</code>): The desired device of the parameters and buffers in this module.</li><li><strong>recurse</strong> (<code>bool</code>): Whether parameters and buffers of submodules should be recursively moved to the specified device.</li></ul><h4 id="returns-72" tabindex="-1">Returns <a class="header-anchor" href="#returns-72" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="train-self-mode-bool-true-self-source-2" tabindex="-1"><code>train(self, mode: bool = True) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2786" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#train-self-mode-bool-true-self-source-2" aria-label="Permalink to &quot;`train(self, mode: bool = True) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2786)&quot;">​</a></h4><p>Set the module in training mode.</p><p>这仅对某些模块有影响。请参阅特定模块的文档 了解它们在训练/评估模式下的行为细节， mode, i.e., whether they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>, 等。</p><h4 id="args-81" tabindex="-1">Args <a class="header-anchor" href="#args-81" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>mode</strong> (<code>bool</code>): whether to set training mode (<code>True</code>) or evaluation mode (<code>False</code>). 默认值： <code>True</code>.</li></ul><h4 id="returns-73" tabindex="-1">Returns <a class="header-anchor" href="#returns-73" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="type-self-dst-type-union-tensorplay-dtype-str-self-source-2" tabindex="-1"><code>type(self, dst_type: Union[tensorplay.DType, str]) -&gt; Self</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1061" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#type-self-dst-type-union-tensorplay-dtype-str-self-source-2" aria-label="Permalink to &quot;`type(self, dst_type: Union[tensorplay.DType, str]) -&gt; Self` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L1061)&quot;">​</a></h4><p>Casts all parameters and buffers to <code>dst_type</code>.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此方法会就地修改模块。</p></div><h4 id="args-82" tabindex="-1">Args <a class="header-anchor" href="#args-82" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>dst_type</strong> (<code>type or string</code>): the desired type</li></ul><h4 id="returns-74" tabindex="-1">Returns <a class="header-anchor" href="#returns-74" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><ul><li><strong>Module</strong>: self</li></ul><hr><h4 id="zero-grad-self-set-to-none-bool-true-none-source-2" tabindex="-1"><code>zero_grad(self, set_to_none: bool = True) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2849" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#zero-grad-self-set-to-none-bool-true-none-source-2" aria-label="Permalink to &quot;`zero_grad(self, set_to_none: bool = True) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/nn/modules/module.py#L2849)&quot;">​</a></h4><p>Reset gradients of all model parameters.</p><p>See similar function under <code>tensorplay.optim.Optimizer</code> for more context.</p><h4 id="args-83" tabindex="-1">Args <a class="header-anchor" href="#args-83" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>set_to_none</strong> (<code>bool</code>): instead of setting to zero, set the grads to None. See <code>tensorplay.optim.Optimizer.zero_grad</code> for details.</li></ul><hr></details>',3))])}]]);export{l as __pageData,de as default};

import{_ as a,c as i,o as n,a4 as t}from"./chunks/framework.t-GQSDtj.js";const c=JSON.parse('{"title":"Custom Autograd Functions","description":"","frontmatter":{},"headers":[],"relativePath":"guide/tutorials/custom-autograd.md","filePath":"guide/tutorials/custom-autograd.md"}'),e={name:"guide/tutorials/custom-autograd.md"};function l(p,s,r,h,o,k){return n(),i("div",null,[...s[0]||(s[0]=[t(`<h1 id="custom-autograd-functions" tabindex="-1">Custom Autograd Functions <a class="header-anchor" href="#custom-autograd-functions" aria-label="Permalink to &quot;Custom Autograd Functions&quot;">​</a></h1><p>TensorPlay allows you to extend its automatic differentiation engine by defining your own forward and backward logic. This is useful for implementing non-differentiable operations with custom gradients or optimizing specific kernels.</p><h2 id="defining-a-custom-function" tabindex="-1">Defining a Custom Function <a class="header-anchor" href="#defining-a-custom-function" aria-label="Permalink to &quot;Defining a Custom Function&quot;">​</a></h2><p>To create a custom autograd function, inherit from <code>tpx.autograd.Function</code> and implement the static methods <code>forward</code> and <code>backward</code>.</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tp</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.autograd </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Function</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MyExp</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Function</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    @</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">staticmethod</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(ctx, i):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i.exp()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        ctx.save_for_backward(result)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> result</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    @</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">staticmethod</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> backward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(ctx, grad_output):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        result, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ctx.saved_tensors</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> grad_output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> result</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Usage</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> my_exp</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyExp.apply(x)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tp.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> my_exp(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.sum().backward()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x.grad)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div><h2 id="when-to-use-custom-functions" tabindex="-1">When to Use Custom Functions? <a class="header-anchor" href="#when-to-use-custom-functions" aria-label="Permalink to &quot;When to Use Custom Functions?&quot;">​</a></h2><ol><li><strong>Efficiency</strong>: If you can compute a combined gradient more efficiently than the composition of standard operations.</li><li><strong>Stability</strong>: Implementing numerically stable versions of functions (e.g., LogSumExp).</li><li><strong>Custom Hardware</strong>: Interfacing with hardware that has its own differentiation logic.</li><li><strong>Non-differentiable Ops</strong>: Providing a &quot;surrogate gradient&quot; for operations like Step functions or Quantization.</li></ol><h2 id="context-object-ctx" tabindex="-1">Context Object (<code>ctx</code>) <a class="header-anchor" href="#context-object-ctx" aria-label="Permalink to &quot;Context Object (\`ctx\`)&quot;">​</a></h2><p>The <code>ctx</code> object is used to communicate information from the forward pass to the backward pass:</p><ul><li><code>ctx.save_for_backward(*tensors)</code>: Use this to save tensors needed for the backward pass.</li><li><code>ctx.saved_tensors</code>: Access the saved tensors in <code>backward</code>.</li><li><code>ctx.mark_dirty(*tensors)</code>: Mark tensors that are modified in-place.</li><li><code>ctx.mark_non_differentiable(*tensors)</code>: Mark outputs that don&#39;t require gradients.</li></ul>`,10)])])}const u=a(e,[["render",l]]);export{c as __pageData,u as default};

import{_ as n,C as t,c as r,o as s,j as l,a4 as c,G as a}from"./chunks/framework.DWXU4yX9.js";const v=JSON.parse(`{"title":"","description":"","frontmatter":{"layout":"home","hero":{"name":"TensorPlay","text":"Transparent AI Architecture","tagline":"A learner-friendly, PyTorch-compatible deep learning framework designed to demystify neural network internals and facilitate custom hardware experimentation.","image":{"light":"/images/logo-1.png","dark":"/images/logo-4.png","alt":"TensorPlay"},"actions":[{"theme":"brand","text":"Get Started","link":"#install"},{"theme":"alt","text":"View on GitHub","link":"https://github.com/bluemoon-o2/tensorplay"}]},"features":[{"title":"Pure & Transparent","details":"Built with clarity in mind, TensorPlay allows you to trace every operation from Python down to the C++ core without getting lost in abstraction.","icon":"üîç"},{"title":"DIY Acceleration","details":"A simplified implementation of CPU and CUDA backends, making it the perfect playground for implementing your own hardware kernels.","icon":"üõ†Ô∏è"},{"title":"Modular Autograd","details":"Understand the magic of backpropagation with a decoupled autograd engine (TPX) that's easy to read, extend, and modify.","icon":"üß¨"},{"title":"Research Ready","details":"Highly extensible design that lets you prototype new layer types, optimizers, and storage formats with minimal boilerplate.","icon":"üß™"}]},"headers":[],"relativePath":"index.md","filePath":"index.md"}`),d={name:"index.md"},h={id:"install"};function p(m,e,u,g,y,f){const i=t("InstallSelector"),o=t("StayInTouch");return s(),r("div",null,[l("div",h,[a(i)]),e[0]||(e[0]=c('<div class="ecosystem-section"><h2 class="section-title">The TensorPlay Ecosystem</h2><p class="section-subtitle">A collection of libraries designed to be used together or independently.</p><div class="ecosystem-grid"><div class="ecosystem-card"><h3>P10</h3><p>The core calculation engine. Provides a clean, readable implementation of memory management and basic tensor kernels.</p><a href="/guide/architecture#1-p10-tensor-computation-engine" class="card-link">Design Philosophy ‚Üí</a></div><div class="ecosystem-card"><h3>TPX</h3><p>The explicit autograd layer. Designed for those who want to understand or modify how computational graphs are built.</p><a href="/guide/architecture#2-tpx-autograd-engine" class="card-link">Design Philosophy ‚Üí</a></div><div class="ecosystem-card"><h3>Stax</h3><p>The optimization playground. Experiment with operator fusion and static graph capture in a simplified environment.</p><a href="/guide/architecture#3-stax-static-graph-accelerator" class="card-link">Design Philosophy ‚Üí</a></div><div class="ecosystem-card"><h3>NN</h3><p>The modular business layer. High-level components (Linear, Conv2d) that serve as blueprints for your own network layers.</p><a href="/guide/architecture#4-nn-neural-network-library" class="card-link">Design Philosophy ‚Üí</a></div></div></div>',1)),a(o)])}const T=n(d,[["render",p]]);export{v as __pageData,T as default};

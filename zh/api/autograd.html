<!DOCTYPE html>
<html lang="zh" dir="ltr">
  <head>
    <meta charset="utf-8">
    
    <title>tensorplay.autograd | TensorPlay</title>
    <meta name="description" content="一个适合学习者、兼容 PyTorch 的深度学习框架。">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/assets/style.r3WZttRK.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.SzVb3b0O.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.x1apcxUX.js">
    <link rel="modulepreload" href="/assets/chunks/framework.DJtYh1Hc.js">
    <link rel="modulepreload" href="/assets/zh_api_autograd.md.D2gfxv4i.lean.js">
    <link rel="icon" href="/favicon.png">
    <link rel="icon" type="image/png" href="/favicon.png">
    <link rel="shortcut icon" href="/favicon.png">
    <link rel="apple-touch-icon" href="/images/logo-0.png">
    <meta name="baidu-site-verification" content="codeva-AhyreL7IDE">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="keywords" content="deep learning, machine learning, ai framework, pytorch compatible, educational, c++, python, tensorplay, 深度学习, 机器学习, 自动微分">
    <meta name="author" content="TensorPlay Team">
    <meta property="og:type" content="website">
    <meta property="og:title" content="TensorPlay | Transparent &amp; Compatible AI Framework">
    <meta property="og:description" content="A transparent, educational, and PyTorch-compatible deep learning framework for the modern AI era.">
    <meta property="og:site_name" content="TensorPlay">
    <meta property="og:url" content="https://www.tensorplay.cn">
    <meta property="og:image" content="https://www.tensorplay.cn/images/logo-1.png">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="TensorPlay | Transparent &amp; Compatible AI Framework">
    <meta name="twitter:description" content="A transparent, educational, and PyTorch-compatible deep learning framework for the modern AI era.">
    <meta name="twitter:image" content="https://www.tensorplay.cn/images/logo-1.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300;400;500;600;700&amp;display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><canvas id="cyberpunk-particles" data-v-02d3b8a7></canvas><!----><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/zh/" data-v-1168a8e4><!--[--><!--]--><!--[--><img class="VPImage logo" src="/images/logo-0.png" alt data-v-8426fc1a><!--]--><span data-v-1168a8e4>TensorPlay</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><!----><span data-v-cf11d7a2>学习</span><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/zh/guide/getting-started" data-v-35975db6><!--[--><span data-v-35975db6>快速开始</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/zh/guide/tutorials" data-v-35975db6><!--[--><span data-v-35975db6>教程</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/community/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>社区</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/ecosystem/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>项目</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/api/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>文档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/blog/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>博客与新闻</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/about/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>关于</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/join/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>加入我们</span><!--]--></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-6aa21345 data-v-88af2de4 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><span class="vpi-languages option-icon" data-v-cf11d7a2></span><!----><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><div class="items" data-v-88af2de4><p class="title" data-v-88af2de4>简体中文</p><!--[--><div class="VPMenuLink" data-v-88af2de4 data-v-35975db6><a class="VPLink link" href="/api/autograd" data-v-35975db6><!--[--><span data-v-35975db6>English</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/bluemoon-o2/tensorplay" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><div class="group translations" data-v-bb2aa2f0><p class="trans-title" data-v-bb2aa2f0>简体中文</p><!--[--><div class="VPMenuLink" data-v-bb2aa2f0 data-v-35975db6><a class="VPLink link" href="/api/autograd" data-v-35975db6><!--[--><span data-v-35975db6>English</span><!--]--></a></div><!--]--></div><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/bluemoon-o2/tensorplay" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 has-active" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>核心 API</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>概览</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/tensorplay" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>tensorplay</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/autograd" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>autograd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/functional" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>functional</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/optim" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>optim</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/cuda" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>cuda</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>神经网络 (nn)</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/nn" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>nn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/modules" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Modules</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/linear" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Linear Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/conv" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Convolution Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/pooling" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Pooling Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/activation" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Activation Functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/normalization" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Normalization Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/loss" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Loss Functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/dropout" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dropout Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/zh/api/container" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Container</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>On this page</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--[--><!--[--><!----><!--]--><!--]--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _zh_api_autograd" data-v-39a288b8><div><h1 id="tensorplay-autograd" tabindex="-1">tensorplay.autograd <a class="header-anchor" href="#tensorplay-autograd" aria-label="Permalink to &quot;tensorplay.autograd&quot;">​</a></h1><p><code>tensorplay.autograd</code> 提供了实现任意标量值函数自动微分的类和函数。</p><p>它只需要对现有代码进行极少的更改 - 你只需要使用 <code>requires_grad=True</code> 关键字声明应计算梯度的 <code>Tensor</code>。 目前，我们仅支持浮点 <code>Tensor</code> 类型（half, float, double 和 bfloat16）和复数 <code>Tensor</code> 类型（cfloat, cdouble）的自动微分。</p><h2 id="classes" tabindex="-1">Classes <a class="header-anchor" href="#classes" aria-label="Permalink to &quot;Classes&quot;">​</a></h2><h3 id="class-function-source" tabindex="-1"><code>class Function</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L18" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-function-source" aria-label="Permalink to &quot;`class Function` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L18)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Function()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Records operation history and defines formulas for differentiating ops.</p><details><summary>Methods</summary><h4 id="apply-args-kwargs-source" tabindex="-1"><code>apply(*args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L37" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#apply-args-kwargs-source" aria-label="Permalink to &quot;`apply(*args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L37)&quot;">​</a></h4><hr><h4 id="backward-ctx-grad-outputs-source" tabindex="-1"><code>backward(ctx, *grad_outputs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L30" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#backward-ctx-grad-outputs-source" aria-label="Permalink to &quot;`backward(ctx, *grad_outputs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L30)&quot;">​</a></h4><p>定义微分操作的公式。</p><hr><h4 id="forward-ctx-args-kwargs-source" tabindex="-1"><code>forward(ctx, *args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L23" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#forward-ctx-args-kwargs-source" aria-label="Permalink to &quot;`forward(ctx, *args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L23)&quot;">​</a></h4><p>执行操作。</p><hr></details><h3 id="class-enable-grad-source" tabindex="-1"><code>class enable_grad</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L86" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-enable-grad-source" aria-label="Permalink to &quot;`class enable_grad` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L86)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">enable_grad(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">orig_func</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_NoParamDecoratorContextManager</code></p><p>启用梯度计算的上下文管理器。</p><p>如果通过 <code>~no_grad</code> 或 <code>~set_grad_enabled</code> 禁用了梯度计算，则启用它。</p><p>此上下文管理器是线程局部的；它不会影响其他线程中的计算。</p><p>也可以作为装饰器使用。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>enable_grad 是几种可以在局部启用或禁用梯度的机制之一，有关它们的比较，请参阅 <code>locally-disable-grad-doc</code>。</p></div><div class="info custom-block"><p class="custom-block-title">INFO</p><p>此 API 不适用于 <code>forward-mode AD &lt;forward-mode-ad&gt;</code>。</p></div><h4 id="example" tabindex="-1">Example <a class="header-anchor" href="#example" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.enable_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.backward()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x.grad</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.])</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.enable_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> doubler</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doubler(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.enable_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> tripler</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 3</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tripler(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div><details><summary>Methods</summary><h4 id="clone-self-source" tabindex="-1"><code>clone(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/utils/_contextlib.py#L147" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#clone-self-source" aria-label="Permalink to &quot;`clone(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/utils/_contextlib.py#L147)&quot;">​</a></h4><hr></details><h3 id="class-no-grad-source" tabindex="-1"><code>class no_grad</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L21" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-no-grad-source" aria-label="Permalink to &quot;`class no_grad` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L21)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">no_grad() </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_NoParamDecoratorContextManager</code></p><p>Context-manager that disables gradient calculation.</p><p>Disabling gradient calculation is useful for inference, when you are sure that you will not call <code>Tensor.backward()</code>. It will reduce memory consumption for computations that would otherwise have <code>requires_grad=True</code>.</p><p>In this mode, the result of every computation will have <code>requires_grad=False</code>, even when the inputs have <code>requires_grad=True</code>. There is an exception! All factory functions, or functions that create a new Tensor and take a requires_grad kwarg, will NOT be affected by this mode.</p><p>This context manager is thread local; it will not affect computation in other threads.</p><p>Also functions as a decorator.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>No-grad is one of several mechanisms that can enable or disable gradients locally see <code>locally-disable-grad-doc</code> for more information on how they compare.</p></div><div class="info custom-block"><p class="custom-block-title">INFO</p><p>This API does not apply to <code>forward-mode AD &lt;forward-mode-ad&gt;</code>. If you want to disable forward AD for a computation, you can unpack your dual tensors.</p></div><h4 id="example-1" tabindex="-1">Example <a class="header-anchor" href="#example-1" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.no_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> doubler</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doubler(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.no_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> tripler</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 3</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tripler(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># factory function exception</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.nn.Parameter(tensorplay.rand(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">a.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><details><summary>Methods</summary><h4 id="init-self-none-source" tabindex="-1"><code>__init__(self) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L74" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-none-source" aria-label="Permalink to &quot;`__init__(self) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L74)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="clone-self-source-1" tabindex="-1"><code>clone(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/utils/_contextlib.py#L147" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#clone-self-source-1" aria-label="Permalink to &quot;`clone(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/utils/_contextlib.py#L147)&quot;">​</a></h4><hr></details><h3 id="class-set-grad-enabled-source" tabindex="-1"><code>class set_grad_enabled</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L145" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-set-grad-enabled-source" aria-label="Permalink to &quot;`class set_grad_enabled` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L145)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">set_grad_enabled(mode: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_DecoratorContextManager</code></p><p>Context-manager that sets gradient calculation on or off.</p><p><code>set_grad_enabled</code> will enable or disable grads based on its argument <code>mode</code>. It can be used as a context-manager or as a function.</p><p>This context manager is thread local; it will not affect computation in other threads.</p><h4 id="args" tabindex="-1">Args <a class="header-anchor" href="#args" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>mode</strong> (<code>bool</code>): Flag whether to enable grad (<code>True</code>), or disable (<code>False</code>). This can be used to conditionally enable gradients.</li></ul><div class="info custom-block"><p class="custom-block-title">INFO</p><p>set_grad_enabled is one of several mechanisms that can enable or disable gradients locally see <code>locally-disable-grad-doc</code> for more information on how they compare.</p></div><div class="info custom-block"><p class="custom-block-title">INFO</p><p>This API does not apply to <code>forward-mode AD &lt;forward-mode-ad&gt;</code>.</p></div><h4 id="example-2" tabindex="-1">Example <a class="header-anchor" href="#example-2" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">is_train </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.set_grad_enabled(is_train):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.set_grad_enabled(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.set_grad_enabled(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><details><summary>Methods</summary><h4 id="init-self-mode-bool-none-source" tabindex="-1"><code>__init__(self, mode: bool) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L186" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-mode-bool-none-source" aria-label="Permalink to &quot;`__init__(self, mode: bool) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L186)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="clone-self-set-grad-enabled-source" tabindex="-1"><code>clone(self) -&gt; &#39;set_grad_enabled&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L208" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#clone-self-set-grad-enabled-source" aria-label="Permalink to &quot;`clone(self) -&gt; &#39;set_grad_enabled&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L208)&quot;">​</a></h4><p>Create a copy of this class</p><hr></details><h2 id="functions" tabindex="-1">Functions <a class="header-anchor" href="#functions" aria-label="Permalink to &quot;Functions&quot;">​</a></h2><h3 id="grad-source" tabindex="-1"><code>grad()</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/__init__.py#L43" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#grad-source" aria-label="Permalink to &quot;`grad()` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/__init__.py#L43)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">grad(outputs: Union[tensorplay._C.TensorBase, collections.abc.Sequence[tensorplay._C.TensorBase]], inputs: Union[tensorplay._C.TensorBase, collections.abc.Sequence[tensorplay._C.TensorBase]], grad_outputs: Union[tensorplay._C.TensorBase, collections.abc.Sequence[tensorplay._C.TensorBase], NoneType] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, retain_graph: Optional[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, create_graph: </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, allow_unused: Optional[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tuple[tensorplay._C.TensorBase, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>计算并返回输出相对于输入的梯度之和。</p><p><code>grad_outputs</code> 应该是长度与 <code>output</code> 匹配的序列，包含向量-雅可比积中的“向量”，通常是相对于每个输出的预计算梯度。如果输出不需要梯度 (require_grad)，则梯度可以是 <code>None</code>。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>如果你在用户指定的 CUDA 流上下文中运行任何前向操作、创建 <code>grad_outputs</code> 和/或调用 <code>grad</code>，请参阅 <code>Stream semantics of backward passes&lt;bwd-cuda-stream-semantics&gt;</code>。</p></div><h4 id="args-1" tabindex="-1">Args <a class="header-anchor" href="#args-1" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>outputs</strong> (<code>Tensor 或 GradientEdge 的序列</code>): 微分函数的输出。</li><li><strong>inputs</strong> (<code>Tensor 或 GradientEdge 的序列</code>): 将返回其梯度的输入（并且不会累积到 <code>.grad</code> 中）。</li><li><strong>grad_outputs</strong> (<code>Tensor 的序列</code>): 向量-雅可比积中的“向量”。通常是相对于每个输出的梯度。对于标量张量或不需要梯度的张量，可以指定 None 值。如果所有 grad_tensors 都可以接受 None 值，则此参数是可选的。默认值: None。</li><li><strong>retain_graph</strong> (<code>bool, optional</code>): 如果为 <code>False</code>，用于计算梯度的图将被释放。请注意，在几乎所有情况下，都不需要将此选项设置为 <code>True</code>，通常可以以更有效的方式解决。默认为 <code>create_graph</code> 的值。</li><li><strong>create_graph</strong> (<code>bool, optional</code>): 如果为 <code>True</code>，将构建导数图，允许计算高阶导数乘积。</li><li><strong>Default</strong>: <code>False</code>。</li><li><strong>allow_unused</strong> (<code>Optional[bool], optional</code>): 如果为 <code>False</code>，指定在计算输出时未使用的输入（因此它们的梯度始终为零）是一个错误。默认为 <code>materialize_grads</code> 的值。</li></ul><h3 id="is-grad-enabled-source" tabindex="-1"><code>is_grad_enabled()</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L141" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#is-grad-enabled-source" aria-label="Permalink to &quot;`is_grad_enabled()` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L141)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">is_grad_enabled()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/zh/api/tensorplay" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Previous page</span><span class="title" data-v-e257564d>tensorplay</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/zh/api/functional" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>functional</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>基于 Apache 2.0 许可发布。</p><p class="copyright" data-v-e315a0ad>版权所有 © 2025 zlx。保留所有权利。</p></div></footer><!--[--><a href="https://deepwiki.com/bluemoon-o2/TensorPlay" target="_blank" rel="noopener noreferrer" class="deepwiki-floating-badge" title="View on DeepWiki" data-v-5bf2a798><div class="badge-content" data-v-5bf2a798><span class="badge-icon" data-v-5bf2a798>📚</span><span class="badge-text" data-v-5bf2a798>DeepWiki</span></div></a><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_index.md\":\"CIIINTJo\",\"api__c.md\":\"CqosplcF\",\"api__reduction.md\":\"4CT0Th-w\",\"api_activation.md\":\"D6ga1LTB\",\"api_adagrad.md\":\"DLbERoZa\",\"api_adam.md\":\"RHJKi90L\",\"api_adamw.md\":\"CwVxav7q\",\"api_alexnet.md\":\"MpdCIREt\",\"api_amp.md\":\"DwxpVi7g\",\"api_audio.md\":\"Bh-isKk9\",\"api_autocast_mode.md\":\"Upx07om-\",\"api_autograd.md\":\"CT9D3RMp\",\"api_backend.md\":\"B-rtwINW\",\"api_backends.md\":\"CZwYzPim\",\"api_batchnorm.md\":\"DiZgGllz\",\"api_collate.md\":\"D7C1FWND\",\"api_common_types.md\":\"D___UsnV\",\"api_comparison.md\":\"CreVyI7m\",\"api_container.md\":\"DHHM_Bnu\",\"api_conv.md\":\"DVE_N5Pv\",\"api_cpp.md\":\"BzQeMOx5\",\"api_cpu.md\":\"CRrVscpA\",\"api_cuda.md\":\"CfDgBLV4\",\"api_data.md\":\"X1JkS3Ea\",\"api_dataloader.md\":\"C7Xq7oGq\",\"api_dataset.md\":\"B_1fKkbj\",\"api_datasets.md\":\"X5IH5o-c\",\"api_dropout.md\":\"4oOM6zi3\",\"api_flatten.md\":\"CazrUAyd\",\"api_folder.md\":\"iJO9XhTd\",\"api_function.md\":\"Cifia0I5\",\"api_functional.md\":\"vzxgI2qA\",\"api_grad_mode.md\":\"pynV7unl\",\"api_grad_scaler.md\":\"B2e1EVkK\",\"api_hooks.md\":\"oWg4LFLb\",\"api_hub.md\":\"LAmAFqTQ\",\"api_index.md\":\"7k9z3nEC\",\"api_init.md\":\"CRGsoW-4\",\"api_instancenorm.md\":\"DLI9QpOZ\",\"api_io.md\":\"B4QJ8i4z\",\"api_lazy.md\":\"CncGuZCr\",\"api_linear.md\":\"oksodNM4\",\"api_loss.md\":\"j_BqCfCJ\",\"api_lr_scheduler.md\":\"X8HZdXpB\",\"api_mkl.md\":\"BjC9gPeB\",\"api_mkldnn.md\":\"vxGeiDLe\",\"api_mnist.md\":\"y5npcclL\",\"api_models.md\":\"SRUf7VVL\",\"api_module.md\":\"BwrS1O16\",\"api_modules.md\":\"QlSgpybu\",\"api_multiprocessing.md\":\"DQUtvEWY\",\"api_nn.md\":\"COPAhDKB\",\"api_normalization.md\":\"ByrPVG7H\",\"api_onnx.md\":\"SEclrq_a\",\"api_openmp.md\":\"BT-Xb62x\",\"api_ops.md\":\"BQq94cRn\",\"api_optim.md\":\"Dn-RoM6r\",\"api_optimizer.md\":\"C2B0c4Z4\",\"api_parameter.md\":\"BKqpCoGr\",\"api_pooling.md\":\"D0thcWXT\",\"api_primitives.md\":\"D9obA82D\",\"api_rmsprop.md\":\"5QmwGE08\",\"api_sampler.md\":\"FxRjpOCf\",\"api_serialization.md\":\"DHRYYFog\",\"api_sgd.md\":\"C_yFSfpK\",\"api_sparse.md\":\"JEGqpwR5\",\"api_stax.md\":\"FE2KuGtx\",\"api_tensorplay.md\":\"CKZuHRE1\",\"api_transforms.md\":\"2p8MgsrV\",\"api_triton.md\":\"Cjx-7JMC\",\"api_types.md\":\"CXoOl-31\",\"api_utils.md\":\"D3F7mqqh\",\"api_vision.md\":\"DLc3G25z\",\"api_viz.md\":\"B2hlZ2Gl\",\"api_worker.md\":\"B5lclh1L\",\"blog_index.md\":\"D21wAZT6\",\"blog_posts_deep-dive-p10-dispatcher.md\":\"Ca8YFPud\",\"blog_posts_tensorplay-architecture-design.md\":\"B8x6QRfn\",\"blog_posts_tpx-autograd-decoupling.md\":\"D7yIFGv8\",\"changelog.md\":\"CfqvsU-D\",\"community_index.md\":\"DsvJKdP0\",\"contributing.md\":\"reV6tBNP\",\"ecosystem_index.md\":\"C5wl-ECg\",\"guide_architecture.md\":\"dtwAcikV\",\"guide_getting-started.md\":\"DA8shq5l\",\"guide_install.md\":\"CFhD7ThC\",\"guide_quickstart.md\":\"DmWxuskA\",\"guide_resources.md\":\"CvwzxFzL\",\"guide_tutorials.md\":\"DIGxDztk\",\"guide_tutorials_cnn-classification.md\":\"BW6UVjdS\",\"guide_tutorials_custom-autograd.md\":\"CisYHV9c\",\"guide_tutorials_linear-regression.md\":\"CE8n7LhM\",\"guide_what-is-tensorplay.md\":\"EVupmN6e\",\"index.md\":\"BLDTU91p\",\"join_index.md\":\"gMCm4TUT\",\"privacy_index.md\":\"CJIqUJMr\",\"subscribe_index.md\":\"B4TN1i3y\",\"zh_about_index.md\":\"-3pTOuqZ\",\"zh_api__c.md\":\"MPrSxP_X\",\"zh_api__reduction.md\":\"qV6ouOlq\",\"zh_api_activation.md\":\"DhmY2P-X\",\"zh_api_adagrad.md\":\"DBlRXNHF\",\"zh_api_adam.md\":\"C0nw-mF4\",\"zh_api_adamw.md\":\"D-lYkaTv\",\"zh_api_alexnet.md\":\"BWVWH3KT\",\"zh_api_amp.md\":\"DmfeKcbR\",\"zh_api_audio.md\":\"DV8jfVkL\",\"zh_api_autocast_mode.md\":\"CA5EsxSP\",\"zh_api_autograd.md\":\"D2gfxv4i\",\"zh_api_backend.md\":\"D7d0LjCA\",\"zh_api_backends.md\":\"DI7dZt-1\",\"zh_api_batchnorm.md\":\"QaaaODQC\",\"zh_api_collate.md\":\"CkgzFnj7\",\"zh_api_common_types.md\":\"Bi-t-p8_\",\"zh_api_comparison.md\":\"8mWeXUIV\",\"zh_api_container.md\":\"3WPRuOa5\",\"zh_api_conv.md\":\"FT4rQ48Y\",\"zh_api_cpp.md\":\"Dg31fkWU\",\"zh_api_cuda.md\":\"Ftjr_r5j\",\"zh_api_data.md\":\"DXafuWdu\",\"zh_api_dataloader.md\":\"9lTMqcrA\",\"zh_api_dataset.md\":\"BjaAZvTL\",\"zh_api_datasets.md\":\"rRe-_lwa\",\"zh_api_dropout.md\":\"DicyjWrW\",\"zh_api_flatten.md\":\"CiGze1E1\",\"zh_api_folder.md\":\"C0ip8jxS\",\"zh_api_function.md\":\"CC0XVXv7\",\"zh_api_functional.md\":\"CKRoagcS\",\"zh_api_grad_mode.md\":\"BAdK9C3A\",\"zh_api_grad_scaler.md\":\"ayjcYf_m\",\"zh_api_hooks.md\":\"lgFFJBfG\",\"zh_api_hub.md\":\"BU3mLuXZ\",\"zh_api_index.md\":\"XELyvdx1\",\"zh_api_init.md\":\"BpuF-xTb\",\"zh_api_instancenorm.md\":\"Bx8asyFc\",\"zh_api_io.md\":\"CKfyH_yr\",\"zh_api_lazy.md\":\"Dh-43yXH\",\"zh_api_linear.md\":\"DAJwSbeo\",\"zh_api_loss.md\":\"BtTzGqB8\",\"zh_api_lr_scheduler.md\":\"Bx57Gcb3\",\"zh_api_mkl.md\":\"BTQ2a__w\",\"zh_api_mkldnn.md\":\"CXkzUfQN\",\"zh_api_mnist.md\":\"DRdX7jO1\",\"zh_api_models.md\":\"FzTgqXB3\",\"zh_api_module.md\":\"yXevpwKU\",\"zh_api_modules.md\":\"4fFY20ZD\",\"zh_api_multiprocessing.md\":\"um9au9b1\",\"zh_api_nn.md\":\"CplqfocR\",\"zh_api_normalization.md\":\"hobNBqmi\",\"zh_api_onnx.md\":\"Ddz87Msq\",\"zh_api_openmp.md\":\"i1AKxeou\",\"zh_api_ops.md\":\"9Jj9Wr54\",\"zh_api_optim.md\":\"Dw0vGXeU\",\"zh_api_optimizer.md\":\"BqVotpYJ\",\"zh_api_parameter.md\":\"C3WaBDRJ\",\"zh_api_pooling.md\":\"KQjmVa32\",\"zh_api_primitives.md\":\"asKXZhlA\",\"zh_api_rmsprop.md\":\"CZe0TE5A\",\"zh_api_sampler.md\":\"B5rPkeW0\",\"zh_api_serialization.md\":\"DkXFDqSw\",\"zh_api_sgd.md\":\"sm0U3Vw6\",\"zh_api_sparse.md\":\"CejENDG3\",\"zh_api_stax.md\":\"CGuqno6N\",\"zh_api_tensorplay.md\":\"CNtf_oqw\",\"zh_api_transforms.md\":\"zevP9TO2\",\"zh_api_types.md\":\"DU2x97wA\",\"zh_api_utils.md\":\"DPEFHCAQ\",\"zh_api_vision.md\":\"DLR640Rq\",\"zh_api_viz.md\":\"B512LDgq\",\"zh_api_worker.md\":\"BUorbrDl\",\"zh_blog_index.md\":\"DVTzOKJL\",\"zh_blog_posts_deep-dive-p10-dispatcher.md\":\"DC8lY5o1\",\"zh_blog_posts_tensorplay-architecture-design.md\":\"CSq3TUdr\",\"zh_blog_posts_tpx-autograd-decoupling.md\":\"DLZzwXhu\",\"zh_changelog.md\":\"6PPzigGg\",\"zh_community_index.md\":\"EwEOzVj_\",\"zh_contributing.md\":\"CGGMcTSp\",\"zh_ecosystem_index.md\":\"yUKOvCqU\",\"zh_guide_architecture.md\":\"DCtlxIRq\",\"zh_guide_getting-started.md\":\"BKIhLfTl\",\"zh_guide_install.md\":\"D4h-Og8N\",\"zh_guide_quickstart.md\":\"CDQ5vuiK\",\"zh_guide_resources.md\":\"C7rFLh8M\",\"zh_guide_tutorials.md\":\"ZnE-wF46\",\"zh_guide_tutorials_cnn-classification.md\":\"B4Ud8y-D\",\"zh_guide_tutorials_custom-autograd.md\":\"BYkwBgzh\",\"zh_guide_tutorials_linear-regression.md\":\"BnHJUJXt\",\"zh_guide_what-is-tensorplay.md\":\"DqKe5Ta0\",\"zh_index.md\":\"CZTb8-i1\",\"zh_join_index.md\":\"CiJpMZ-N\",\"zh_privacy_index.md\":\"sYKLed_z\",\"zh_subscribe_index.md\":\"B7p3pDqA\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"TensorPlay\",\"description\":\"A transparent, educational, and PyTorch-compatible deep learning framework.\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/images/logo-0.png\",\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/bluemoon-o2/tensorplay\"}],\"search\":{\"provider\":\"local\",\"options\":{\"locales\":{\"zh\":{\"translations\":{\"button\":{\"buttonText\":\"搜索文档\",\"buttonAriaLabel\":\"搜索文档\"},\"modal\":{\"noResultsText\":\"无法找到相关结果\",\"resetButtonTitle\":\"清除查询条件\",\"footer\":{\"selectText\":\"选择\",\"navigateText\":\"切换\",\"closeText\":\"关闭\"}}}}}}}},\"locales\":{\"root\":{\"label\":\"English\",\"lang\":\"en\",\"description\":\"A simple deep learning framework designed for educational purposes and small-scale experiments.\",\"themeConfig\":{\"nav\":[{\"text\":\"Learn\",\"items\":[{\"text\":\"Getting Started\",\"link\":\"/guide/getting-started\"},{\"text\":\"Tutorials\",\"link\":\"/guide/tutorials\"}]},{\"text\":\"Community\",\"link\":\"/community/\"},{\"text\":\"Projects\",\"link\":\"/ecosystem/\"},{\"text\":\"Docs\",\"link\":\"/api/\"},{\"text\":\"Blog & News\",\"link\":\"/blog/\"},{\"text\":\"About\",\"link\":\"/about/\"},{\"text\":\"JOIN\",\"link\":\"/join/\"}],\"sidebar\":{\"/guide/\":[{\"text\":\"Introduction\",\"items\":[{\"text\":\"What is TensorPlay?\",\"link\":\"/guide/what-is-tensorplay\"},{\"text\":\"Getting Started\",\"link\":\"/guide/getting-started\"},{\"text\":\"Installation\",\"link\":\"/guide/install\"},{\"text\":\"Quickstart\",\"link\":\"/guide/quickstart\"},{\"text\":\"Architecture\",\"link\":\"/guide/architecture\"}]},{\"text\":\"Guides & Resources\",\"items\":[{\"text\":\"Tutorials\",\"link\":\"/guide/tutorials\",\"items\":[{\"text\":\"Image Classification\",\"link\":\"/guide/tutorials/cnn-classification\"},{\"text\":\"Linear Regression\",\"link\":\"/guide/tutorials/linear-regression\"},{\"text\":\"Custom Autograd\",\"link\":\"/guide/tutorials/custom-autograd\"}]},{\"text\":\"Resources\",\"link\":\"/guide/resources\"},{\"text\":\"API Reference\",\"link\":\"/api/\"}]}],\"/api/\":[{\"text\":\"Core API\",\"items\":[{\"text\":\"Overview\",\"link\":\"/api/\"},{\"text\":\"tensorplay\",\"link\":\"/api/tensorplay\"},{\"text\":\"autograd\",\"link\":\"/api/autograd\"},{\"text\":\"functional\",\"link\":\"/api/functional\"},{\"text\":\"optim\",\"link\":\"/api/optim\"},{\"text\":\"cuda\",\"link\":\"/api/cuda\"}]},{\"text\":\"Neural Networks (nn)\",\"collapsed\":false,\"items\":[{\"text\":\"nn\",\"link\":\"/api/nn\"},{\"text\":\"Modules\",\"link\":\"/api/modules\"},{\"text\":\"Linear Layers\",\"link\":\"/api/linear\"},{\"text\":\"Convolution Layers\",\"link\":\"/api/conv\"},{\"text\":\"Pooling Layers\",\"link\":\"/api/pooling\"},{\"text\":\"Activation Functions\",\"link\":\"/api/activation\"},{\"text\":\"Normalization Layers\",\"link\":\"/api/normalization\"},{\"text\":\"Loss Functions\",\"link\":\"/api/loss\"},{\"text\":\"Dropout Layers\",\"link\":\"/api/dropout\"},{\"text\":\"Container\",\"link\":\"/api/container\"}]}]},\"footer\":{\"message\":\"Released under the Apache 2.0 License.\",\"copyright\":\"Copyright © 2025 zlx. All rights reserved.\"}}},\"zh\":{\"label\":\"简体中文\",\"lang\":\"zh\",\"link\":\"/zh/\",\"description\":\"一个适合学习者、兼容 PyTorch 的深度学习框架。\",\"themeConfig\":{\"nav\":[{\"text\":\"学习\",\"items\":[{\"text\":\"快速开始\",\"link\":\"/zh/guide/getting-started\"},{\"text\":\"教程\",\"link\":\"/zh/guide/tutorials\"}]},{\"text\":\"社区\",\"link\":\"/zh/community/\"},{\"text\":\"项目\",\"link\":\"/zh/ecosystem/\"},{\"text\":\"文档\",\"link\":\"/zh/api/\"},{\"text\":\"博客与新闻\",\"link\":\"/zh/blog/\"},{\"text\":\"关于\",\"link\":\"/zh/about/\"},{\"text\":\"加入我们\",\"link\":\"/zh/join/\"}],\"sidebar\":{\"/zh/guide/\":[{\"text\":\"介绍\",\"items\":[{\"text\":\"什么是 TensorPlay?\",\"link\":\"/zh/guide/what-is-tensorplay\"},{\"text\":\"快速开始\",\"link\":\"/zh/guide/getting-started\"},{\"text\":\"安装\",\"link\":\"/zh/guide/install\"},{\"text\":\"快速入门\",\"link\":\"/zh/guide/quickstart\"},{\"text\":\"架构设计\",\"link\":\"/zh/guide/architecture\"}]},{\"text\":\"指南与资源\",\"items\":[{\"text\":\"教程\",\"link\":\"/zh/guide/tutorials\",\"items\":[{\"text\":\"图像分类\",\"link\":\"/zh/guide/tutorials/cnn-classification\"},{\"text\":\"线性回归\",\"link\":\"/zh/guide/tutorials/linear-regression\"},{\"text\":\"自定义自动微分\",\"link\":\"/zh/guide/tutorials/custom-autograd\"}]},{\"text\":\"资源\",\"link\":\"/zh/guide/resources\"},{\"text\":\"API 参考\",\"link\":\"/zh/api/\"}]}],\"/zh/api/\":[{\"text\":\"核心 API\",\"items\":[{\"text\":\"概览\",\"link\":\"/zh/api/\"},{\"text\":\"tensorplay\",\"link\":\"/zh/api/tensorplay\"},{\"text\":\"autograd\",\"link\":\"/zh/api/autograd\"},{\"text\":\"functional\",\"link\":\"/zh/api/functional\"},{\"text\":\"optim\",\"link\":\"/zh/api/optim\"},{\"text\":\"cuda\",\"link\":\"/zh/api/cuda\"}]},{\"text\":\"神经网络 (nn)\",\"collapsed\":false,\"items\":[{\"text\":\"nn\",\"link\":\"/zh/api/nn\"},{\"text\":\"Modules\",\"link\":\"/zh/api/modules\"},{\"text\":\"Linear Layers\",\"link\":\"/zh/api/linear\"},{\"text\":\"Convolution Layers\",\"link\":\"/zh/api/conv\"},{\"text\":\"Pooling Layers\",\"link\":\"/zh/api/pooling\"},{\"text\":\"Activation Functions\",\"link\":\"/zh/api/activation\"},{\"text\":\"Normalization Layers\",\"link\":\"/zh/api/normalization\"},{\"text\":\"Loss Functions\",\"link\":\"/zh/api/loss\"},{\"text\":\"Dropout Layers\",\"link\":\"/zh/api/dropout\"},{\"text\":\"Container\",\"link\":\"/zh/api/container\"}]}]},\"footer\":{\"message\":\"基于 Apache 2.0 许可发布。\",\"copyright\":\"版权所有 © 2025 zlx。保留所有权利。\"}}}},\"scrollOffset\":134,\"cleanUrls\":true}");</script>
    
  </body>
</html>
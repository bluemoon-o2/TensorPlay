import yaml
import os
import re
import argparse
import codegen_utils

# Type mapping from YAML schema to C++ signature
TYPE_MAP = {
    'int64_t[]': 'const std::vector<int64_t>&',
    'DType': 'tensorplay::DType',
    'Device': 'tensorplay::Device',
    'double': 'double',
    'bool': 'bool',
    'Scalar': 'tensorplay::Scalar',
    'Tensor': 'const tensorplay::Tensor&',
    'Tensor(a!)': 'tensorplay::Tensor&',
}

# Mapping for nanobind arguments
BINDING_TYPE_MAP = {
    'int64_t[]': 'std::vector<int64_t>', # pass by value to python adapter often easier, or stick to const ref
    # For nanobind, const std::vector<int64_t>& works fine
}

def default_handler(type_str, default):
    if default == 'Float32': return 'tensorplay::DType::Float32'
    if default == 'CPU': return 'tensorplay::Device(tensorplay::DeviceType::CPU)'
    if default == 'Int64': return 'tensorplay::DType::Int64'
    if type_str == 'Scalar' and re.match(r'^-?\d+(\.\d+)?$', default):
        return f'tensorplay::Scalar({default})'
    return default

def parse_func(func_str):
    # Use TYPE_MAP (defined in file)
    f = codegen_utils.parse_func(func_str, TYPE_MAP, default_handler)
    
    # Fix return type if needed
    # TYPE_MAP has 'Tensor': 'const tensorplay::Tensor&'
    # We want return type 'tensorplay::Tensor'
    if f['schema_return_type'] == 'Tensor':
        f['return_type'] = 'tensorplay::Tensor'
    elif f['schema_return_type'] == 'Tensor(a!)':
        f['return_type'] = 'tensorplay::Tensor&'
        
    return f

def generate_header(ops):
    lines = []
    lines.append("// Generated by tensorplaygen")
    lines.append("#pragma once")
    lines.append("#include <tensorplay/core/Tensor.h>")
    lines.append("#include <vector>")
    lines.append("")
    lines.append("// User must implement these functions in their C++ files")
    lines.append("namespace impl {")
    lines.append("")
    
    for op in ops:
        # Generate declarations for dispatched functions
        dispatch = op.get('dispatch', {})
        if not dispatch:
            # If no dispatch, assume a single function matching the name (or user provided name)
            # But usually we want explicit implementation names
            pass
            
        for device, impl_name in dispatch.items():
            # Signature matches the op
            sig = f"{op['return_type']} {impl_name}("
            arg_strs = []
            for arg in op['args']:
                arg_strs.append(f"{arg['cpp_type']} {arg['name']}")
            sig += ", ".join(arg_strs) + ");"
            lines.append(f"    {sig}")
            
    lines.append("")
    lines.append("} // namespace impl")
    return "\n".join(lines)

def generate_binding(ops, module_name):
    lines = []
    lines.append("// Generated by tensorplaygen")
    lines.append("#include <nanobind/nanobind.h>")
    lines.append("#include <nanobind/stl/vector.h>")
    lines.append("#include <tensorplay/core/Tensor.h>")
    lines.append("#include <tensorplay/core/Device.h>")
    lines.append("#include <tensorplay/core/Exception.h>")
    lines.append("#include \"OpsGenerated.h\"") # Assuming header name
    lines.append("")
    lines.append("namespace nb = nanobind;")
    lines.append("using namespace nb::literals;")
    lines.append("using namespace tensorplay;")
    lines.append("")
    
    # Generate dispatch wrappers
    lines.append("// Dispatch wrappers")
    for op in ops:
        fname = op['name']
        dispatch = op.get('dispatch', {})
        
        # Signature
        sig = f"{op['return_type']} {fname}_dispatch("
        arg_strs = []
        for arg in op['args']:
            arg_strs.append(f"{arg['cpp_type']} {arg['name']}")
        sig += ", ".join(arg_strs) + ") {"
        lines.append(sig)
        
        # Dispatch logic
        # Find first Tensor argument to check device
        tensor_arg = next((arg for arg in op['args'] if 'Tensor' in arg['type']), None)
        
        if not tensor_arg and dispatch:
             lines.append(f'    TP_THROW(RuntimeError, "{fname}: No Tensor argument to dispatch on.");')
        elif dispatch:
            lines.append(f"    DeviceType dt = {tensor_arg['name']}.device().type();")
            
            for device, impl_name in dispatch.items():
                if device == 'CPU':
                    lines.append("    if (dt == DeviceType::CPU) {")
                    
                elif device == 'CUDA':
                    lines.append("    if (dt == DeviceType::CUDA) {")
                else:
                    lines.append(f"    // Unknown device: {device}")
                    continue
                
                # Call impl
                call_args = [arg['name'] for arg in op['args']]
                lines.append(f"        return impl::{impl_name}({', '.join(call_args)});")
                lines.append("    }")
            
            lines.append(f'    TP_THROW(NotImplementedError, "{fname}: No implementation for device");')
            
        lines.append("}")
        lines.append("")

    lines.append(f"NB_MODULE({module_name}, m) {{")
    
    for op in ops:
        fname = op['name']
        lines.append(f'    m.def("{fname}", &{fname}_dispatch,')
        for arg in op['args']:
            arg_def = f'"{arg["name"]}"_a'
            if arg['default']:
                arg_def += f" = {arg['default']}"
            lines.append(f"          {arg_def},")
        lines.append("          nb::rv_policy::move);") # Default policy for value return
        
    lines.append("}")
    
    return "\n".join(lines)

def main():
    parser = argparse.ArgumentParser(description="TensorPlay Custom Op Generator")
    parser.add_argument('--yaml', required=True, help='Path to .tp_ops.yaml')
    parser.add_argument('--out_dir', required=True, help='Output directory')
    parser.add_argument('--module_name', default='custom_ops', help='Name of the generated python module')
    args = parser.parse_args()
    
    with open(args.yaml, 'r') as f:
        data = yaml.safe_load(f)
        
    if data is None:
        data = []
        
    ops = []
    for item in data:
        op = parse_func(item['func'])
        op['dispatch'] = item.get('dispatch', {})
        op['autograd'] = item.get('autograd', {})
        ops.append(op)
        
    if not os.path.exists(args.out_dir):
        os.makedirs(args.out_dir)
        
    header_path = os.path.join(args.out_dir, "OpsGenerated.h")
    cpp_path = os.path.join(args.out_dir, "OpsBinding.cpp")
    
    with open(header_path, 'w') as f:
        f.write(generate_header(ops))
        
    with open(cpp_path, 'w') as f:
        f.write(generate_binding(ops, args.module_name))
        
    print(f"Generated {header_path} and {cpp_path}")

if __name__ == "__main__":
    main()

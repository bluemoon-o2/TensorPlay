<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    
    <title>tensorplay.autograd | TensorPlay</title>
    <meta name="description" content="A simple deep learning framework designed for educational purposes and small-scale experiments.">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/assets/style.BnQNfQuE.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.BOYV62xo.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.D353iLUo.js">
    <link rel="modulepreload" href="/assets/chunks/framework.t-GQSDtj.js">
    <link rel="modulepreload" href="/assets/api_autograd.md.C37rD2mB.lean.js">
    <link rel="icon" type="image/png" href="/images/logo-0.png">
    <link rel="apple-touch-icon" href="/images/logo-0.png">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="keywords" content="deep learning, machine learning, ai framework, pytorch compatible, educational, c++, python, tensorplay, 深度学习, 机器学习, 自动微分">
    <meta name="author" content="TensorPlay Team">
    <meta property="og:type" content="website">
    <meta property="og:title" content="TensorPlay | Transparent &amp; Compatible AI Framework">
    <meta property="og:description" content="A transparent, educational, and PyTorch-compatible deep learning framework for the modern AI era.">
    <meta property="og:site_name" content="TensorPlay">
    <meta property="og:url" content="https://www.tensorplay.cn">
    <meta property="og:image" content="https://www.tensorplay.cn/images/logo-1.png">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="TensorPlay | Transparent &amp; Compatible AI Framework">
    <meta name="twitter:description" content="A transparent, educational, and PyTorch-compatible deep learning framework for the modern AI era.">
    <meta name="twitter:image" content="https://www.tensorplay.cn/images/logo-1.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300;400;500;600;700&amp;display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><canvas id="cyberpunk-particles" data-v-36680640></canvas><!----><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/" data-v-1168a8e4><!--[--><!--]--><!--[--><img class="VPImage logo" src="/images/logo-0.png" alt data-v-8426fc1a><!--]--><span data-v-1168a8e4>TensorPlay</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><!----><span data-v-cf11d7a2>Learn</span><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/guide/getting-started.html" data-v-35975db6><!--[--><span data-v-35975db6>Getting Started</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/guide/tutorials.html" data-v-35975db6><!--[--><span data-v-35975db6>Tutorials</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/community/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Community</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/ecosystem/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Projects</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/api/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Docs</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Blog & News</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/about/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>About</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/join/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>JOIN</span><!--]--></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-6aa21345 data-v-88af2de4 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><span class="vpi-languages option-icon" data-v-cf11d7a2></span><!----><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><div class="items" data-v-88af2de4><p class="title" data-v-88af2de4>English</p><!--[--><div class="VPMenuLink" data-v-88af2de4 data-v-35975db6><a class="VPLink link" href="/zh/api/autograd.html" data-v-35975db6><!--[--><span data-v-35975db6>简体中文</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/bluemoon-o2/tensorplay" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><div class="group translations" data-v-bb2aa2f0><p class="trans-title" data-v-bb2aa2f0>English</p><!--[--><div class="VPMenuLink" data-v-bb2aa2f0 data-v-35975db6><a class="VPLink link" href="/zh/api/autograd.html" data-v-35975db6><!--[--><span data-v-35975db6>简体中文</span><!--]--></a></div><!--]--></div><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/bluemoon-o2/tensorplay" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 has-active" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Core API</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/tensorplay.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>tensorplay</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/autograd.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>autograd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/functional.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>functional</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/optim.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>optim</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/cuda.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>cuda</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Neural Networks (nn)</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/nn.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>nn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/modules.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Modules</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/linear.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Linear Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/conv.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Convolution Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/pooling.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Pooling Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/activation.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Activation Functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/normalization.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Normalization Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/loss.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Loss Functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/dropout.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dropout Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/container.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Container</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>On this page</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--[--><!--[--><!----><!--]--><!--]--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _api_autograd" data-v-39a288b8><div><h1 id="tensorplay-autograd" tabindex="-1">tensorplay.autograd <a class="header-anchor" href="#tensorplay-autograd" aria-label="Permalink to &quot;tensorplay.autograd&quot;">​</a></h1><p><code>tensorplay.autograd</code> provides classes and functions implementing automatic differentiation of arbitrary scalar valued functions.</p><p>It requires minimal changes to the existing code - you only need to declare <code>Tensor</code> s for which gradients should be computed with the <code>requires_grad=True</code> keyword. As of now, we only support autograd for floating point <code>Tensor</code> types ( half, float, double and bfloat16) and complex <code>Tensor</code> types (cfloat, cdouble).</p><h2 id="classes" tabindex="-1">Classes <a class="header-anchor" href="#classes" aria-label="Permalink to &quot;Classes&quot;">​</a></h2><h3 id="class-function-source" tabindex="-1"><code>class Function</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L18" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-function-source" aria-label="Permalink to &quot;`class Function` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L18)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Function()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Records operation history and defines formulas for differentiating ops.</p><details><summary>Methods</summary><h4 id="apply-args-kwargs-source" tabindex="-1"><code>apply(*args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L37" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#apply-args-kwargs-source" aria-label="Permalink to &quot;`apply(*args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L37)&quot;">​</a></h4><hr><h4 id="backward-ctx-grad-outputs-source" tabindex="-1"><code>backward(ctx, *grad_outputs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L30" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#backward-ctx-grad-outputs-source" aria-label="Permalink to &quot;`backward(ctx, *grad_outputs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L30)&quot;">​</a></h4><p>Defines a formula for differentiating the operation.</p><hr><h4 id="forward-ctx-args-kwargs-source" tabindex="-1"><code>forward(ctx, *args, **kwargs)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L23" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#forward-ctx-args-kwargs-source" aria-label="Permalink to &quot;`forward(ctx, *args, **kwargs)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/function.py#L23)&quot;">​</a></h4><p>Performs the operation.</p><hr></details><h3 id="class-enable-grad-source" tabindex="-1"><code>class enable_grad</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L86" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-enable-grad-source" aria-label="Permalink to &quot;`class enable_grad` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L86)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">enable_grad(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">orig_func</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_NoParamDecoratorContextManager</code></p><p>Context-manager that enables gradient calculation.</p><p>Enables gradient calculation, if it has been disabled via <code>~no_grad</code> or <code>~set_grad_enabled</code>.</p><p>This context manager is thread local; it will not affect computation in other threads.</p><p>Also functions as a decorator.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>enable_grad is one of several mechanisms that can enable or disable gradients locally see <code>locally-disable-grad-doc</code> for more information on how they compare.</p></div><div class="info custom-block"><p class="custom-block-title">INFO</p><p>This API does not apply to <code>forward-mode AD &lt;forward-mode-ad&gt;</code>.</p></div><h4 id="example" tabindex="-1">Example <a class="header-anchor" href="#example" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.enable_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.backward()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x.grad</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.])</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.enable_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> doubler</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doubler(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.enable_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> tripler</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 3</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tripler(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div><details><summary>Methods</summary><h4 id="clone-self-source" tabindex="-1"><code>clone(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/utils/_contextlib.py#L147" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#clone-self-source" aria-label="Permalink to &quot;`clone(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/utils/_contextlib.py#L147)&quot;">​</a></h4><hr></details><h3 id="class-no-grad-source" tabindex="-1"><code>class no_grad</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L21" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-no-grad-source" aria-label="Permalink to &quot;`class no_grad` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L21)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">no_grad() </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_NoParamDecoratorContextManager</code></p><p>Context-manager that disables gradient calculation.</p><p>Disabling gradient calculation is useful for inference, when you are sure that you will not call <code>Tensor.backward()</code>. It will reduce memory consumption for computations that would otherwise have <code>requires_grad=True</code>.</p><p>In this mode, the result of every computation will have <code>requires_grad=False</code>, even when the inputs have <code>requires_grad=True</code>. There is an exception! All factory functions, or functions that create a new Tensor and take a requires_grad kwarg, will NOT be affected by this mode.</p><p>This context manager is thread local; it will not affect computation in other threads.</p><p>Also functions as a decorator.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>No-grad is one of several mechanisms that can enable or disable gradients locally see <code>locally-disable-grad-doc</code> for more information on how they compare.</p></div><div class="info custom-block"><p class="custom-block-title">INFO</p><p>This API does not apply to <code>forward-mode AD &lt;forward-mode-ad&gt;</code>. If you want to disable forward AD for a computation, you can unpack your dual tensors.</p></div><h4 id="example-1" tabindex="-1">Example <a class="header-anchor" href="#example-1" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.no_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> doubler</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doubler(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@tensorplay.no_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> tripler</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 3</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tripler(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># factory function exception</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.nn.Parameter(tensorplay.rand(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">a.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><details><summary>Methods</summary><h4 id="init-self-none-source" tabindex="-1"><code>__init__(self) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L74" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-none-source" aria-label="Permalink to &quot;`__init__(self) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L74)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="clone-self-source-1" tabindex="-1"><code>clone(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/utils/_contextlib.py#L147" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#clone-self-source-1" aria-label="Permalink to &quot;`clone(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/utils/_contextlib.py#L147)&quot;">​</a></h4><hr></details><h3 id="class-set-grad-enabled-source" tabindex="-1"><code>class set_grad_enabled</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L145" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-set-grad-enabled-source" aria-label="Permalink to &quot;`class set_grad_enabled` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L145)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">set_grad_enabled(mode: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_DecoratorContextManager</code></p><p>Context-manager that sets gradient calculation on or off.</p><p><code>set_grad_enabled</code> will enable or disable grads based on its argument <code>mode</code>. It can be used as a context-manager or as a function.</p><p>This context manager is thread local; it will not affect computation in other threads.</p><h4 id="args" tabindex="-1">Args <a class="header-anchor" href="#args" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>mode</strong> (<code>bool</code>): Flag whether to enable grad (<code>True</code>), or disable (<code>False</code>). This can be used to conditionally enable gradients.</li></ul><div class="info custom-block"><p class="custom-block-title">INFO</p><p>set_grad_enabled is one of several mechanisms that can enable or disable gradients locally see <code>locally-disable-grad-doc</code> for more information on how they compare.</p></div><div class="info custom-block"><p class="custom-block-title">INFO</p><p>This API does not apply to <code>forward-mode AD &lt;forward-mode-ad&gt;</code>.</p></div><h4 id="example-2" tabindex="-1">Example <a class="header-anchor" href="#example-2" aria-label="Permalink to &quot;Example&quot;">​</a></h4><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># xdoctest: +SKIP</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">is_train </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.set_grad_enabled(is_train):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.set_grad_enabled(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorplay.set_grad_enabled(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y.requires_grad</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><details><summary>Methods</summary><h4 id="init-self-mode-bool-none-source" tabindex="-1"><code>__init__(self, mode: bool) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L186" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-mode-bool-none-source" aria-label="Permalink to &quot;`__init__(self, mode: bool) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L186)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="clone-self-set-grad-enabled-source" tabindex="-1"><code>clone(self) -&gt; &#39;set_grad_enabled&#39;</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L208" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#clone-self-set-grad-enabled-source" aria-label="Permalink to &quot;`clone(self) -&gt; &#39;set_grad_enabled&#39;` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L208)&quot;">​</a></h4><p>Create a copy of this class</p><hr></details><h2 id="functions" tabindex="-1">Functions <a class="header-anchor" href="#functions" aria-label="Permalink to &quot;Functions&quot;">​</a></h2><h3 id="grad-source" tabindex="-1"><code>grad()</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/__init__.py#L43" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#grad-source" aria-label="Permalink to &quot;`grad()` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/__init__.py#L43)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">grad(outputs: Union[tensorplay._C.TensorBase, collections.abc.Sequence[tensorplay._C.TensorBase]], inputs: Union[tensorplay._C.TensorBase, collections.abc.Sequence[tensorplay._C.TensorBase]], grad_outputs: Union[tensorplay._C.TensorBase, collections.abc.Sequence[tensorplay._C.TensorBase], NoneType] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, retain_graph: Optional[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, create_graph: </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, allow_unused: Optional[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">-&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tuple[tensorplay._C.TensorBase, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Compute and return the sum of gradients of outputs with respect to the inputs.</p><p><code>grad_outputs</code> should be a sequence of length matching <code>output</code> containing the &quot;vector&quot; in vector-Jacobian product, usually the pre-computed gradients w.r.t. each of the outputs. If an output doesn&#39;t require_grad, then the gradient can be <code>None</code>).</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>If you run any forward ops, create <code>grad_outputs</code>, and/or call <code>grad</code> in a user-specified CUDA stream context, see <code>Stream semantics of backward passes&lt;bwd-cuda-stream-semantics&gt;</code>.</p></div><h4 id="args-1" tabindex="-1">Args <a class="header-anchor" href="#args-1" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>outputs</strong> (<code>sequence of Tensor or GradientEdge</code>): outputs of the differentiated function.</li><li><strong>inputs</strong> (<code>sequence of Tensor or GradientEdge</code>): Inputs w.r.t. which the gradient will be returned (and not accumulated into <code>.grad</code>).</li><li><strong>grad_outputs</strong> (<code>sequence of Tensor</code>): The &quot;vector&quot; in the vector-Jacobian product. Usually gradients w.r.t. each output. None values can be specified for scalar Tensors or ones that don&#39;t require grad. If a None value would be acceptable for all grad_tensors, then this argument is optional. Default: None.</li><li><strong>retain_graph</strong> (<code>bool, optional</code>): If <code>False</code>, the graph used to compute the grad will be freed. Note that in nearly all cases setting this option to <code>True</code> is not needed and often can be worked around in a much more efficient way. Defaults to the value of <code>create_graph</code>.</li><li><strong>create_graph</strong> (<code>bool, optional</code>): If <code>True</code>, graph of the derivative will be constructed, allowing to compute higher order derivative products.</li><li><strong>Default</strong>: <code>False</code>.</li><li><strong>allow_unused</strong> (<code>Optional[bool], optional</code>): If <code>False</code>, specifying inputs that were not used when computing outputs (and therefore their grad is always zero) is an error. Defaults to the value of <code>materialize_grads</code>.</li></ul><h3 id="is-grad-enabled-source" tabindex="-1"><code>is_grad_enabled()</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L141" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#is-grad-enabled-source" aria-label="Permalink to &quot;`is_grad_enabled()` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/autograd/grad_mode.py#L141)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">is_grad_enabled()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/api/tensorplay.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Previous page</span><span class="title" data-v-e257564d>tensorplay</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/api/functional.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>functional</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>Released under the Apache 2.0 License.</p><p class="copyright" data-v-e315a0ad>Copyright © 2025 zlx. All rights reserved.</p></div></footer><!--[--><a href="https://deepwiki.com/bluemoon-o2/TensorPlay" target="_blank" rel="noopener noreferrer" class="deepwiki-floating-badge" title="View on DeepWiki" data-v-5bf2a798><div class="badge-content" data-v-5bf2a798><span class="badge-icon" data-v-5bf2a798>📚</span><span class="badge-text" data-v-5bf2a798>DeepWiki</span></div></a><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_index.md\":\"D9dXnE2q\",\"api__c.md\":\"Qv-Y0wjX\",\"api__reduction.md\":\"rW4mwTRL\",\"api_activation.md\":\"DBJWtw-_\",\"api_adagrad.md\":\"7fEiNcol\",\"api_adam.md\":\"DgIdmxbk\",\"api_adamw.md\":\"S2cbrQb2\",\"api_alexnet.md\":\"xfyhbAAv\",\"api_amp.md\":\"C1Rj-pkI\",\"api_audio.md\":\"CAYtsDhl\",\"api_autocast_mode.md\":\"Hp418vAU\",\"api_autograd.md\":\"C37rD2mB\",\"api_backend.md\":\"CKBPOse6\",\"api_backends.md\":\"CBEPI80Z\",\"api_batchnorm.md\":\"CsfUu6Z4\",\"api_collate.md\":\"VS3YRrxy\",\"api_common_types.md\":\"B_86CbjF\",\"api_comparison.md\":\"rUN-CnTf\",\"api_container.md\":\"Cbof7ev1\",\"api_conv.md\":\"CIzymlZe\",\"api_cpp.md\":\"-u6g5kTd\",\"api_cpu.md\":\"DsGhUd54\",\"api_cuda.md\":\"DBdOhQWo\",\"api_data.md\":\"BOUwdm3B\",\"api_dataloader.md\":\"D2ehS173\",\"api_dataset.md\":\"BiSF7wC4\",\"api_datasets.md\":\"DRjHfmsZ\",\"api_dropout.md\":\"D2jx3blg\",\"api_flatten.md\":\"kF2VdI-B\",\"api_folder.md\":\"DfdTacwP\",\"api_function.md\":\"5rAE_oC6\",\"api_functional.md\":\"BzPu4r9-\",\"api_grad_mode.md\":\"DezgUw3X\",\"api_grad_scaler.md\":\"6-RhoFRG\",\"api_hooks.md\":\"hmrR_JFD\",\"api_hub.md\":\"B2G66UMX\",\"api_index.md\":\"CYD0ysgI\",\"api_init.md\":\"Cj8numYV\",\"api_instancenorm.md\":\"g1Nob3MB\",\"api_io.md\":\"CGoKD34V\",\"api_lazy.md\":\"CtdTYN7T\",\"api_linear.md\":\"BFksnXVV\",\"api_loss.md\":\"D6D496Nc\",\"api_lr_scheduler.md\":\"DMd8S7P9\",\"api_mkl.md\":\"KhDXHcio\",\"api_mkldnn.md\":\"OSo2TWhL\",\"api_mnist.md\":\"H73sp2Vx\",\"api_models.md\":\"CZ5yo_yb\",\"api_module.md\":\"wX6_Ikao\",\"api_modules.md\":\"49CYcx2L\",\"api_multiprocessing.md\":\"Bd55nk9B\",\"api_nn.md\":\"DMjIkNqO\",\"api_normalization.md\":\"B7JudeAG\",\"api_onnx.md\":\"bPexZ2kf\",\"api_openmp.md\":\"0DZ1wZuu\",\"api_ops.md\":\"Cx9M0vLQ\",\"api_optim.md\":\"BOjgiHyt\",\"api_optimizer.md\":\"DR7JhJE4\",\"api_parameter.md\":\"DhBlWvMo\",\"api_pooling.md\":\"DQs7B4a8\",\"api_primitives.md\":\"BR4vfoSM\",\"api_rmsprop.md\":\"CIbJMV6n\",\"api_sampler.md\":\"i75Z7DWN\",\"api_serialization.md\":\"B6wu7cB-\",\"api_sgd.md\":\"BV8ROtS0\",\"api_sparse.md\":\"0uz7O3D9\",\"api_stax.md\":\"C3cBQ6GW\",\"api_tensorplay.md\":\"CQCL757z\",\"api_transforms.md\":\"BNml18Hv\",\"api_triton.md\":\"kCIU5EE5\",\"api_types.md\":\"DEthfquR\",\"api_utils.md\":\"C52JWJfN\",\"api_vision.md\":\"Dsfwg8F4\",\"api_viz.md\":\"CoC58de7\",\"api_worker.md\":\"CJ7Xru23\",\"blog_index.md\":\"DWx6QLbZ\",\"blog_posts_deep-dive-p10-dispatcher.md\":\"Bsr5JIJl\",\"blog_posts_tensorplay-architecture-design.md\":\"DZ5JTIw8\",\"blog_posts_tpx-autograd-decoupling.md\":\"MgXrRr7D\",\"changelog.md\":\"BjgyldP3\",\"community_index.md\":\"CD0VRmCL\",\"contributing.md\":\"_wut4jFO\",\"ecosystem_index.md\":\"CsS7Iq3X\",\"guide_architecture.md\":\"DN9lvA1S\",\"guide_getting-started.md\":\"DxMhyyFi\",\"guide_install.md\":\"BP5Ti7wA\",\"guide_quickstart.md\":\"3nrEFmq3\",\"guide_resources.md\":\"Et5vYTSi\",\"guide_tutorials.md\":\"Bzn4fGO6\",\"guide_tutorials_cnn-classification.md\":\"3MlqEGfJ\",\"guide_tutorials_custom-autograd.md\":\"BA2l9XEV\",\"guide_tutorials_linear-regression.md\":\"CAjgMIxs\",\"guide_what-is-tensorplay.md\":\"Bus4zqCU\",\"index.md\":\"BJoikFZB\",\"join_index.md\":\"DyN1heDn\",\"privacy.md\":\"CUargZAb\",\"subscribe.md\":\"yyhsv4JB\",\"zh_about_index.md\":\"CfkbfFQO\",\"zh_api__c.md\":\"QeicHXDe\",\"zh_api__reduction.md\":\"DKP80wgV\",\"zh_api_activation.md\":\"CUSYvzmq\",\"zh_api_adagrad.md\":\"DsSFdYof\",\"zh_api_adam.md\":\"aYFvwb_r\",\"zh_api_adamw.md\":\"CuuMUrqp\",\"zh_api_alexnet.md\":\"lUwYgt4s\",\"zh_api_amp.md\":\"Bx-qbrS1\",\"zh_api_audio.md\":\"DZ7q1f0A\",\"zh_api_autocast_mode.md\":\"uTU9KiPt\",\"zh_api_autograd.md\":\"CPhHsUFS\",\"zh_api_backend.md\":\"fRwsnBsB\",\"zh_api_backends.md\":\"BdFrLHXF\",\"zh_api_batchnorm.md\":\"CxUNeLTO\",\"zh_api_collate.md\":\"Cws0sRGA\",\"zh_api_common_types.md\":\"BEuCGHON\",\"zh_api_comparison.md\":\"-2Uetodq\",\"zh_api_container.md\":\"D37_QN0R\",\"zh_api_conv.md\":\"DJ8R3UbX\",\"zh_api_cpp.md\":\"CBkBC3zp\",\"zh_api_cuda.md\":\"DLkcv7Ir\",\"zh_api_data.md\":\"Bm-dEaQ8\",\"zh_api_dataloader.md\":\"lDF5DeKn\",\"zh_api_dataset.md\":\"BY_BnnRD\",\"zh_api_datasets.md\":\"CGpwicJU\",\"zh_api_dropout.md\":\"BMfQ_6Jp\",\"zh_api_flatten.md\":\"Cz8OGJr_\",\"zh_api_folder.md\":\"Dkku3kqH\",\"zh_api_function.md\":\"Hl6Wc3if\",\"zh_api_functional.md\":\"BBH6gxp5\",\"zh_api_grad_mode.md\":\"B-aIV7qE\",\"zh_api_grad_scaler.md\":\"KHiz-nuo\",\"zh_api_hooks.md\":\"BcBD7LCX\",\"zh_api_hub.md\":\"BarfC3-I\",\"zh_api_index.md\":\"T7wkXIIq\",\"zh_api_init.md\":\"idSMB-ST\",\"zh_api_instancenorm.md\":\"BYOE56AO\",\"zh_api_io.md\":\"DqQyHES8\",\"zh_api_lazy.md\":\"CTqJ9B6Q\",\"zh_api_linear.md\":\"Bw2KJByh\",\"zh_api_loss.md\":\"CD_2mlj8\",\"zh_api_lr_scheduler.md\":\"CJQqZqOW\",\"zh_api_mkl.md\":\"DNl7FjP1\",\"zh_api_mkldnn.md\":\"C1sB8LAM\",\"zh_api_mnist.md\":\"CiAk-CTL\",\"zh_api_models.md\":\"DA2vw96r\",\"zh_api_module.md\":\"C-JmapjX\",\"zh_api_modules.md\":\"DdXcls2D\",\"zh_api_multiprocessing.md\":\"BIFNJIFd\",\"zh_api_nn.md\":\"6X89tfqq\",\"zh_api_normalization.md\":\"D4kXog4C\",\"zh_api_onnx.md\":\"C3CyIUd2\",\"zh_api_openmp.md\":\"BrkaPwMO\",\"zh_api_ops.md\":\"DLDjaRJF\",\"zh_api_optim.md\":\"H0ppJfCx\",\"zh_api_optimizer.md\":\"B23Nsf3p\",\"zh_api_parameter.md\":\"CI9-b1SL\",\"zh_api_pooling.md\":\"D-QWUN-u\",\"zh_api_primitives.md\":\"CQMCnO1g\",\"zh_api_rmsprop.md\":\"DcIfxc-y\",\"zh_api_sampler.md\":\"1BHbZ0ce\",\"zh_api_serialization.md\":\"BK3y5eRp\",\"zh_api_sgd.md\":\"D4bm7-9m\",\"zh_api_sparse.md\":\"Fk1PMEC7\",\"zh_api_stax.md\":\"rEV1TX_h\",\"zh_api_tensorplay.md\":\"Bcr-Gbkh\",\"zh_api_transforms.md\":\"B9PVNQ_u\",\"zh_api_types.md\":\"B19GW1aQ\",\"zh_api_utils.md\":\"C4y9IfsU\",\"zh_api_vision.md\":\"DQiyNVBw\",\"zh_api_viz.md\":\"DsbB1XZt\",\"zh_api_worker.md\":\"D391YJXa\",\"zh_blog_index.md\":\"BYN71ob1\",\"zh_blog_posts_deep-dive-p10-dispatcher.md\":\"Y3GqFZb4\",\"zh_blog_posts_tensorplay-architecture-design.md\":\"QEfEv62m\",\"zh_blog_posts_tpx-autograd-decoupling.md\":\"DBPxqNCw\",\"zh_changelog.md\":\"CIInNQ38\",\"zh_community_index.md\":\"BrTXnH0F\",\"zh_contributing.md\":\"BIqwhrVB\",\"zh_ecosystem_index.md\":\"BZxgrPi-\",\"zh_guide_architecture.md\":\"B71RCcWJ\",\"zh_guide_getting-started.md\":\"0DEyCvVy\",\"zh_guide_install.md\":\"B8k6r5zl\",\"zh_guide_quickstart.md\":\"DW3vVox8\",\"zh_guide_resources.md\":\"BR79XVNb\",\"zh_guide_tutorials.md\":\"BmJcGJVU\",\"zh_guide_tutorials_cnn-classification.md\":\"DiJZgTxg\",\"zh_guide_tutorials_custom-autograd.md\":\"CV4tgvS7\",\"zh_guide_tutorials_linear-regression.md\":\"BzPRWTLi\",\"zh_guide_what-is-tensorplay.md\":\"siipjvez\",\"zh_index.md\":\"BSTTcJkG\",\"zh_join_index.md\":\"D-DdnxPn\",\"zh_privacy.md\":\"DVaX5FnO\",\"zh_subscribe.md\":\"fu0XvrWf\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"TensorPlay\",\"description\":\"A transparent, educational, and PyTorch-compatible deep learning framework.\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/images/logo-0.png\",\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/bluemoon-o2/tensorplay\"}],\"search\":{\"provider\":\"local\",\"options\":{\"locales\":{\"zh\":{\"translations\":{\"button\":{\"buttonText\":\"搜索文档\",\"buttonAriaLabel\":\"搜索文档\"},\"modal\":{\"noResultsText\":\"无法找到相关结果\",\"resetButtonTitle\":\"清除查询条件\",\"footer\":{\"selectText\":\"选择\",\"navigateText\":\"切换\",\"closeText\":\"关闭\"}}}}}}}},\"locales\":{\"root\":{\"label\":\"English\",\"lang\":\"en\",\"description\":\"A simple deep learning framework designed for educational purposes and small-scale experiments.\",\"themeConfig\":{\"nav\":[{\"text\":\"Learn\",\"items\":[{\"text\":\"Getting Started\",\"link\":\"/guide/getting-started\"},{\"text\":\"Tutorials\",\"link\":\"/guide/tutorials\"}]},{\"text\":\"Community\",\"link\":\"/community/\"},{\"text\":\"Projects\",\"link\":\"/ecosystem/\"},{\"text\":\"Docs\",\"link\":\"/api/\"},{\"text\":\"Blog & News\",\"link\":\"/blog/\"},{\"text\":\"About\",\"link\":\"/about/\"},{\"text\":\"JOIN\",\"link\":\"/join/\"}],\"sidebar\":{\"/guide/\":[{\"text\":\"Introduction\",\"items\":[{\"text\":\"What is TensorPlay?\",\"link\":\"/guide/what-is-tensorplay\"},{\"text\":\"Getting Started\",\"link\":\"/guide/getting-started\"},{\"text\":\"Installation\",\"link\":\"/guide/install\"},{\"text\":\"Quickstart\",\"link\":\"/guide/quickstart\"},{\"text\":\"Architecture\",\"link\":\"/guide/architecture\"}]},{\"text\":\"Guides & Resources\",\"items\":[{\"text\":\"Tutorials\",\"link\":\"/guide/tutorials\",\"items\":[{\"text\":\"Image Classification\",\"link\":\"/guide/tutorials/cnn-classification\"},{\"text\":\"Linear Regression\",\"link\":\"/guide/tutorials/linear-regression\"},{\"text\":\"Custom Autograd\",\"link\":\"/guide/tutorials/custom-autograd\"}]},{\"text\":\"Resources\",\"link\":\"/guide/resources\"},{\"text\":\"API Reference\",\"link\":\"/api/\"}]}],\"/api/\":[{\"text\":\"Core API\",\"items\":[{\"text\":\"Overview\",\"link\":\"/api/\"},{\"text\":\"tensorplay\",\"link\":\"/api/tensorplay\"},{\"text\":\"autograd\",\"link\":\"/api/autograd\"},{\"text\":\"functional\",\"link\":\"/api/functional\"},{\"text\":\"optim\",\"link\":\"/api/optim\"},{\"text\":\"cuda\",\"link\":\"/api/cuda\"}]},{\"text\":\"Neural Networks (nn)\",\"collapsed\":false,\"items\":[{\"text\":\"nn\",\"link\":\"/api/nn\"},{\"text\":\"Modules\",\"link\":\"/api/modules\"},{\"text\":\"Linear Layers\",\"link\":\"/api/linear\"},{\"text\":\"Convolution Layers\",\"link\":\"/api/conv\"},{\"text\":\"Pooling Layers\",\"link\":\"/api/pooling\"},{\"text\":\"Activation Functions\",\"link\":\"/api/activation\"},{\"text\":\"Normalization Layers\",\"link\":\"/api/normalization\"},{\"text\":\"Loss Functions\",\"link\":\"/api/loss\"},{\"text\":\"Dropout Layers\",\"link\":\"/api/dropout\"},{\"text\":\"Container\",\"link\":\"/api/container\"}]}]},\"footer\":{\"message\":\"Released under the Apache 2.0 License.\",\"copyright\":\"Copyright © 2025 zlx. All rights reserved.\"}}},\"zh\":{\"label\":\"简体中文\",\"lang\":\"zh\",\"link\":\"/zh/\",\"description\":\"一个适合学习者、兼容 PyTorch 的深度学习框架。\",\"themeConfig\":{\"nav\":[{\"text\":\"学习\",\"items\":[{\"text\":\"快速开始\",\"link\":\"/zh/guide/getting-started\"},{\"text\":\"教程\",\"link\":\"/zh/guide/tutorials\"}]},{\"text\":\"社区\",\"link\":\"/zh/community/\"},{\"text\":\"项目\",\"link\":\"/zh/ecosystem/\"},{\"text\":\"文档\",\"link\":\"/zh/api/\"},{\"text\":\"博客与新闻\",\"link\":\"/zh/blog/\"},{\"text\":\"关于\",\"link\":\"/zh/about/\"},{\"text\":\"加入我们\",\"link\":\"/zh/join/\"}],\"sidebar\":{\"/zh/guide/\":[{\"text\":\"介绍\",\"items\":[{\"text\":\"什么是 TensorPlay?\",\"link\":\"/zh/guide/what-is-tensorplay\"},{\"text\":\"快速开始\",\"link\":\"/zh/guide/getting-started\"},{\"text\":\"安装\",\"link\":\"/zh/guide/install\"},{\"text\":\"快速入门\",\"link\":\"/zh/guide/quickstart\"},{\"text\":\"架构设计\",\"link\":\"/zh/guide/architecture\"}]},{\"text\":\"指南与资源\",\"items\":[{\"text\":\"教程\",\"link\":\"/zh/guide/tutorials\",\"items\":[{\"text\":\"图像分类\",\"link\":\"/zh/guide/tutorials/cnn-classification\"},{\"text\":\"线性回归\",\"link\":\"/zh/guide/tutorials/linear-regression\"},{\"text\":\"自定义自动微分\",\"link\":\"/zh/guide/tutorials/custom-autograd\"}]},{\"text\":\"资源\",\"link\":\"/zh/guide/resources\"},{\"text\":\"API 参考\",\"link\":\"/zh/api/\"}]}],\"/zh/api/\":[{\"text\":\"核心 API\",\"items\":[{\"text\":\"概览\",\"link\":\"/zh/api/\"},{\"text\":\"tensorplay\",\"link\":\"/zh/api/tensorplay\"},{\"text\":\"autograd\",\"link\":\"/zh/api/autograd\"},{\"text\":\"functional\",\"link\":\"/zh/api/functional\"},{\"text\":\"optim\",\"link\":\"/zh/api/optim\"},{\"text\":\"cuda\",\"link\":\"/zh/api/cuda\"}]},{\"text\":\"神经网络 (nn)\",\"collapsed\":false,\"items\":[{\"text\":\"nn\",\"link\":\"/zh/api/nn\"},{\"text\":\"Modules\",\"link\":\"/zh/api/modules\"},{\"text\":\"Linear Layers\",\"link\":\"/zh/api/linear\"},{\"text\":\"Convolution Layers\",\"link\":\"/zh/api/conv\"},{\"text\":\"Pooling Layers\",\"link\":\"/zh/api/pooling\"},{\"text\":\"Activation Functions\",\"link\":\"/zh/api/activation\"},{\"text\":\"Normalization Layers\",\"link\":\"/zh/api/normalization\"},{\"text\":\"Loss Functions\",\"link\":\"/zh/api/loss\"},{\"text\":\"Dropout Layers\",\"link\":\"/zh/api/dropout\"},{\"text\":\"Container\",\"link\":\"/zh/api/container\"}]}]},\"footer\":{\"message\":\"基于 Apache 2.0 许可发布。\",\"copyright\":\"版权所有 © 2025 zlx。保留所有权利。\"}}}},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
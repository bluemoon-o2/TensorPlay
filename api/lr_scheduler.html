<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    
    <title>tensorplay.optim.lr_scheduler | TensorPlay</title>
    <meta name="description" content="A simple deep learning framework designed for educational purposes and small-scale experiments.">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/assets/style.B8sODEHC.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.Bbcpdn01.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.DcPLavyx.js">
    <link rel="modulepreload" href="/assets/chunks/framework.DWXU4yX9.js">
    <link rel="modulepreload" href="/assets/api_lr_scheduler.md.qKIcmL6f.lean.js">
    <link rel="icon" type="image/png" href="/images/logo-0.png">
    <link rel="apple-touch-icon" href="/images/logo-0.png">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="keywords" content="deep learning, machine learning, ai framework, pytorch compatible, educational, c++, python, tensorplay, 深度学习, 机器学习, 自动微分">
    <meta name="author" content="TensorPlay Team">
    <meta property="og:type" content="website">
    <meta property="og:title" content="TensorPlay | Transparent &amp; Compatible AI Framework">
    <meta property="og:description" content="A transparent, educational, and PyTorch-compatible deep learning framework for the modern AI era.">
    <meta property="og:site_name" content="TensorPlay">
    <meta property="og:url" content="https://www.tensorplay.cn">
    <meta property="og:image" content="https://www.tensorplay.cn/images/logo-1.png">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="TensorPlay | Transparent &amp; Compatible AI Framework">
    <meta name="twitter:description" content="A transparent, educational, and PyTorch-compatible deep learning framework for the modern AI era.">
    <meta name="twitter:image" content="https://www.tensorplay.cn/images/logo-1.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300;400;500;600;700&amp;display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><canvas id="cyberpunk-particles" data-v-36680640></canvas><!----><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/" data-v-1168a8e4><!--[--><!--]--><!--[--><img class="VPImage logo" src="/images/logo-0.png" alt data-v-8426fc1a><!--]--><span data-v-1168a8e4>TensorPlay</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><!----><span data-v-cf11d7a2>Learn</span><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/guide/getting-started.html" data-v-35975db6><!--[--><span data-v-35975db6>Getting Started</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-35975db6><a class="VPLink link" href="/guide/tutorials.html" data-v-35975db6><!--[--><span data-v-35975db6>Tutorials</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/community/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Community</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/ecosystem/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Projects</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/api/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Docs</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Blog & News</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/about/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>About</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/join/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>JOIN</span><!--]--></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-6aa21345 data-v-88af2de4 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><span class="vpi-languages option-icon" data-v-cf11d7a2></span><!----><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><div class="items" data-v-88af2de4><p class="title" data-v-88af2de4>English</p><!--[--><div class="VPMenuLink" data-v-88af2de4 data-v-35975db6><a class="VPLink link" href="/zh/api/lr_scheduler.html" data-v-35975db6><!--[--><span data-v-35975db6>简体中文</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/bluemoon-o2/tensorplay" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><div class="group translations" data-v-bb2aa2f0><p class="trans-title" data-v-bb2aa2f0>English</p><!--[--><div class="VPMenuLink" data-v-bb2aa2f0 data-v-35975db6><a class="VPLink link" href="/zh/api/lr_scheduler.html" data-v-35975db6><!--[--><span data-v-35975db6>简体中文</span><!--]--></a></div><!--]--></div><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/bluemoon-o2/tensorplay" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Core API</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/tensorplay.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>tensorplay</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/autograd.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>autograd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/functional.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>functional</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/optim.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>optim</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/cuda.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>cuda</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Neural Networks (nn)</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/nn.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>nn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/modules.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Modules</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/linear.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Linear Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/conv.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Convolution Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/pooling.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Pooling Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/activation.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Activation Functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/normalization.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Normalization Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/loss.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Loss Functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/dropout.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dropout Layers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/api/container.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Container</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>On this page</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _api_lr_scheduler" data-v-39a288b8><div><h1 id="tensorplay-optim-lr-scheduler" tabindex="-1">tensorplay.optim.lr_scheduler <a class="header-anchor" href="#tensorplay-optim-lr-scheduler" aria-label="Permalink to &quot;tensorplay.optim.lr_scheduler&quot;">​</a></h1><h2 id="classes" tabindex="-1">Classes <a class="header-anchor" href="#classes" aria-label="Permalink to &quot;Classes&quot;">​</a></h2><h3 id="class-cosineannealinglr-source" tabindex="-1"><code>class CosineAnnealingLR</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L218" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-cosineannealinglr-source" aria-label="Permalink to &quot;`class CosineAnnealingLR` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L218)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">CosineAnnealingLR(optimizer, t_max, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eta_min</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">last_epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_LRScheduler</code></p><p>Set the learning rate of each parameter group using a cosine annealing schedule, where <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.489ex;" xmlns="http://www.w3.org/2000/svg" width="4.478ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 1979.4 658" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(530,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1407,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>η</mi><mrow data-mjx-texclass="ORD"><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> is set to the initial lr and <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.675ex" height="1.889ex" role="img" focusable="false" viewBox="0 -677 2066.4 834.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(617,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1407,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mrow data-mjx-texclass="ORD"><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> is the number of epochs to decay. When last_epoch=-1, sets initial lr as lr.</p><h4 id="args" tabindex="-1">Args <a class="header-anchor" href="#args" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>optimizer</strong> (<code>Optimizer</code>): Wrapped optimizer.</li><li><strong>t_max</strong> (<code>int</code>): Maximum number of epochs.</li><li><strong>eta_min</strong> (<code>float</code>): Minimum learning rate. Default: 0.</li><li><strong>last_epoch</strong> (<code>int</code>): The index of last epoch. Default: -1.</li><li><strong>verbose</strong> (<code>bool</code>): If <code>True</code>, prints a message to stdout for each update. Default: <code>False</code>.</li></ul><details><summary>Methods</summary><h4 id="init-self-optimizer-t-max-eta-min-0-last-epoch-1-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, t_max, eta_min=0, last_epoch=-1, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L233" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-t-max-eta-min-0-last-epoch-1-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, t_max, eta_min=0, last_epoch=-1, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L233)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="get-last-lr-self-list-float-source" tabindex="-1"><code>get_last_lr(self) -&gt; List[float]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-last-lr-self-list-float-source" aria-label="Permalink to &quot;`get_last_lr(self) -&gt; List[float]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93)&quot;">​</a></h4><p>Return last computed learning rates by the scheduler.</p><h4 id="raises" tabindex="-1">Raises <a class="header-anchor" href="#raises" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>RuntimeError</strong>: If the scheduler has not stepped yet.</li></ul><hr><h4 id="get-lr-self-source" tabindex="-1"><code>get_lr(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L238" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-lr-self-source" aria-label="Permalink to &quot;`get_lr(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L238)&quot;">​</a></h4><p>Compute the learning rate for the current epoch.</p><h4 id="returns" tabindex="-1">Returns <a class="header-anchor" href="#returns" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>List[float]: Learning rates for each parameter group. Must have the same length as param_groups.
</code></pre><hr><h4 id="load-state-dict-self-state-dict-dict-str-typing-any-none-source" tabindex="-1"><code>load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-dict-str-typing-any-none-source" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64)&quot;">​</a></h4><p>Loads the scheduler state.</p><h4 id="args-1" tabindex="-1">Args <a class="header-anchor" href="#args-1" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): Scheduler state. Should be an object returned from a call to <code>state_dict</code>.</li></ul><h4 id="raises-1" tabindex="-1">Raises <a class="header-anchor" href="#raises-1" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the number of base_lrs in state_dict does not match the current optimizer&#39;s param_groups.</li></ul><hr><h4 id="state-dict-self-dict-str-typing-any-source" tabindex="-1"><code>state_dict(self) -&gt; dict[str, typing.Any]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-dict-str-typing-any-source" aria-label="Permalink to &quot;`state_dict(self) -&gt; dict[str, typing.Any]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56)&quot;">​</a></h4><p>Returns the state of the scheduler as a dict.</p><p>Includes all attributes except &#39;optimizer&#39; to avoid circular references.</p><hr><h4 id="step-self-epoch-optional-int-none-none-source" tabindex="-1"><code>step(self, epoch: Optional[int] = None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-epoch-optional-int-none-none-source" aria-label="Permalink to &quot;`step(self, epoch: Optional[int] = None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104)&quot;">​</a></h4><p>Step the scheduler to update learning rates.</p><h4 id="args-2" tabindex="-1">Args <a class="header-anchor" href="#args-2" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>epoch</strong> (<code>Optional[int]</code>): The epoch index to set. If None, increment last_epoch by 1.</li></ul><h4 id="raises-2" tabindex="-1">Raises <a class="header-anchor" href="#raises-2" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If epoch is a non-integer or negative value, or less than current last_epoch.</li></ul><hr></details><h3 id="class-exponentiallr-source" tabindex="-1"><code>class ExponentialLR</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L195" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-exponentiallr-source" aria-label="Permalink to &quot;`class ExponentialLR` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L195)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ExponentialLR(optimizer, gamma, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">last_epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_LRScheduler</code></p><p>Set the learning rate of each parameter group to the initial lr decayed by gamma every epoch. When last_epoch=-1, sets initial lr as lr.</p><h4 id="args-3" tabindex="-1">Args <a class="header-anchor" href="#args-3" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>optimizer</strong> (<code>Optimizer</code>): Wrapped optimizer.</li><li><strong>gamma</strong> (<code>float</code>): Multiplicative factor of learning rate decay.</li><li><strong>Default</strong>: 0.1.</li><li><strong>last_epoch</strong> (<code>int</code>): The index of last epoch. Default: -1.</li><li><strong>verbose</strong> (<code>bool</code>): If <code>True</code>, prints a message to stdout for each update. Default: <code>False</code>.</li></ul><details><summary>Methods</summary><h4 id="init-self-optimizer-gamma-last-epoch-1-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, gamma, last_epoch=-1, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L208" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-gamma-last-epoch-1-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, gamma, last_epoch=-1, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L208)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="get-last-lr-self-list-float-source-1" tabindex="-1"><code>get_last_lr(self) -&gt; List[float]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-last-lr-self-list-float-source-1" aria-label="Permalink to &quot;`get_last_lr(self) -&gt; List[float]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93)&quot;">​</a></h4><p>Return last computed learning rates by the scheduler.</p><h4 id="raises-3" tabindex="-1">Raises <a class="header-anchor" href="#raises-3" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>RuntimeError</strong>: If the scheduler has not stepped yet.</li></ul><hr><h4 id="get-lr-self-source-1" tabindex="-1"><code>get_lr(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L212" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-lr-self-source-1" aria-label="Permalink to &quot;`get_lr(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L212)&quot;">​</a></h4><p>Compute the learning rate for the current epoch.</p><h4 id="returns-1" tabindex="-1">Returns <a class="header-anchor" href="#returns-1" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>List[float]: Learning rates for each parameter group. Must have the same length as param_groups.
</code></pre><hr><h4 id="load-state-dict-self-state-dict-dict-str-typing-any-none-source-1" tabindex="-1"><code>load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-dict-str-typing-any-none-source-1" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64)&quot;">​</a></h4><p>Loads the scheduler state.</p><h4 id="args-4" tabindex="-1">Args <a class="header-anchor" href="#args-4" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): Scheduler state. Should be an object returned from a call to <code>state_dict</code>.</li></ul><h4 id="raises-4" tabindex="-1">Raises <a class="header-anchor" href="#raises-4" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the number of base_lrs in state_dict does not match the current optimizer&#39;s param_groups.</li></ul><hr><h4 id="state-dict-self-dict-str-typing-any-source-1" tabindex="-1"><code>state_dict(self) -&gt; dict[str, typing.Any]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-dict-str-typing-any-source-1" aria-label="Permalink to &quot;`state_dict(self) -&gt; dict[str, typing.Any]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56)&quot;">​</a></h4><p>Returns the state of the scheduler as a dict.</p><p>Includes all attributes except &#39;optimizer&#39; to avoid circular references.</p><hr><h4 id="step-self-epoch-optional-int-none-none-source-1" tabindex="-1"><code>step(self, epoch: Optional[int] = None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-epoch-optional-int-none-none-source-1" aria-label="Permalink to &quot;`step(self, epoch: Optional[int] = None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104)&quot;">​</a></h4><p>Step the scheduler to update learning rates.</p><h4 id="args-5" tabindex="-1">Args <a class="header-anchor" href="#args-5" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>epoch</strong> (<code>Optional[int]</code>): The epoch index to set. If None, increment last_epoch by 1.</li></ul><h4 id="raises-5" tabindex="-1">Raises <a class="header-anchor" href="#raises-5" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If epoch is a non-integer or negative value, or less than current last_epoch.</li></ul><hr></details><h3 id="class-multisteplr-source" tabindex="-1"><code>class MultiStepLR</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L169" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-multisteplr-source" aria-label="Permalink to &quot;`class MultiStepLR` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L169)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MultiStepLR(optimizer, milestones, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">gamma</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">last_epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_LRScheduler</code></p><p>Set the learning rate of each parameter group to the initial lr decayed by gamma once the number of epoch reaches one of the milestones. When last_epoch=-1, sets initial lr as lr.</p><h4 id="args-6" tabindex="-1">Args <a class="header-anchor" href="#args-6" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>optimizer</strong> (<code>Optimizer</code>): Wrapped optimizer.</li><li><strong>milestones</strong> (<code>set of int</code>): Set of epoch indices. Must be increasing.</li><li><strong>gamma</strong> (<code>float</code>): Multiplicative factor of learning rate decay.</li><li><strong>Default</strong>: 0.1.</li><li><strong>last_epoch</strong> (<code>int</code>): The index of last epoch. Default: -1.</li><li><strong>verbose</strong> (<code>bool</code>): If <code>True</code>, prints a message to stdout for each update. Default: <code>False</code>.</li></ul><details><summary>Methods</summary><h4 id="init-self-optimizer-milestones-gamma-0-1-last-epoch-1-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, milestones, gamma=0.1, last_epoch=-1, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L184" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-milestones-gamma-0-1-last-epoch-1-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, milestones, gamma=0.1, last_epoch=-1, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L184)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="get-last-lr-self-list-float-source-2" tabindex="-1"><code>get_last_lr(self) -&gt; List[float]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-last-lr-self-list-float-source-2" aria-label="Permalink to &quot;`get_last_lr(self) -&gt; List[float]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93)&quot;">​</a></h4><p>Return last computed learning rates by the scheduler.</p><h4 id="raises-6" tabindex="-1">Raises <a class="header-anchor" href="#raises-6" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>RuntimeError</strong>: If the scheduler has not stepped yet.</li></ul><hr><h4 id="get-lr-self-source-2" tabindex="-1"><code>get_lr(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L189" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-lr-self-source-2" aria-label="Permalink to &quot;`get_lr(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L189)&quot;">​</a></h4><p>Compute the learning rate for the current epoch.</p><h4 id="returns-2" tabindex="-1">Returns <a class="header-anchor" href="#returns-2" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>List[float]: Learning rates for each parameter group. Must have the same length as param_groups.
</code></pre><hr><h4 id="load-state-dict-self-state-dict-dict-str-typing-any-none-source-2" tabindex="-1"><code>load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-dict-str-typing-any-none-source-2" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64)&quot;">​</a></h4><p>Loads the scheduler state.</p><h4 id="args-7" tabindex="-1">Args <a class="header-anchor" href="#args-7" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): Scheduler state. Should be an object returned from a call to <code>state_dict</code>.</li></ul><h4 id="raises-7" tabindex="-1">Raises <a class="header-anchor" href="#raises-7" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the number of base_lrs in state_dict does not match the current optimizer&#39;s param_groups.</li></ul><hr><h4 id="state-dict-self-dict-str-typing-any-source-2" tabindex="-1"><code>state_dict(self) -&gt; dict[str, typing.Any]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-dict-str-typing-any-source-2" aria-label="Permalink to &quot;`state_dict(self) -&gt; dict[str, typing.Any]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56)&quot;">​</a></h4><p>Returns the state of the scheduler as a dict.</p><p>Includes all attributes except &#39;optimizer&#39; to avoid circular references.</p><hr><h4 id="step-self-epoch-optional-int-none-none-source-2" tabindex="-1"><code>step(self, epoch: Optional[int] = None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-epoch-optional-int-none-none-source-2" aria-label="Permalink to &quot;`step(self, epoch: Optional[int] = None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104)&quot;">​</a></h4><p>Step the scheduler to update learning rates.</p><h4 id="args-8" tabindex="-1">Args <a class="header-anchor" href="#args-8" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>epoch</strong> (<code>Optional[int]</code>): The epoch index to set. If None, increment last_epoch by 1.</li></ul><h4 id="raises-8" tabindex="-1">Raises <a class="header-anchor" href="#raises-8" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If epoch is a non-integer or negative value, or less than current last_epoch.</li></ul><hr></details><h3 id="class-optimizer-source" tabindex="-1"><code>class Optimizer</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L5" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-optimizer-source" aria-label="Permalink to &quot;`class Optimizer` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L5)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Optimizer(params, defaults)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Base class for optimizers.</p><h4 id="args-9" tabindex="-1">Args <a class="header-anchor" href="#args-9" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>params</strong> (<code>iterable</code>): an iterable of <code>Tensor</code> s or <code>dict</code> s. Specifies what Tensors should be optimized.</li><li><strong>defaults</strong>: (dict): a dict containing default values of optimization options (used when a parameter group doesn&#39;t specify them).</li></ul><details><summary>Methods</summary><h4 id="init-self-params-defaults-source" tabindex="-1"><code>__init__(self, params, defaults)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L16" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-params-defaults-source" aria-label="Permalink to &quot;`__init__(self, params, defaults)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L16)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="add-param-group-self-param-group-source" tabindex="-1"><code>add_param_group(self, param_group)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L29" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#add-param-group-self-param-group-source" aria-label="Permalink to &quot;`add_param_group(self, param_group)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L29)&quot;">​</a></h4><hr><h4 id="load-state-dict-self-state-dict-source" tabindex="-1"><code>load_state_dict(self, state_dict)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L110" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-source" aria-label="Permalink to &quot;`load_state_dict(self, state_dict)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L110)&quot;">​</a></h4><hr><h4 id="state-dict-self-source" tabindex="-1"><code>state_dict(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L80" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-source" aria-label="Permalink to &quot;`state_dict(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L80)&quot;">​</a></h4><hr><h4 id="step-self-closure-none-source" tabindex="-1"><code>step(self, closure=None)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L77" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-closure-none-source" aria-label="Permalink to &quot;`step(self, closure=None)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L77)&quot;">​</a></h4><hr><h4 id="zero-grad-self-set-to-none-false-source" tabindex="-1"><code>zero_grad(self, set_to_none=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#zero-grad-self-set-to-none-false-source" aria-label="Permalink to &quot;`zero_grad(self, set_to_none=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/optimizer.py#L64)&quot;">​</a></h4><hr></details><h3 id="class-reducelronplateau-source" tabindex="-1"><code>class ReduceLROnPlateau</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L251" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-reducelronplateau-source" aria-label="Permalink to &quot;`class ReduceLROnPlateau` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L251)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ReduceLROnPlateau(optimizer, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;min&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">factor</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">patience</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0001</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">threshold_mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;rel&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">cooldown</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">min_lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-08</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Base class for reducing learning rate when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This scheduler reads a metrics quantity and if no improvement is seen for a &#39;patience&#39; number of epochs, the learning rate is reduced.</p><details><summary>Methods</summary><h4 id="init-self-optimizer-mode-min-factor-0-1-patience-10-threshold-0-0001-threshold-mode-rel-cooldown-0-min-lr-0-eps-1e-08-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, mode=&#39;min&#39;, factor=0.1, patience=10, threshold=0.0001, threshold_mode=&#39;rel&#39;, cooldown=0, min_lr=0, eps=1e-08, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L260" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-mode-min-factor-0-1-patience-10-threshold-0-0001-threshold-mode-rel-cooldown-0-min-lr-0-eps-1e-08-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, mode=&#39;min&#39;, factor=0.1, patience=10, threshold=0.0001, threshold_mode=&#39;rel&#39;, cooldown=0, min_lr=0, eps=1e-08, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L260)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="is-better-self-a-best-source" tabindex="-1"><code>is_better(self, a, best)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L341" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#is-better-self-a-best-source" aria-label="Permalink to &quot;`is_better(self, a, best)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L341)&quot;">​</a></h4><hr><h4 id="load-state-dict-self-state-dict-source-1" tabindex="-1"><code>load_state_dict(self, state_dict)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L374" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-source-1" aria-label="Permalink to &quot;`load_state_dict(self, state_dict)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L374)&quot;">​</a></h4><hr><h4 id="state-dict-self-source-1" tabindex="-1"><code>state_dict(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L371" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-source-1" aria-label="Permalink to &quot;`state_dict(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L371)&quot;">​</a></h4><hr><h4 id="step-self-metrics-epoch-none-source" tabindex="-1"><code>step(self, metrics, epoch=None)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L304" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-metrics-epoch-none-source" aria-label="Permalink to &quot;`step(self, metrics, epoch=None)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L304)&quot;">​</a></h4><hr></details><h3 id="class-steplr-source" tabindex="-1"><code>class StepLR</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L143" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#class-steplr-source" aria-label="Permalink to &quot;`class StepLR` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L143)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">StepLR(optimizer, step_size, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">gamma</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">last_epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><strong>Bases:</strong> <code>_LRScheduler</code></p><p>Set the learning rate of each parameter group to the initial lr decayed by gamma every step_size epochs. When last_epoch=-1, sets initial lr as lr.</p><h4 id="args-10" tabindex="-1">Args <a class="header-anchor" href="#args-10" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>optimizer</strong> (<code>Optimizer</code>): Wrapped optimizer.</li><li><strong>step_size</strong> (<code>int</code>): Period of learning rate decay.</li><li><strong>gamma</strong> (<code>float</code>): Multiplicative factor of learning rate decay.</li><li><strong>Default</strong>: 0.1.</li><li><strong>last_epoch</strong> (<code>int</code>): The index of last epoch. Default: -1.</li><li><strong>verbose</strong> (<code>bool</code>): If <code>True</code>, prints a message to stdout for each update. Default: <code>False</code>.</li></ul><details><summary>Methods</summary><h4 id="init-self-optimizer-step-size-gamma-0-1-last-epoch-1-verbose-false-source" tabindex="-1"><code>__init__(self, optimizer, step_size, gamma=0.1, last_epoch=-1, verbose=False)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L158" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#init-self-optimizer-step-size-gamma-0-1-last-epoch-1-verbose-false-source" aria-label="Permalink to &quot;`__init__(self, optimizer, step_size, gamma=0.1, last_epoch=-1, verbose=False)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L158)&quot;">​</a></h4><p>Initialize self. See help(type(self)) for accurate signature.</p><hr><h4 id="get-last-lr-self-list-float-source-3" tabindex="-1"><code>get_last_lr(self) -&gt; List[float]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-last-lr-self-list-float-source-3" aria-label="Permalink to &quot;`get_last_lr(self) -&gt; List[float]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L93)&quot;">​</a></h4><p>Return last computed learning rates by the scheduler.</p><h4 id="raises-9" tabindex="-1">Raises <a class="header-anchor" href="#raises-9" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>RuntimeError</strong>: If the scheduler has not stepped yet.</li></ul><hr><h4 id="get-lr-self-source-3" tabindex="-1"><code>get_lr(self)</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L163" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#get-lr-self-source-3" aria-label="Permalink to &quot;`get_lr(self)` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L163)&quot;">​</a></h4><p>Compute the learning rate for the current epoch.</p><h4 id="returns-3" tabindex="-1">Returns <a class="header-anchor" href="#returns-3" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><pre><code>List[float]: Learning rates for each parameter group. Must have the same length as param_groups.
</code></pre><hr><h4 id="load-state-dict-self-state-dict-dict-str-typing-any-none-source-3" tabindex="-1"><code>load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#load-state-dict-self-state-dict-dict-str-typing-any-none-source-3" aria-label="Permalink to &quot;`load_state_dict(self, state_dict: dict[str, typing.Any]) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L64)&quot;">​</a></h4><p>Loads the scheduler state.</p><h4 id="args-11" tabindex="-1">Args <a class="header-anchor" href="#args-11" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>state_dict</strong> (<code>dict</code>): Scheduler state. Should be an object returned from a call to <code>state_dict</code>.</li></ul><h4 id="raises-10" tabindex="-1">Raises <a class="header-anchor" href="#raises-10" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If the number of base_lrs in state_dict does not match the current optimizer&#39;s param_groups.</li></ul><hr><h4 id="state-dict-self-dict-str-typing-any-source-3" tabindex="-1"><code>state_dict(self) -&gt; dict[str, typing.Any]</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#state-dict-self-dict-str-typing-any-source-3" aria-label="Permalink to &quot;`state_dict(self) -&gt; dict[str, typing.Any]` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L56)&quot;">​</a></h4><p>Returns the state of the scheduler as a dict.</p><p>Includes all attributes except &#39;optimizer&#39; to avoid circular references.</p><hr><h4 id="step-self-epoch-optional-int-none-none-source-3" tabindex="-1"><code>step(self, epoch: Optional[int] = None) -&gt; None</code> <a href="https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104" target="_blank" rel="noreferrer">[source]</a> <a class="header-anchor" href="#step-self-epoch-optional-int-none-none-source-3" aria-label="Permalink to &quot;`step(self, epoch: Optional[int] = None) -&gt; None` [[source]](https://github.com/bluemoon-o2/tensorplay/blob/main/tensorplay/optim/lr_scheduler.py#L104)&quot;">​</a></h4><p>Step the scheduler to update learning rates.</p><h4 id="args-12" tabindex="-1">Args <a class="header-anchor" href="#args-12" aria-label="Permalink to &quot;Args&quot;">​</a></h4><ul><li><strong>epoch</strong> (<code>Optional[int]</code>): The epoch index to set. If None, increment last_epoch by 1.</li></ul><h4 id="raises-11" tabindex="-1">Raises <a class="header-anchor" href="#raises-11" aria-label="Permalink to &quot;Raises&quot;">​</a></h4><ul><li><strong>ValueError</strong>: If epoch is a non-integer or negative value, or less than current last_epoch.</li></ul><hr></details></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><!----></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/api/" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>Overview</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>Released under the Apache 2.0 License.</p><p class="copyright" data-v-e315a0ad>Copyright © 2025 zlx. All rights reserved.</p></div></footer><!--[--><a href="https://deepwiki.com/bluemoon-o2/TensorPlay" target="_blank" rel="noopener noreferrer" class="deepwiki-floating-badge" title="View on DeepWiki" data-v-5bf2a798><div class="badge-content" data-v-5bf2a798><span class="badge-icon" data-v-5bf2a798>📚</span><span class="badge-text" data-v-5bf2a798>DeepWiki</span></div></a><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_index.md\":\"CivpnJLS\",\"api__c.md\":\"C_J0EWHA\",\"api__reduction.md\":\"CcQTGa52\",\"api_activation.md\":\"BGBcfbA_\",\"api_adagrad.md\":\"Duucap4L\",\"api_adam.md\":\"B6F6HfPc\",\"api_adamw.md\":\"BRkR1iuY\",\"api_alexnet.md\":\"DY6a19PR\",\"api_amp.md\":\"C-bU3qHi\",\"api_audio.md\":\"COxDUPkl\",\"api_autocast_mode.md\":\"0iN_nBmE\",\"api_autograd.md\":\"9kpZfXtl\",\"api_backend.md\":\"CXUhZEyb\",\"api_backends.md\":\"B_bG74Gi\",\"api_batchnorm.md\":\"XLqeoBPh\",\"api_collate.md\":\"D4ONEdYq\",\"api_common_types.md\":\"Dh75-e2Y\",\"api_comparison.md\":\"COlCxpxH\",\"api_container.md\":\"DMH3KEiI\",\"api_conv.md\":\"DF0GFaql\",\"api_cpp.md\":\"B9E_vT7t\",\"api_cpu.md\":\"BOjn8BaM\",\"api_cuda.md\":\"v6ikcKwC\",\"api_data.md\":\"B7m_AC2B\",\"api_dataloader.md\":\"C057K852\",\"api_dataset.md\":\"B-DwApTM\",\"api_datasets.md\":\"i2152NFq\",\"api_dropout.md\":\"DzMMlVs2\",\"api_flatten.md\":\"D4zA_qjP\",\"api_folder.md\":\"DaSoqjRC\",\"api_function.md\":\"nCZMqEoD\",\"api_functional.md\":\"DRB1e583\",\"api_grad_mode.md\":\"CwdRNt1O\",\"api_grad_scaler.md\":\"Cx6Iula5\",\"api_hooks.md\":\"BIKb4iGy\",\"api_hub.md\":\"BlxbfAE8\",\"api_index.md\":\"CU1NhOLw\",\"api_init.md\":\"yxiO6Ie6\",\"api_instancenorm.md\":\"CyhqGI7E\",\"api_io.md\":\"D5L0xo2J\",\"api_lazy.md\":\"C1xShkoe\",\"api_linear.md\":\"D0-JMnEM\",\"api_loss.md\":\"BJQVFhNb\",\"api_lr_scheduler.md\":\"qKIcmL6f\",\"api_mkl.md\":\"CGkKnAIU\",\"api_mkldnn.md\":\"DLcmdCYf\",\"api_mnist.md\":\"DvSH5G-2\",\"api_models.md\":\"PxIjWRF1\",\"api_module.md\":\"CnrRone4\",\"api_modules.md\":\"yK73B9y6\",\"api_multiprocessing.md\":\"DrisgWAY\",\"api_nn.md\":\"4XkbCLIj\",\"api_normalization.md\":\"D0JAaa1R\",\"api_onnx.md\":\"maU2_GEX\",\"api_openmp.md\":\"BCYWCTil\",\"api_ops.md\":\"BMv0aklF\",\"api_optim.md\":\"CaxPVV4U\",\"api_optimizer.md\":\"TLuDU7KR\",\"api_parameter.md\":\"BQlUd1Rx\",\"api_pooling.md\":\"Csm8n1fJ\",\"api_primitives.md\":\"h9kmOGWa\",\"api_rmsprop.md\":\"K8IflYqt\",\"api_sampler.md\":\"Docoa_mD\",\"api_serialization.md\":\"Yz3Vj80d\",\"api_sgd.md\":\"CvX_KTaM\",\"api_sparse.md\":\"BREaz85i\",\"api_stax.md\":\"XChG2EZZ\",\"api_tensorplay.md\":\"DmrkfdPn\",\"api_transforms.md\":\"Be1af3uD\",\"api_triton.md\":\"JKz49eZ7\",\"api_types.md\":\"943V7hWH\",\"api_utils.md\":\"DVKjBrp2\",\"api_vision.md\":\"zbCijo_o\",\"api_viz.md\":\"CiZx1vUZ\",\"api_worker.md\":\"Bz9t8sLd\",\"blog_index.md\":\"B2h2By8z\",\"blog_posts_deep-dive-p10-dispatcher.md\":\"Op6Q8VOt\",\"blog_posts_tensorplay-architecture-design.md\":\"C3rZ8MKN\",\"blog_posts_tpx-autograd-decoupling.md\":\"B5BuZeLr\",\"changelog.md\":\"BUIkw7Qb\",\"community_index.md\":\"ClpoEdVU\",\"contributing.md\":\"D8ZfsEom\",\"ecosystem_index.md\":\"gtvnBFE0\",\"guide_architecture.md\":\"6oaLgXdc\",\"guide_getting-started.md\":\"Buqy5xfl\",\"guide_install.md\":\"CMrQwZ6d\",\"guide_quickstart.md\":\"B6_UpAzb\",\"guide_resources.md\":\"BV5U6Os2\",\"guide_tutorials.md\":\"BZfLWtiC\",\"guide_tutorials_cnn-classification.md\":\"gUJGnFt_\",\"guide_tutorials_custom-autograd.md\":\"sQU_lsig\",\"guide_tutorials_linear-regression.md\":\"DgenOgcp\",\"guide_what-is-tensorplay.md\":\"Cr9LJ0YI\",\"index.md\":\"FiW_nFlh\",\"join_index.md\":\"DEJ6DZZ0\",\"privacy.md\":\"DEhyX8TP\",\"zh_about_index.md\":\"C0qMuj3_\",\"zh_api__c.md\":\"CSuKrWkC\",\"zh_api__reduction.md\":\"B3daZSCA\",\"zh_api_activation.md\":\"CZMJ9jbW\",\"zh_api_adagrad.md\":\"DHu6ziwz\",\"zh_api_adam.md\":\"B0FY4EOy\",\"zh_api_adamw.md\":\"CWrIOxtJ\",\"zh_api_alexnet.md\":\"DFqPETqU\",\"zh_api_amp.md\":\"Cp6DUBtV\",\"zh_api_audio.md\":\"DzU_oAU1\",\"zh_api_autocast_mode.md\":\"C5QatGaz\",\"zh_api_autograd.md\":\"C3rUrDnv\",\"zh_api_backend.md\":\"BvUHlOkJ\",\"zh_api_backends.md\":\"D5m5NMmh\",\"zh_api_batchnorm.md\":\"Bo4Pl8ij\",\"zh_api_collate.md\":\"C9yeRKMz\",\"zh_api_common_types.md\":\"51LRPJtH\",\"zh_api_comparison.md\":\"CmoYjd2x\",\"zh_api_container.md\":\"ecpuGL9c\",\"zh_api_conv.md\":\"CCAFGFF2\",\"zh_api_cpp.md\":\"C_Qv-gh-\",\"zh_api_cuda.md\":\"Ch-0DTcR\",\"zh_api_data.md\":\"D8Ewk7N7\",\"zh_api_dataloader.md\":\"CcmiB811\",\"zh_api_dataset.md\":\"D-cegnxU\",\"zh_api_datasets.md\":\"DYHjDpEe\",\"zh_api_dropout.md\":\"B4KevHXm\",\"zh_api_flatten.md\":\"DEAvbacp\",\"zh_api_folder.md\":\"Cgxw6iWX\",\"zh_api_function.md\":\"BJWjNfM0\",\"zh_api_functional.md\":\"DQbKL0xC\",\"zh_api_grad_mode.md\":\"BFeDCfd7\",\"zh_api_grad_scaler.md\":\"DCTY_-th\",\"zh_api_hooks.md\":\"3iIg6lb4\",\"zh_api_hub.md\":\"CEDAtQ6E\",\"zh_api_index.md\":\"CbRR1k25\",\"zh_api_init.md\":\"BqQy98Zn\",\"zh_api_instancenorm.md\":\"LzLgKUnO\",\"zh_api_io.md\":\"D2S8h9kl\",\"zh_api_lazy.md\":\"aFzKlDTe\",\"zh_api_linear.md\":\"CNWJcDWd\",\"zh_api_loss.md\":\"CJx9AuDU\",\"zh_api_lr_scheduler.md\":\"CEmO09Z4\",\"zh_api_mkl.md\":\"CJb3speK\",\"zh_api_mkldnn.md\":\"IkiVLyDS\",\"zh_api_mnist.md\":\"B9ADoHZ5\",\"zh_api_models.md\":\"g3-O97YN\",\"zh_api_module.md\":\"BPDJ-1Kk\",\"zh_api_modules.md\":\"Cgu9RPlU\",\"zh_api_multiprocessing.md\":\"G2hJzSLM\",\"zh_api_nn.md\":\"DT072hnu\",\"zh_api_normalization.md\":\"CMzsTRlT\",\"zh_api_onnx.md\":\"CjhD6BJR\",\"zh_api_openmp.md\":\"D9v_3MHS\",\"zh_api_ops.md\":\"BkisPtY5\",\"zh_api_optim.md\":\"CP5UB3gJ\",\"zh_api_optimizer.md\":\"CPOByaaw\",\"zh_api_parameter.md\":\"XiiS9CGF\",\"zh_api_pooling.md\":\"D950IsK0\",\"zh_api_primitives.md\":\"Dd3Dk8aE\",\"zh_api_rmsprop.md\":\"CPe7ryaO\",\"zh_api_sampler.md\":\"Bfhil5Ns\",\"zh_api_serialization.md\":\"Cmp7efEt\",\"zh_api_sgd.md\":\"C5LAFD4S\",\"zh_api_sparse.md\":\"CARPRVJP\",\"zh_api_stax.md\":\"B38hG-b1\",\"zh_api_tensorplay.md\":\"CPudKJkw\",\"zh_api_transforms.md\":\"CqQu24bY\",\"zh_api_types.md\":\"CWZNrGJb\",\"zh_api_utils.md\":\"B2MXTLh6\",\"zh_api_vision.md\":\"nVKKiAhu\",\"zh_api_viz.md\":\"CgkacQOO\",\"zh_api_worker.md\":\"Ca4fmC1_\",\"zh_blog_index.md\":\"K40rMw4R\",\"zh_blog_posts_deep-dive-p10-dispatcher.md\":\"B9LpN9fE\",\"zh_blog_posts_tensorplay-architecture-design.md\":\"B1115zly\",\"zh_blog_posts_tpx-autograd-decoupling.md\":\"jONX5ja6\",\"zh_changelog.md\":\"DWHyZqpt\",\"zh_community_index.md\":\"eV1HDn5F\",\"zh_contributing.md\":\"Ba70JOpw\",\"zh_ecosystem_index.md\":\"CtS2mywe\",\"zh_guide_architecture.md\":\"C-yDD8tS\",\"zh_guide_getting-started.md\":\"yqgE04Td\",\"zh_guide_install.md\":\"DuL2QCJ_\",\"zh_guide_quickstart.md\":\"CPJMLO2F\",\"zh_guide_resources.md\":\"6P7d8N8C\",\"zh_guide_tutorials.md\":\"B1F8PlnM\",\"zh_guide_tutorials_cnn-classification.md\":\"6bqTLd2c\",\"zh_guide_tutorials_custom-autograd.md\":\"1odlIk1U\",\"zh_guide_tutorials_linear-regression.md\":\"CRwjWFUg\",\"zh_guide_what-is-tensorplay.md\":\"BjbN8xd_\",\"zh_index.md\":\"lfD4EwUL\",\"zh_join_index.md\":\"Conbfq5r\",\"zh_privacy.md\":\"CaMhTqnu\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"TensorPlay\",\"description\":\"A transparent, educational, and PyTorch-compatible deep learning framework.\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/images/logo-0.png\",\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/bluemoon-o2/tensorplay\"}],\"search\":{\"provider\":\"local\",\"options\":{\"locales\":{\"zh\":{\"translations\":{\"button\":{\"buttonText\":\"搜索文档\",\"buttonAriaLabel\":\"搜索文档\"},\"modal\":{\"noResultsText\":\"无法找到相关结果\",\"resetButtonTitle\":\"清除查询条件\",\"footer\":{\"selectText\":\"选择\",\"navigateText\":\"切换\",\"closeText\":\"关闭\"}}}}}}}},\"locales\":{\"root\":{\"label\":\"English\",\"lang\":\"en\",\"description\":\"A simple deep learning framework designed for educational purposes and small-scale experiments.\",\"themeConfig\":{\"nav\":[{\"text\":\"Learn\",\"items\":[{\"text\":\"Getting Started\",\"link\":\"/guide/getting-started\"},{\"text\":\"Tutorials\",\"link\":\"/guide/tutorials\"}]},{\"text\":\"Community\",\"link\":\"/community/\"},{\"text\":\"Projects\",\"link\":\"/ecosystem/\"},{\"text\":\"Docs\",\"link\":\"/api/\"},{\"text\":\"Blog & News\",\"link\":\"/blog/\"},{\"text\":\"About\",\"link\":\"/about/\"},{\"text\":\"JOIN\",\"link\":\"/join/\"}],\"sidebar\":{\"/guide/\":[{\"text\":\"Introduction\",\"items\":[{\"text\":\"What is TensorPlay?\",\"link\":\"/guide/what-is-tensorplay\"},{\"text\":\"Getting Started\",\"link\":\"/guide/getting-started\"},{\"text\":\"Installation\",\"link\":\"/guide/install\"},{\"text\":\"Quickstart\",\"link\":\"/guide/quickstart\"},{\"text\":\"Architecture\",\"link\":\"/guide/architecture\"}]},{\"text\":\"Guides & Resources\",\"items\":[{\"text\":\"Tutorials\",\"link\":\"/guide/tutorials\",\"items\":[{\"text\":\"Image Classification\",\"link\":\"/guide/tutorials/cnn-classification\"},{\"text\":\"Linear Regression\",\"link\":\"/guide/tutorials/linear-regression\"},{\"text\":\"Custom Autograd\",\"link\":\"/guide/tutorials/custom-autograd\"}]},{\"text\":\"Resources\",\"link\":\"/guide/resources\"},{\"text\":\"API Reference\",\"link\":\"/api/\"}]}],\"/api/\":[{\"text\":\"Core API\",\"items\":[{\"text\":\"Overview\",\"link\":\"/api/\"},{\"text\":\"tensorplay\",\"link\":\"/api/tensorplay\"},{\"text\":\"autograd\",\"link\":\"/api/autograd\"},{\"text\":\"functional\",\"link\":\"/api/functional\"},{\"text\":\"optim\",\"link\":\"/api/optim\"},{\"text\":\"cuda\",\"link\":\"/api/cuda\"}]},{\"text\":\"Neural Networks (nn)\",\"collapsed\":false,\"items\":[{\"text\":\"nn\",\"link\":\"/api/nn\"},{\"text\":\"Modules\",\"link\":\"/api/modules\"},{\"text\":\"Linear Layers\",\"link\":\"/api/linear\"},{\"text\":\"Convolution Layers\",\"link\":\"/api/conv\"},{\"text\":\"Pooling Layers\",\"link\":\"/api/pooling\"},{\"text\":\"Activation Functions\",\"link\":\"/api/activation\"},{\"text\":\"Normalization Layers\",\"link\":\"/api/normalization\"},{\"text\":\"Loss Functions\",\"link\":\"/api/loss\"},{\"text\":\"Dropout Layers\",\"link\":\"/api/dropout\"},{\"text\":\"Container\",\"link\":\"/api/container\"}]}]},\"footer\":{\"message\":\"Released under the Apache 2.0 License.\",\"copyright\":\"Copyright © 2025 zlx. All rights reserved.\"}}},\"zh\":{\"label\":\"简体中文\",\"lang\":\"zh\",\"link\":\"/zh/\",\"description\":\"一个适合学习者、兼容 PyTorch 的深度学习框架。\",\"themeConfig\":{\"nav\":[{\"text\":\"学习\",\"items\":[{\"text\":\"快速开始\",\"link\":\"/zh/guide/getting-started\"},{\"text\":\"教程\",\"link\":\"/zh/guide/tutorials\"}]},{\"text\":\"社区\",\"link\":\"/zh/community/\"},{\"text\":\"项目\",\"link\":\"/zh/ecosystem/\"},{\"text\":\"文档\",\"link\":\"/zh/api/\"},{\"text\":\"博客与新闻\",\"link\":\"/zh/blog/\"},{\"text\":\"关于\",\"link\":\"/zh/about/\"},{\"text\":\"加入我们\",\"link\":\"/zh/join/\"}],\"sidebar\":{\"/zh/guide/\":[{\"text\":\"介绍\",\"items\":[{\"text\":\"什么是 TensorPlay?\",\"link\":\"/zh/guide/what-is-tensorplay\"},{\"text\":\"快速开始\",\"link\":\"/zh/guide/getting-started\"},{\"text\":\"安装\",\"link\":\"/zh/guide/install\"},{\"text\":\"快速入门\",\"link\":\"/zh/guide/quickstart\"},{\"text\":\"架构设计\",\"link\":\"/zh/guide/architecture\"}]},{\"text\":\"指南与资源\",\"items\":[{\"text\":\"教程\",\"link\":\"/zh/guide/tutorials\",\"items\":[{\"text\":\"图像分类\",\"link\":\"/zh/guide/tutorials/cnn-classification\"},{\"text\":\"线性回归\",\"link\":\"/zh/guide/tutorials/linear-regression\"},{\"text\":\"自定义自动微分\",\"link\":\"/zh/guide/tutorials/custom-autograd\"}]},{\"text\":\"资源\",\"link\":\"/zh/guide/resources\"},{\"text\":\"API 参考\",\"link\":\"/zh/api/\"}]}],\"/zh/api/\":[{\"text\":\"核心 API\",\"items\":[{\"text\":\"概览\",\"link\":\"/zh/api/\"},{\"text\":\"tensorplay\",\"link\":\"/zh/api/tensorplay\"},{\"text\":\"autograd\",\"link\":\"/zh/api/autograd\"},{\"text\":\"functional\",\"link\":\"/zh/api/functional\"},{\"text\":\"optim\",\"link\":\"/zh/api/optim\"},{\"text\":\"cuda\",\"link\":\"/zh/api/cuda\"}]},{\"text\":\"神经网络 (nn)\",\"collapsed\":false,\"items\":[{\"text\":\"nn\",\"link\":\"/zh/api/nn\"},{\"text\":\"Modules\",\"link\":\"/zh/api/modules\"},{\"text\":\"Linear Layers\",\"link\":\"/zh/api/linear\"},{\"text\":\"Convolution Layers\",\"link\":\"/zh/api/conv\"},{\"text\":\"Pooling Layers\",\"link\":\"/zh/api/pooling\"},{\"text\":\"Activation Functions\",\"link\":\"/zh/api/activation\"},{\"text\":\"Normalization Layers\",\"link\":\"/zh/api/normalization\"},{\"text\":\"Loss Functions\",\"link\":\"/zh/api/loss\"},{\"text\":\"Dropout Layers\",\"link\":\"/zh/api/dropout\"},{\"text\":\"Container\",\"link\":\"/zh/api/container\"}]}]},\"footer\":{\"message\":\"基于 Apache 2.0 许可发布。\",\"copyright\":\"版权所有 © 2025 zlx。保留所有权利。\"}}}},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>